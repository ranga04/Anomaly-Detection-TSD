{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "id": "NcUYAJRhaSkU",
        "outputId": "67dc1495-9f9a-41a6-a09d-92859c311f9d"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Import necessary libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "np.random.seed(42)\n",
        "\n",
        "# Function to generate synthetic time-series data with anomalies\n",
        "def generate_synthetic_data(n_steps=1000):\n",
        "    time = np.arange(0, n_steps)\n",
        "    # Generate a sine wave and add some noise\n",
        "    data = np.sin(0.02 * time) + 0.1 * np.random.randn(n_steps)\n",
        "    # Introduce anomalies (e.g., outliers)\n",
        "    anomalies = np.random.randint(0, n_steps, size=10)\n",
        "    data[anomalies] += np.random.randn(10) * 5  # Add large outliers to simulate anomalies\n",
        "    return time, data\n",
        "\n",
        "# Generate synthetic time-series data\n",
        "time, data = generate_synthetic_data()\n",
        "\n",
        "# Plot the time-series data with anomalies\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(time, data, label=\"Time Series Data\")\n",
        "plt.title(\"Synthetic Time Series Data with Anomalies\")\n",
        "plt.xlabel(\"Time\")\n",
        "plt.ylabel(\"Value\")\n",
        "plt.legend()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Data Preprocessing\n",
        "\n",
        "# Normalize the data\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "data_scaled = scaler.fit_transform(data.reshape(-1, 1))\n",
        "\n",
        "# Create sequences for LSTM input\n",
        "def create_sequences(data, seq_length):\n",
        "    sequences = []\n",
        "    labels = []\n",
        "    for i in range(len(data) - seq_length):\n",
        "        sequences.append(data[i:i + seq_length])\n",
        "        labels.append(data[i + seq_length])\n",
        "    return np.array(sequences), np.array(labels)\n",
        "\n",
        "# Define the sequence length\n",
        "sequence_length = 50  # You can adjust this based on the dataset\n",
        "\n",
        "# Create sequences and labels\n",
        "X, y = create_sequences(data_scaled, sequence_length)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "split = int(0.8 * len(X))  # 80% training, 20% testing\n",
        "X_train, X_test = X[:split], X[split:]\n",
        "y_train, y_test = y[:split], y[split:]\n",
        "\n",
        "# Manual Hyperparameter Tuning\n",
        "def create_and_train_model(units, dropout_rate, optimizer, batch_size, epochs):\n",
        "    model = Sequential()\n",
        "    model.add(LSTM(units=units, return_sequences=True, input_shape=(sequence_length, 1)))\n",
        "    model.add(Dropout(dropout_rate))\n",
        "    model.add(LSTM(units=units))\n",
        "    model.add(Dropout(dropout_rate))\n",
        "    model.add(Dense(1))\n",
        "    model.compile(optimizer=optimizer, loss='mean_squared_error')\n",
        "\n",
        "    # Train the model\n",
        "    model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, validation_data=(X_test, y_test), verbose=1)\n",
        "\n",
        "    # Evaluate the model\n",
        "    y_pred = model.predict(X_test)\n",
        "    y_pred_rescaled = scaler.inverse_transform(y_pred)\n",
        "    y_test_rescaled = scaler.inverse_transform(y_test.reshape(-1, 1))\n",
        "\n",
        "    # Calculate and return Mean Squared Error\n",
        "    mse = mean_squared_error(y_test_rescaled, y_pred_rescaled)\n",
        "    return mse, model\n",
        "\n",
        "# Define hyperparameter space\n",
        "units_options = [50, 100]\n",
        "dropout_options = [0.2, 0.3]\n",
        "batch_size_options = [32, 64]\n",
        "epochs_options = [20, 40]\n",
        "optimizer_options = ['adam', 'rmsprop']\n",
        "\n",
        "# Iterate over each combination of hyperparameters\n",
        "best_mse = float('inf')\n",
        "best_params = None\n",
        "best_model = None\n",
        "\n",
        "for units in units_options:\n",
        "    for dropout_rate in dropout_options:\n",
        "        for batch_size in batch_size_options:\n",
        "            for epochs in epochs_options:\n",
        "                for optimizer in optimizer_options:\n",
        "                    print(f\"Training model with units={units}, dropout={dropout_rate}, batch_size={batch_size}, epochs={epochs}, optimizer={optimizer}\")\n",
        "                    mse, model = create_and_train_model(units, dropout_rate, optimizer, batch_size, epochs)\n",
        "                    print(f\"MSE: {mse}\")\n",
        "                    if mse < best_mse:\n",
        "                        best_mse = mse\n",
        "                        best_params = (units, dropout_rate, batch_size, epochs, optimizer)\n",
        "                        best_model = model\n",
        "\n",
        "# Output best hyperparameters\n",
        "print(f\"Best Hyperparameters: Units={best_params[0]}, Dropout={best_params[1]}, Batch Size={best_params[2]}, Epochs={best_params[3]}, Optimizer={best_params[4]}\")\n",
        "print(f\"Best MSE: {best_mse:.4f}\")\n",
        "\n",
        "# Use the best_model for further predictions or evaluations\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-rALmKS0bPsf",
        "outputId": "d1e26c65-196d-47d2-d883-dc5c924c3f5c"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training model with units=50, dropout=0.2, batch_size=32, epochs=20, optimizer=adam\n",
            "Epoch 1/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 34ms/step - loss: 0.0257 - val_loss: 0.0058\n",
            "Epoch 2/20\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 44ms/step - loss: 0.0020 - val_loss: 0.0055\n",
            "Epoch 3/20\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0018 - val_loss: 0.0054\n",
            "Epoch 4/20\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0013 - val_loss: 0.0053\n",
            "Epoch 5/20\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0014 - val_loss: 0.0055\n",
            "Epoch 6/20\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0015 - val_loss: 0.0053\n",
            "Epoch 7/20\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0013 - val_loss: 0.0053\n",
            "Epoch 8/20\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0014 - val_loss: 0.0053\n",
            "Epoch 9/20\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0015 - val_loss: 0.0053\n",
            "Epoch 10/20\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0017 - val_loss: 0.0053\n",
            "Epoch 11/20\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0010 - val_loss: 0.0053\n",
            "Epoch 12/20\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0013 - val_loss: 0.0053\n",
            "Epoch 13/20\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0023 - val_loss: 0.0053\n",
            "Epoch 14/20\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0012 - val_loss: 0.0054\n",
            "Epoch 15/20\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 8.1591e-04 - val_loss: 0.0054\n",
            "Epoch 16/20\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0013 - val_loss: 0.0053\n",
            "Epoch 17/20\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 9.3484e-04 - val_loss: 0.0054\n",
            "Epoch 18/20\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0022 - val_loss: 0.0053\n",
            "Epoch 19/20\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0012 - val_loss: 0.0053\n",
            "Epoch 20/20\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 7.7605e-04 - val_loss: 0.0053\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "MSE: 0.5978308956398055\n",
            "Training model with units=50, dropout=0.2, batch_size=32, epochs=20, optimizer=rmsprop\n",
            "Epoch 1/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 0.0142 - val_loss: 0.0055\n",
            "Epoch 2/20\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0020 - val_loss: 0.0055\n",
            "Epoch 3/20\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0024 - val_loss: 0.0054\n",
            "Epoch 4/20\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0017 - val_loss: 0.0053\n",
            "Epoch 5/20\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0020 - val_loss: 0.0056\n",
            "Epoch 6/20\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0019 - val_loss: 0.0061\n",
            "Epoch 7/20\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0014 - val_loss: 0.0053\n",
            "Epoch 8/20\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0021 - val_loss: 0.0055\n",
            "Epoch 9/20\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0015 - val_loss: 0.0054\n",
            "Epoch 10/20\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0016 - val_loss: 0.0053\n",
            "Epoch 11/20\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0017 - val_loss: 0.0053\n",
            "Epoch 12/20\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0014 - val_loss: 0.0056\n",
            "Epoch 13/20\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0017 - val_loss: 0.0061\n",
            "Epoch 14/20\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0011 - val_loss: 0.0056\n",
            "Epoch 15/20\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0014 - val_loss: 0.0069\n",
            "Epoch 16/20\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0018 - val_loss: 0.0056\n",
            "Epoch 17/20\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0011 - val_loss: 0.0053\n",
            "Epoch 18/20\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 8.2642e-04 - val_loss: 0.0053\n",
            "Epoch 19/20\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0011 - val_loss: 0.0054\n",
            "Epoch 20/20\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 7.6804e-04 - val_loss: 0.0056\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "MSE: 0.6293700462706833\n",
            "Training model with units=50, dropout=0.2, batch_size=32, epochs=40, optimizer=adam\n",
            "Epoch 1/40\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 0.0246 - val_loss: 0.0057\n",
            "Epoch 2/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0024 - val_loss: 0.0055\n",
            "Epoch 3/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0015 - val_loss: 0.0054\n",
            "Epoch 4/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0014 - val_loss: 0.0053\n",
            "Epoch 5/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0019 - val_loss: 0.0053\n",
            "Epoch 6/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 9.2288e-04 - val_loss: 0.0053\n",
            "Epoch 7/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0020 - val_loss: 0.0053\n",
            "Epoch 8/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0011 - val_loss: 0.0055\n",
            "Epoch 9/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0010 - val_loss: 0.0053\n",
            "Epoch 10/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 9.6632e-04 - val_loss: 0.0053\n",
            "Epoch 11/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0015 - val_loss: 0.0053\n",
            "Epoch 12/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0013 - val_loss: 0.0053\n",
            "Epoch 13/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 7.0894e-04 - val_loss: 0.0053\n",
            "Epoch 14/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 9.4538e-04 - val_loss: 0.0054\n",
            "Epoch 15/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0015 - val_loss: 0.0054\n",
            "Epoch 16/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0011 - val_loss: 0.0053\n",
            "Epoch 17/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 8.8845e-04 - val_loss: 0.0053\n",
            "Epoch 18/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 8.8540e-04 - val_loss: 0.0055\n",
            "Epoch 19/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0017 - val_loss: 0.0055\n",
            "Epoch 20/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0013 - val_loss: 0.0054\n",
            "Epoch 21/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 6.6966e-04 - val_loss: 0.0053\n",
            "Epoch 22/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 9.3246e-04 - val_loss: 0.0053\n",
            "Epoch 23/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 9.9711e-04 - val_loss: 0.0054\n",
            "Epoch 24/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0011 - val_loss: 0.0057\n",
            "Epoch 25/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0018 - val_loss: 0.0055\n",
            "Epoch 26/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0016 - val_loss: 0.0053\n",
            "Epoch 27/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0012 - val_loss: 0.0054\n",
            "Epoch 28/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0020 - val_loss: 0.0054\n",
            "Epoch 29/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 9.2927e-04 - val_loss: 0.0054\n",
            "Epoch 30/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0015 - val_loss: 0.0054\n",
            "Epoch 31/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0015 - val_loss: 0.0053\n",
            "Epoch 32/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 6.7528e-04 - val_loss: 0.0053\n",
            "Epoch 33/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0014 - val_loss: 0.0054\n",
            "Epoch 34/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 7.9207e-04 - val_loss: 0.0053\n",
            "Epoch 35/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 9.9668e-04 - val_loss: 0.0053\n",
            "Epoch 36/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0015 - val_loss: 0.0053\n",
            "Epoch 37/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0011 - val_loss: 0.0053\n",
            "Epoch 38/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 5.1137e-04 - val_loss: 0.0054\n",
            "Epoch 39/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0015 - val_loss: 0.0053\n",
            "Epoch 40/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0011 - val_loss: 0.0054\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 13 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7e4820f82d40> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m6/6\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "MSE: 0.6003066785468975\n",
            "Training model with units=50, dropout=0.2, batch_size=32, epochs=40, optimizer=rmsprop\n",
            "Epoch 1/40\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 0.0178 - val_loss: 0.0056\n",
            "Epoch 2/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0022 - val_loss: 0.0054\n",
            "Epoch 3/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0021 - val_loss: 0.0053\n",
            "Epoch 4/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0027 - val_loss: 0.0062\n",
            "Epoch 5/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0022 - val_loss: 0.0053\n",
            "Epoch 6/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0020 - val_loss: 0.0059\n",
            "Epoch 7/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0016 - val_loss: 0.0057\n",
            "Epoch 8/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0015 - val_loss: 0.0062\n",
            "Epoch 9/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0015 - val_loss: 0.0055\n",
            "Epoch 10/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0013 - val_loss: 0.0056\n",
            "Epoch 11/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0014 - val_loss: 0.0055\n",
            "Epoch 12/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0015 - val_loss: 0.0060\n",
            "Epoch 13/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0025 - val_loss: 0.0056\n",
            "Epoch 14/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0010 - val_loss: 0.0053\n",
            "Epoch 15/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0011 - val_loss: 0.0053\n",
            "Epoch 16/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 7.8993e-04 - val_loss: 0.0053\n",
            "Epoch 17/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0011 - val_loss: 0.0053\n",
            "Epoch 18/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0012 - val_loss: 0.0053\n",
            "Epoch 19/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0016 - val_loss: 0.0054\n",
            "Epoch 20/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0016 - val_loss: 0.0054\n",
            "Epoch 21/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0016 - val_loss: 0.0054\n",
            "Epoch 22/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0015 - val_loss: 0.0053\n",
            "Epoch 23/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0012 - val_loss: 0.0053\n",
            "Epoch 24/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0017 - val_loss: 0.0056\n",
            "Epoch 25/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0016 - val_loss: 0.0065\n",
            "Epoch 26/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0014 - val_loss: 0.0055\n",
            "Epoch 27/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0019 - val_loss: 0.0056\n",
            "Epoch 28/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0014 - val_loss: 0.0056\n",
            "Epoch 29/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0016 - val_loss: 0.0055\n",
            "Epoch 30/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0011 - val_loss: 0.0053\n",
            "Epoch 31/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0015 - val_loss: 0.0055\n",
            "Epoch 32/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 9.9125e-04 - val_loss: 0.0055\n",
            "Epoch 33/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 9.4283e-04 - val_loss: 0.0056\n",
            "Epoch 34/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0017 - val_loss: 0.0054\n",
            "Epoch 35/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 7.1855e-04 - val_loss: 0.0054\n",
            "Epoch 36/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 5.3625e-04 - val_loss: 0.0083\n",
            "Epoch 37/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0016 - val_loss: 0.0054\n",
            "Epoch 38/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 9.0695e-04 - val_loss: 0.0054\n",
            "Epoch 39/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 8.2690e-04 - val_loss: 0.0057\n",
            "Epoch 40/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0011 - val_loss: 0.0055\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 13 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7e482003ad40> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m6/6\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MSE: 0.6101686865493274\n",
            "Training model with units=50, dropout=0.2, batch_size=64, epochs=20, optimizer=adam\n",
            "Epoch 1/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - loss: 0.0269 - val_loss: 0.0061\n",
            "Epoch 2/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0026 - val_loss: 0.0055\n",
            "Epoch 3/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0018 - val_loss: 0.0055\n",
            "Epoch 4/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0015 - val_loss: 0.0055\n",
            "Epoch 5/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0013 - val_loss: 0.0054\n",
            "Epoch 6/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0014 - val_loss: 0.0053\n",
            "Epoch 7/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0017 - val_loss: 0.0053\n",
            "Epoch 8/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0017 - val_loss: 0.0053\n",
            "Epoch 9/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0011 - val_loss: 0.0053\n",
            "Epoch 10/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0016 - val_loss: 0.0055\n",
            "Epoch 11/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0014 - val_loss: 0.0055\n",
            "Epoch 12/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0011 - val_loss: 0.0053\n",
            "Epoch 13/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0017 - val_loss: 0.0053\n",
            "Epoch 14/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0017 - val_loss: 0.0053\n",
            "Epoch 15/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 8.8894e-04 - val_loss: 0.0053\n",
            "Epoch 16/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0011 - val_loss: 0.0053\n",
            "Epoch 17/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0013 - val_loss: 0.0054\n",
            "Epoch 18/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0023 - val_loss: 0.0053\n",
            "Epoch 19/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0019 - val_loss: 0.0053\n",
            "Epoch 20/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0016 - val_loss: 0.0053\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "MSE: 0.5978060277358602\n",
            "Training model with units=50, dropout=0.2, batch_size=64, epochs=20, optimizer=rmsprop\n",
            "Epoch 1/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 35ms/step - loss: 0.0105 - val_loss: 0.0056\n",
            "Epoch 2/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0027 - val_loss: 0.0053\n",
            "Epoch 3/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0030 - val_loss: 0.0071\n",
            "Epoch 4/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0026 - val_loss: 0.0054\n",
            "Epoch 5/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0022 - val_loss: 0.0060\n",
            "Epoch 6/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0020 - val_loss: 0.0053\n",
            "Epoch 7/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0021 - val_loss: 0.0056\n",
            "Epoch 8/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0018 - val_loss: 0.0053\n",
            "Epoch 9/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0014 - val_loss: 0.0053\n",
            "Epoch 10/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0025 - val_loss: 0.0053\n",
            "Epoch 11/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0016 - val_loss: 0.0053\n",
            "Epoch 12/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0015 - val_loss: 0.0056\n",
            "Epoch 13/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0025 - val_loss: 0.0054\n",
            "Epoch 14/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0022 - val_loss: 0.0056\n",
            "Epoch 15/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0020 - val_loss: 0.0055\n",
            "Epoch 16/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0019 - val_loss: 0.0053\n",
            "Epoch 17/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 9.4853e-04 - val_loss: 0.0057\n",
            "Epoch 18/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0016 - val_loss: 0.0054\n",
            "Epoch 19/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0023 - val_loss: 0.0053\n",
            "Epoch 20/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0014 - val_loss: 0.0055\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "MSE: 0.6134563452582891\n",
            "Training model with units=50, dropout=0.2, batch_size=64, epochs=40, optimizer=adam\n",
            "Epoch 1/40\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 50ms/step - loss: 0.0403 - val_loss: 0.0076\n",
            "Epoch 2/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0031 - val_loss: 0.0061\n",
            "Epoch 3/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0031 - val_loss: 0.0065\n",
            "Epoch 4/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0024 - val_loss: 0.0056\n",
            "Epoch 5/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0025 - val_loss: 0.0057\n",
            "Epoch 6/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0019 - val_loss: 0.0054\n",
            "Epoch 7/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0013 - val_loss: 0.0053\n",
            "Epoch 8/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0015 - val_loss: 0.0053\n",
            "Epoch 9/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0017 - val_loss: 0.0053\n",
            "Epoch 10/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0013 - val_loss: 0.0054\n",
            "Epoch 11/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0014 - val_loss: 0.0053\n",
            "Epoch 12/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0016 - val_loss: 0.0053\n",
            "Epoch 13/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0014 - val_loss: 0.0053\n",
            "Epoch 14/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 8.8239e-04 - val_loss: 0.0052\n",
            "Epoch 15/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0011 - val_loss: 0.0053\n",
            "Epoch 16/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0020 - val_loss: 0.0053\n",
            "Epoch 17/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 8.9485e-04 - val_loss: 0.0052\n",
            "Epoch 18/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0017 - val_loss: 0.0053\n",
            "Epoch 19/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 6.8839e-04 - val_loss: 0.0053\n",
            "Epoch 20/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0017 - val_loss: 0.0053\n",
            "Epoch 21/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0015 - val_loss: 0.0054\n",
            "Epoch 22/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0018 - val_loss: 0.0053\n",
            "Epoch 23/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 9.0823e-04 - val_loss: 0.0053\n",
            "Epoch 24/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0016 - val_loss: 0.0053\n",
            "Epoch 25/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 8.3372e-04 - val_loss: 0.0054\n",
            "Epoch 26/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0011 - val_loss: 0.0055\n",
            "Epoch 27/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0011 - val_loss: 0.0054\n",
            "Epoch 28/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0013 - val_loss: 0.0055\n",
            "Epoch 29/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0018 - val_loss: 0.0054\n",
            "Epoch 30/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0014 - val_loss: 0.0055\n",
            "Epoch 31/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0015 - val_loss: 0.0055\n",
            "Epoch 32/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0014 - val_loss: 0.0053\n",
            "Epoch 33/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0015 - val_loss: 0.0054\n",
            "Epoch 34/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0012 - val_loss: 0.0054\n",
            "Epoch 35/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0013 - val_loss: 0.0053\n",
            "Epoch 36/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0014 - val_loss: 0.0053\n",
            "Epoch 37/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 9.0759e-04 - val_loss: 0.0053\n",
            "Epoch 38/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0016 - val_loss: 0.0053\n",
            "Epoch 39/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0011 - val_loss: 0.0053\n",
            "Epoch 40/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 7.5557e-04 - val_loss: 0.0053\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
            "MSE: 0.5941281719241566\n",
            "Training model with units=50, dropout=0.2, batch_size=64, epochs=40, optimizer=rmsprop\n",
            "Epoch 1/40\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - loss: 0.0170 - val_loss: 0.0056\n",
            "Epoch 2/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0025 - val_loss: 0.0057\n",
            "Epoch 3/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0016 - val_loss: 0.0058\n",
            "Epoch 4/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0023 - val_loss: 0.0056\n",
            "Epoch 5/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0022 - val_loss: 0.0058\n",
            "Epoch 6/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0017 - val_loss: 0.0054\n",
            "Epoch 7/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0018 - val_loss: 0.0053\n",
            "Epoch 8/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0019 - val_loss: 0.0054\n",
            "Epoch 9/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0016 - val_loss: 0.0057\n",
            "Epoch 10/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0019 - val_loss: 0.0055\n",
            "Epoch 11/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0019 - val_loss: 0.0052\n",
            "Epoch 12/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0024 - val_loss: 0.0053\n",
            "Epoch 13/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0012 - val_loss: 0.0053\n",
            "Epoch 14/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0014 - val_loss: 0.0054\n",
            "Epoch 15/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0017 - val_loss: 0.0053\n",
            "Epoch 16/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0016 - val_loss: 0.0054\n",
            "Epoch 17/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0017 - val_loss: 0.0062\n",
            "Epoch 18/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0028 - val_loss: 0.0059\n",
            "Epoch 19/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0014 - val_loss: 0.0053\n",
            "Epoch 20/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0020 - val_loss: 0.0054\n",
            "Epoch 21/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0017 - val_loss: 0.0057\n",
            "Epoch 22/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0014 - val_loss: 0.0054\n",
            "Epoch 23/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0017 - val_loss: 0.0055\n",
            "Epoch 24/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0015 - val_loss: 0.0060\n",
            "Epoch 25/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0019 - val_loss: 0.0056\n",
            "Epoch 26/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0016 - val_loss: 0.0053\n",
            "Epoch 27/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0019 - val_loss: 0.0057\n",
            "Epoch 28/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0015 - val_loss: 0.0057\n",
            "Epoch 29/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0023 - val_loss: 0.0054\n",
            "Epoch 30/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0014 - val_loss: 0.0057\n",
            "Epoch 31/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0028 - val_loss: 0.0053\n",
            "Epoch 32/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0020 - val_loss: 0.0054\n",
            "Epoch 33/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0012 - val_loss: 0.0055\n",
            "Epoch 34/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0011 - val_loss: 0.0053\n",
            "Epoch 35/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0016 - val_loss: 0.0059\n",
            "Epoch 36/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0015 - val_loss: 0.0054\n",
            "Epoch 37/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0015 - val_loss: 0.0055\n",
            "Epoch 38/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0023 - val_loss: 0.0056\n",
            "Epoch 39/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0017 - val_loss: 0.0053\n",
            "Epoch 40/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 9.1095e-04 - val_loss: 0.0058\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "MSE: 0.6483137540871898\n",
            "Training model with units=50, dropout=0.3, batch_size=32, epochs=20, optimizer=adam\n",
            "Epoch 1/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - loss: 0.0143 - val_loss: 0.0056\n",
            "Epoch 2/20\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0032 - val_loss: 0.0055\n",
            "Epoch 3/20\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0018 - val_loss: 0.0053\n",
            "Epoch 4/20\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0014 - val_loss: 0.0053\n",
            "Epoch 5/20\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0013 - val_loss: 0.0053\n",
            "Epoch 6/20\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0012 - val_loss: 0.0053\n",
            "Epoch 7/20\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0015 - val_loss: 0.0053\n",
            "Epoch 8/20\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0012 - val_loss: 0.0055\n",
            "Epoch 9/20\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0012 - val_loss: 0.0053\n",
            "Epoch 10/20\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0017 - val_loss: 0.0053\n",
            "Epoch 11/20\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0017 - val_loss: 0.0053\n",
            "Epoch 12/20\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0013 - val_loss: 0.0054\n",
            "Epoch 13/20\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0016 - val_loss: 0.0053\n",
            "Epoch 14/20\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0013 - val_loss: 0.0053\n",
            "Epoch 15/20\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0018 - val_loss: 0.0053\n",
            "Epoch 16/20\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0013 - val_loss: 0.0053\n",
            "Epoch 17/20\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0031 - val_loss: 0.0053\n",
            "Epoch 18/20\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0010 - val_loss: 0.0057\n",
            "Epoch 19/20\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0019 - val_loss: 0.0053\n",
            "Epoch 20/20\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0017 - val_loss: 0.0054\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
            "MSE: 0.6083279893719814\n",
            "Training model with units=50, dropout=0.3, batch_size=32, epochs=20, optimizer=rmsprop\n",
            "Epoch 1/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 0.0101 - val_loss: 0.0057\n",
            "Epoch 2/20\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0029 - val_loss: 0.0067\n",
            "Epoch 3/20\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0029 - val_loss: 0.0053\n",
            "Epoch 4/20\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0019 - val_loss: 0.0058\n",
            "Epoch 5/20\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0029 - val_loss: 0.0053\n",
            "Epoch 6/20\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0027 - val_loss: 0.0055\n",
            "Epoch 7/20\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0016 - val_loss: 0.0054\n",
            "Epoch 8/20\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0012 - val_loss: 0.0062\n",
            "Epoch 9/20\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0017 - val_loss: 0.0053\n",
            "Epoch 10/20\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0014 - val_loss: 0.0058\n",
            "Epoch 11/20\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0013 - val_loss: 0.0075\n",
            "Epoch 12/20\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0022 - val_loss: 0.0054\n",
            "Epoch 13/20\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0012 - val_loss: 0.0054\n",
            "Epoch 14/20\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0013 - val_loss: 0.0053\n",
            "Epoch 15/20\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0016 - val_loss: 0.0055\n",
            "Epoch 16/20\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0018 - val_loss: 0.0057\n",
            "Epoch 17/20\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0016 - val_loss: 0.0053\n",
            "Epoch 18/20\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0022 - val_loss: 0.0053\n",
            "Epoch 19/20\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0026 - val_loss: 0.0057\n",
            "Epoch 20/20\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0016 - val_loss: 0.0055\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step\n",
            "MSE: 0.6166914347217766\n",
            "Training model with units=50, dropout=0.3, batch_size=32, epochs=40, optimizer=adam\n",
            "Epoch 1/40\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - loss: 0.0188 - val_loss: 0.0057\n",
            "Epoch 2/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0027 - val_loss: 0.0055\n",
            "Epoch 3/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0020 - val_loss: 0.0054\n",
            "Epoch 4/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0018 - val_loss: 0.0054\n",
            "Epoch 5/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0018 - val_loss: 0.0053\n",
            "Epoch 6/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0015 - val_loss: 0.0054\n",
            "Epoch 7/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0015 - val_loss: 0.0053\n",
            "Epoch 8/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0013 - val_loss: 0.0053\n",
            "Epoch 9/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0017 - val_loss: 0.0054\n",
            "Epoch 10/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0026 - val_loss: 0.0054\n",
            "Epoch 11/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0014 - val_loss: 0.0053\n",
            "Epoch 12/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0020 - val_loss: 0.0053\n",
            "Epoch 13/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0013 - val_loss: 0.0053\n",
            "Epoch 14/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0015 - val_loss: 0.0055\n",
            "Epoch 15/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0013 - val_loss: 0.0055\n",
            "Epoch 16/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0012 - val_loss: 0.0053\n",
            "Epoch 17/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0019 - val_loss: 0.0054\n",
            "Epoch 18/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0014 - val_loss: 0.0054\n",
            "Epoch 19/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0016 - val_loss: 0.0053\n",
            "Epoch 20/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0018 - val_loss: 0.0053\n",
            "Epoch 21/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 9.7254e-04 - val_loss: 0.0053\n",
            "Epoch 22/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 7.9027e-04 - val_loss: 0.0053\n",
            "Epoch 23/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0011 - val_loss: 0.0054\n",
            "Epoch 24/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0014 - val_loss: 0.0054\n",
            "Epoch 25/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0012 - val_loss: 0.0055\n",
            "Epoch 26/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0010 - val_loss: 0.0054\n",
            "Epoch 27/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0019 - val_loss: 0.0053\n",
            "Epoch 28/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 9.0578e-04 - val_loss: 0.0054\n",
            "Epoch 29/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 8.9358e-04 - val_loss: 0.0053\n",
            "Epoch 30/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0011 - val_loss: 0.0054\n",
            "Epoch 31/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0012 - val_loss: 0.0054\n",
            "Epoch 32/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0011 - val_loss: 0.0054\n",
            "Epoch 33/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 9.7726e-04 - val_loss: 0.0055\n",
            "Epoch 34/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 9.5309e-04 - val_loss: 0.0054\n",
            "Epoch 35/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0012 - val_loss: 0.0054\n",
            "Epoch 36/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0010 - val_loss: 0.0055\n",
            "Epoch 37/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0010 - val_loss: 0.0054\n",
            "Epoch 38/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0010 - val_loss: 0.0054\n",
            "Epoch 39/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0016 - val_loss: 0.0054\n",
            "Epoch 40/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 6.1463e-04 - val_loss: 0.0054\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "MSE: 0.6025247603785286\n",
            "Training model with units=50, dropout=0.3, batch_size=32, epochs=40, optimizer=rmsprop\n",
            "Epoch 1/40\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 0.0158 - val_loss: 0.0059\n",
            "Epoch 2/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0030 - val_loss: 0.0056\n",
            "Epoch 3/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0021 - val_loss: 0.0054\n",
            "Epoch 4/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0016 - val_loss: 0.0071\n",
            "Epoch 5/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0036 - val_loss: 0.0053\n",
            "Epoch 6/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0014 - val_loss: 0.0063\n",
            "Epoch 7/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0023 - val_loss: 0.0054\n",
            "Epoch 8/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0016 - val_loss: 0.0053\n",
            "Epoch 9/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0015 - val_loss: 0.0062\n",
            "Epoch 10/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0021 - val_loss: 0.0053\n",
            "Epoch 11/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0021 - val_loss: 0.0053\n",
            "Epoch 12/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0012 - val_loss: 0.0056\n",
            "Epoch 13/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0012 - val_loss: 0.0053\n",
            "Epoch 14/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 9.7766e-04 - val_loss: 0.0053\n",
            "Epoch 15/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0014 - val_loss: 0.0054\n",
            "Epoch 16/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0021 - val_loss: 0.0053\n",
            "Epoch 17/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0016 - val_loss: 0.0055\n",
            "Epoch 18/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0018 - val_loss: 0.0054\n",
            "Epoch 19/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0012 - val_loss: 0.0053\n",
            "Epoch 20/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0013 - val_loss: 0.0056\n",
            "Epoch 21/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0019 - val_loss: 0.0053\n",
            "Epoch 22/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 9.6526e-04 - val_loss: 0.0055\n",
            "Epoch 23/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 9.0895e-04 - val_loss: 0.0056\n",
            "Epoch 24/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0014 - val_loss: 0.0055\n",
            "Epoch 25/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0018 - val_loss: 0.0057\n",
            "Epoch 26/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0012 - val_loss: 0.0055\n",
            "Epoch 27/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0016 - val_loss: 0.0055\n",
            "Epoch 28/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0011 - val_loss: 0.0053\n",
            "Epoch 29/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0011 - val_loss: 0.0053\n",
            "Epoch 30/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0016 - val_loss: 0.0053\n",
            "Epoch 31/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 6.3290e-04 - val_loss: 0.0054\n",
            "Epoch 32/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 8.3514e-04 - val_loss: 0.0054\n",
            "Epoch 33/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0010 - val_loss: 0.0053\n",
            "Epoch 34/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 7.3117e-04 - val_loss: 0.0053\n",
            "Epoch 35/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0017 - val_loss: 0.0054\n",
            "Epoch 36/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 9.8006e-04 - val_loss: 0.0053\n",
            "Epoch 37/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0013 - val_loss: 0.0054\n",
            "Epoch 38/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0010 - val_loss: 0.0054\n",
            "Epoch 39/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 9.1169e-04 - val_loss: 0.0054\n",
            "Epoch 40/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 6.7346e-04 - val_loss: 0.0054\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "MSE: 0.6045664059583391\n",
            "Training model with units=50, dropout=0.3, batch_size=64, epochs=20, optimizer=adam\n",
            "Epoch 1/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - loss: 0.0351 - val_loss: 0.0078\n",
            "Epoch 2/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0045 - val_loss: 0.0058\n",
            "Epoch 3/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0032 - val_loss: 0.0059\n",
            "Epoch 4/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0029 - val_loss: 0.0055\n",
            "Epoch 5/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0020 - val_loss: 0.0054\n",
            "Epoch 6/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0019 - val_loss: 0.0055\n",
            "Epoch 7/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0021 - val_loss: 0.0053\n",
            "Epoch 8/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0019 - val_loss: 0.0053\n",
            "Epoch 9/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0018 - val_loss: 0.0053\n",
            "Epoch 10/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0014 - val_loss: 0.0053\n",
            "Epoch 11/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0015 - val_loss: 0.0053\n",
            "Epoch 12/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0014 - val_loss: 0.0053\n",
            "Epoch 13/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0014 - val_loss: 0.0053\n",
            "Epoch 14/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0022 - val_loss: 0.0053\n",
            "Epoch 15/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0013 - val_loss: 0.0053\n",
            "Epoch 16/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0017 - val_loss: 0.0053\n",
            "Epoch 17/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0013 - val_loss: 0.0053\n",
            "Epoch 18/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0013 - val_loss: 0.0053\n",
            "Epoch 19/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0021 - val_loss: 0.0054\n",
            "Epoch 20/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0019 - val_loss: 0.0053\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "MSE: 0.5918557986864238\n",
            "Training model with units=50, dropout=0.3, batch_size=64, epochs=20, optimizer=rmsprop\n",
            "Epoch 1/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - loss: 0.0155 - val_loss: 0.0060\n",
            "Epoch 2/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0031 - val_loss: 0.0061\n",
            "Epoch 3/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0031 - val_loss: 0.0054\n",
            "Epoch 4/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0022 - val_loss: 0.0057\n",
            "Epoch 5/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0020 - val_loss: 0.0060\n",
            "Epoch 6/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0020 - val_loss: 0.0059\n",
            "Epoch 7/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0023 - val_loss: 0.0057\n",
            "Epoch 8/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0028 - val_loss: 0.0053\n",
            "Epoch 9/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0016 - val_loss: 0.0069\n",
            "Epoch 10/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0031 - val_loss: 0.0053\n",
            "Epoch 11/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0021 - val_loss: 0.0054\n",
            "Epoch 12/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0019 - val_loss: 0.0057\n",
            "Epoch 13/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0018 - val_loss: 0.0053\n",
            "Epoch 14/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0017 - val_loss: 0.0057\n",
            "Epoch 15/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0018 - val_loss: 0.0062\n",
            "Epoch 16/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0020 - val_loss: 0.0053\n",
            "Epoch 17/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0017 - val_loss: 0.0054\n",
            "Epoch 18/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0020 - val_loss: 0.0053\n",
            "Epoch 19/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0013 - val_loss: 0.0067\n",
            "Epoch 20/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0017 - val_loss: 0.0053\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
            "MSE: 0.5902438667946509\n",
            "Training model with units=50, dropout=0.3, batch_size=64, epochs=40, optimizer=adam\n",
            "Epoch 1/40\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - loss: 0.0369 - val_loss: 0.0083\n",
            "Epoch 2/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0041 - val_loss: 0.0058\n",
            "Epoch 3/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0029 - val_loss: 0.0060\n",
            "Epoch 4/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0025 - val_loss: 0.0056\n",
            "Epoch 5/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0019 - val_loss: 0.0054\n",
            "Epoch 6/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0022 - val_loss: 0.0053\n",
            "Epoch 7/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0022 - val_loss: 0.0053\n",
            "Epoch 8/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0016 - val_loss: 0.0053\n",
            "Epoch 9/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0021 - val_loss: 0.0053\n",
            "Epoch 10/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0014 - val_loss: 0.0053\n",
            "Epoch 11/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0016 - val_loss: 0.0053\n",
            "Epoch 12/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0014 - val_loss: 0.0053\n",
            "Epoch 13/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0013 - val_loss: 0.0053\n",
            "Epoch 14/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0011 - val_loss: 0.0053\n",
            "Epoch 15/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0013 - val_loss: 0.0053\n",
            "Epoch 16/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0016 - val_loss: 0.0053\n",
            "Epoch 17/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0016 - val_loss: 0.0054\n",
            "Epoch 18/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0015 - val_loss: 0.0053\n",
            "Epoch 19/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0019 - val_loss: 0.0053\n",
            "Epoch 20/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0016 - val_loss: 0.0053\n",
            "Epoch 21/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0013 - val_loss: 0.0053\n",
            "Epoch 22/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0016 - val_loss: 0.0053\n",
            "Epoch 23/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0015 - val_loss: 0.0053\n",
            "Epoch 24/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0012 - val_loss: 0.0053\n",
            "Epoch 25/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 8.7467e-04 - val_loss: 0.0053\n",
            "Epoch 26/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0012 - val_loss: 0.0054\n",
            "Epoch 27/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0014 - val_loss: 0.0054\n",
            "Epoch 28/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0017 - val_loss: 0.0053\n",
            "Epoch 29/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0014 - val_loss: 0.0053\n",
            "Epoch 30/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0011 - val_loss: 0.0053\n",
            "Epoch 31/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0013 - val_loss: 0.0055\n",
            "Epoch 32/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0021 - val_loss: 0.0056\n",
            "Epoch 33/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0012 - val_loss: 0.0055\n",
            "Epoch 34/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0012 - val_loss: 0.0054\n",
            "Epoch 35/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0013 - val_loss: 0.0054\n",
            "Epoch 36/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 9.5767e-04 - val_loss: 0.0053\n",
            "Epoch 37/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0021 - val_loss: 0.0054\n",
            "Epoch 38/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0014 - val_loss: 0.0055\n",
            "Epoch 39/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0016 - val_loss: 0.0054\n",
            "Epoch 40/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0013 - val_loss: 0.0054\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
            "MSE: 0.5993259657752322\n",
            "Training model with units=50, dropout=0.3, batch_size=64, epochs=40, optimizer=rmsprop\n",
            "Epoch 1/40\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 35ms/step - loss: 0.0093 - val_loss: 0.0084\n",
            "Epoch 2/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0036 - val_loss: 0.0069\n",
            "Epoch 3/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0027 - val_loss: 0.0069\n",
            "Epoch 4/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0022 - val_loss: 0.0074\n",
            "Epoch 5/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0027 - val_loss: 0.0053\n",
            "Epoch 6/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0015 - val_loss: 0.0054\n",
            "Epoch 7/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0020 - val_loss: 0.0067\n",
            "Epoch 8/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0023 - val_loss: 0.0054\n",
            "Epoch 9/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0024 - val_loss: 0.0054\n",
            "Epoch 10/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0012 - val_loss: 0.0056\n",
            "Epoch 11/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0020 - val_loss: 0.0063\n",
            "Epoch 12/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0019 - val_loss: 0.0056\n",
            "Epoch 13/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0019 - val_loss: 0.0054\n",
            "Epoch 14/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0015 - val_loss: 0.0053\n",
            "Epoch 15/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0035 - val_loss: 0.0054\n",
            "Epoch 16/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0021 - val_loss: 0.0055\n",
            "Epoch 17/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0023 - val_loss: 0.0053\n",
            "Epoch 18/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0021 - val_loss: 0.0055\n",
            "Epoch 19/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0024 - val_loss: 0.0061\n",
            "Epoch 20/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0016 - val_loss: 0.0054\n",
            "Epoch 21/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0024 - val_loss: 0.0053\n",
            "Epoch 22/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0015 - val_loss: 0.0056\n",
            "Epoch 23/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0011 - val_loss: 0.0057\n",
            "Epoch 24/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0025 - val_loss: 0.0053\n",
            "Epoch 25/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0020 - val_loss: 0.0055\n",
            "Epoch 26/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0014 - val_loss: 0.0053\n",
            "Epoch 27/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0015 - val_loss: 0.0053\n",
            "Epoch 28/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0022 - val_loss: 0.0073\n",
            "Epoch 29/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0025 - val_loss: 0.0053\n",
            "Epoch 30/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0013 - val_loss: 0.0055\n",
            "Epoch 31/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0014 - val_loss: 0.0056\n",
            "Epoch 32/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0019 - val_loss: 0.0054\n",
            "Epoch 33/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0016 - val_loss: 0.0053\n",
            "Epoch 34/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0010 - val_loss: 0.0056\n",
            "Epoch 35/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0014 - val_loss: 0.0053\n",
            "Epoch 36/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 9.5328e-04 - val_loss: 0.0055\n",
            "Epoch 37/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0017 - val_loss: 0.0055\n",
            "Epoch 38/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 9.3745e-04 - val_loss: 0.0054\n",
            "Epoch 39/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0017 - val_loss: 0.0054\n",
            "Epoch 40/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0014 - val_loss: 0.0054\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
            "MSE: 0.6074929418462699\n",
            "Training model with units=100, dropout=0.2, batch_size=32, epochs=20, optimizer=adam\n",
            "Epoch 1/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - loss: 0.0202 - val_loss: 0.0067\n",
            "Epoch 2/20\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0016 - val_loss: 0.0055\n",
            "Epoch 3/20\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0018 - val_loss: 0.0053\n",
            "Epoch 4/20\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0021 - val_loss: 0.0054\n",
            "Epoch 5/20\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 8.1626e-04 - val_loss: 0.0053\n",
            "Epoch 6/20\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0016 - val_loss: 0.0053\n",
            "Epoch 7/20\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0018 - val_loss: 0.0053\n",
            "Epoch 8/20\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0012 - val_loss: 0.0053\n",
            "Epoch 9/20\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 9.5231e-04 - val_loss: 0.0054\n",
            "Epoch 10/20\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0013 - val_loss: 0.0053\n",
            "Epoch 11/20\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0013 - val_loss: 0.0054\n",
            "Epoch 12/20\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0011 - val_loss: 0.0054\n",
            "Epoch 13/20\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0010 - val_loss: 0.0053\n",
            "Epoch 14/20\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0017 - val_loss: 0.0055\n",
            "Epoch 15/20\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0011 - val_loss: 0.0055\n",
            "Epoch 16/20\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0026 - val_loss: 0.0053\n",
            "Epoch 17/20\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0015 - val_loss: 0.0054\n",
            "Epoch 18/20\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0014 - val_loss: 0.0054\n",
            "Epoch 19/20\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0023 - val_loss: 0.0055\n",
            "Epoch 20/20\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 7.0605e-04 - val_loss: 0.0054\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
            "MSE: 0.6006517933886489\n",
            "Training model with units=100, dropout=0.2, batch_size=32, epochs=20, optimizer=rmsprop\n",
            "Epoch 1/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 0.0103 - val_loss: 0.0055\n",
            "Epoch 2/20\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0026 - val_loss: 0.0071\n",
            "Epoch 3/20\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0019 - val_loss: 0.0072\n",
            "Epoch 4/20\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0035 - val_loss: 0.0054\n",
            "Epoch 5/20\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0017 - val_loss: 0.0054\n",
            "Epoch 6/20\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0012 - val_loss: 0.0054\n",
            "Epoch 7/20\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0010 - val_loss: 0.0060\n",
            "Epoch 8/20\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0018 - val_loss: 0.0053\n",
            "Epoch 9/20\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0024 - val_loss: 0.0056\n",
            "Epoch 10/20\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0018 - val_loss: 0.0057\n",
            "Epoch 11/20\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0014 - val_loss: 0.0055\n",
            "Epoch 12/20\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0010 - val_loss: 0.0053\n",
            "Epoch 13/20\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0018 - val_loss: 0.0053\n",
            "Epoch 14/20\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0020 - val_loss: 0.0053\n",
            "Epoch 15/20\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 8.7373e-04 - val_loss: 0.0055\n",
            "Epoch 16/20\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 9.2651e-04 - val_loss: 0.0053\n",
            "Epoch 17/20\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 7.9724e-04 - val_loss: 0.0053\n",
            "Epoch 18/20\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0017 - val_loss: 0.0054\n",
            "Epoch 19/20\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 8.9249e-04 - val_loss: 0.0054\n",
            "Epoch 20/20\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0021 - val_loss: 0.0054\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "MSE: 0.6057624148683368\n",
            "Training model with units=100, dropout=0.2, batch_size=32, epochs=40, optimizer=adam\n",
            "Epoch 1/40\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 0.0168 - val_loss: 0.0057\n",
            "Epoch 2/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0012 - val_loss: 0.0054\n",
            "Epoch 3/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0017 - val_loss: 0.0053\n",
            "Epoch 4/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0019 - val_loss: 0.0053\n",
            "Epoch 5/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0011 - val_loss: 0.0054\n",
            "Epoch 6/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 8.5472e-04 - val_loss: 0.0053\n",
            "Epoch 7/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 9.2259e-04 - val_loss: 0.0053\n",
            "Epoch 8/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0011 - val_loss: 0.0054\n",
            "Epoch 9/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 9.5508e-04 - val_loss: 0.0053\n",
            "Epoch 10/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 9.4766e-04 - val_loss: 0.0055\n",
            "Epoch 11/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 9.6890e-04 - val_loss: 0.0054\n",
            "Epoch 12/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0021 - val_loss: 0.0055\n",
            "Epoch 13/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0015 - val_loss: 0.0053\n",
            "Epoch 14/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 9.7966e-04 - val_loss: 0.0055\n",
            "Epoch 15/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 9.4557e-04 - val_loss: 0.0054\n",
            "Epoch 16/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0015 - val_loss: 0.0054\n",
            "Epoch 17/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0017 - val_loss: 0.0054\n",
            "Epoch 18/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0018 - val_loss: 0.0054\n",
            "Epoch 19/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0016 - val_loss: 0.0055\n",
            "Epoch 20/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0015 - val_loss: 0.0055\n",
            "Epoch 21/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0011 - val_loss: 0.0054\n",
            "Epoch 22/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0017 - val_loss: 0.0054\n",
            "Epoch 23/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0010 - val_loss: 0.0055\n",
            "Epoch 24/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 8.8537e-04 - val_loss: 0.0054\n",
            "Epoch 25/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0011 - val_loss: 0.0054\n",
            "Epoch 26/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 9.8661e-04 - val_loss: 0.0054\n",
            "Epoch 27/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 8.6784e-04 - val_loss: 0.0055\n",
            "Epoch 28/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0017 - val_loss: 0.0054\n",
            "Epoch 29/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0011 - val_loss: 0.0055\n",
            "Epoch 30/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0010 - val_loss: 0.0054\n",
            "Epoch 31/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 6.1312e-04 - val_loss: 0.0054\n",
            "Epoch 32/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0015 - val_loss: 0.0054\n",
            "Epoch 33/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0012 - val_loss: 0.0054\n",
            "Epoch 34/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 7.0058e-04 - val_loss: 0.0054\n",
            "Epoch 35/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 8.2709e-04 - val_loss: 0.0054\n",
            "Epoch 36/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 8.1750e-04 - val_loss: 0.0054\n",
            "Epoch 37/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 8.0940e-04 - val_loss: 0.0053\n",
            "Epoch 38/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0016 - val_loss: 0.0053\n",
            "Epoch 39/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0011 - val_loss: 0.0053\n",
            "Epoch 40/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 9.2854e-04 - val_loss: 0.0053\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "MSE: 0.5975169349128068\n",
            "Training model with units=100, dropout=0.2, batch_size=32, epochs=40, optimizer=rmsprop\n",
            "Epoch 1/40\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - loss: 0.0106 - val_loss: 0.0059\n",
            "Epoch 2/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0024 - val_loss: 0.0059\n",
            "Epoch 3/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0015 - val_loss: 0.0053\n",
            "Epoch 4/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0014 - val_loss: 0.0076\n",
            "Epoch 5/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0025 - val_loss: 0.0063\n",
            "Epoch 6/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0017 - val_loss: 0.0053\n",
            "Epoch 7/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0015 - val_loss: 0.0058\n",
            "Epoch 8/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0017 - val_loss: 0.0058\n",
            "Epoch 9/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0012 - val_loss: 0.0053\n",
            "Epoch 10/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0022 - val_loss: 0.0063\n",
            "Epoch 11/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0015 - val_loss: 0.0056\n",
            "Epoch 12/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0024 - val_loss: 0.0053\n",
            "Epoch 13/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0014 - val_loss: 0.0053\n",
            "Epoch 14/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0011 - val_loss: 0.0056\n",
            "Epoch 15/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0019 - val_loss: 0.0053\n",
            "Epoch 16/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0013 - val_loss: 0.0054\n",
            "Epoch 17/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0012 - val_loss: 0.0055\n",
            "Epoch 18/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0015 - val_loss: 0.0054\n",
            "Epoch 19/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0012 - val_loss: 0.0056\n",
            "Epoch 20/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0021 - val_loss: 0.0055\n",
            "Epoch 21/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0023 - val_loss: 0.0055\n",
            "Epoch 22/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 7.3768e-04 - val_loss: 0.0054\n",
            "Epoch 23/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0013 - val_loss: 0.0056\n",
            "Epoch 24/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0015 - val_loss: 0.0060\n",
            "Epoch 25/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0010 - val_loss: 0.0057\n",
            "Epoch 26/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0010 - val_loss: 0.0053\n",
            "Epoch 27/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0012 - val_loss: 0.0055\n",
            "Epoch 28/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 8.7264e-04 - val_loss: 0.0054\n",
            "Epoch 29/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0017 - val_loss: 0.0055\n",
            "Epoch 30/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0014 - val_loss: 0.0057\n",
            "Epoch 31/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0013 - val_loss: 0.0054\n",
            "Epoch 32/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0016 - val_loss: 0.0055\n",
            "Epoch 33/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0020 - val_loss: 0.0057\n",
            "Epoch 34/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 9.0330e-04 - val_loss: 0.0054\n",
            "Epoch 35/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 8.2566e-04 - val_loss: 0.0055\n",
            "Epoch 36/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0010 - val_loss: 0.0054\n",
            "Epoch 37/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0015 - val_loss: 0.0058\n",
            "Epoch 38/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 7.6971e-04 - val_loss: 0.0054\n",
            "Epoch 39/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0018 - val_loss: 0.0056\n",
            "Epoch 40/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0014 - val_loss: 0.0054\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "MSE: 0.6014831979633403\n",
            "Training model with units=100, dropout=0.2, batch_size=64, epochs=20, optimizer=adam\n",
            "Epoch 1/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 53ms/step - loss: 0.0257 - val_loss: 0.0076\n",
            "Epoch 2/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0032 - val_loss: 0.0059\n",
            "Epoch 3/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0019 - val_loss: 0.0055\n",
            "Epoch 4/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0014 - val_loss: 0.0054\n",
            "Epoch 5/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0017 - val_loss: 0.0053\n",
            "Epoch 6/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 9.7524e-04 - val_loss: 0.0053\n",
            "Epoch 7/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0012 - val_loss: 0.0054\n",
            "Epoch 8/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 9.4096e-04 - val_loss: 0.0054\n",
            "Epoch 9/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0012 - val_loss: 0.0053\n",
            "Epoch 10/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0014 - val_loss: 0.0053\n",
            "Epoch 11/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0014 - val_loss: 0.0054\n",
            "Epoch 12/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 8.7549e-04 - val_loss: 0.0053\n",
            "Epoch 13/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0019 - val_loss: 0.0054\n",
            "Epoch 14/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 7.5633e-04 - val_loss: 0.0053\n",
            "Epoch 15/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0015 - val_loss: 0.0053\n",
            "Epoch 16/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0017 - val_loss: 0.0053\n",
            "Epoch 17/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 9.0314e-04 - val_loss: 0.0053\n",
            "Epoch 18/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0011 - val_loss: 0.0055\n",
            "Epoch 19/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 9.5325e-04 - val_loss: 0.0054\n",
            "Epoch 20/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0018 - val_loss: 0.0053\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
            "MSE: 0.5974490407135127\n",
            "Training model with units=100, dropout=0.2, batch_size=64, epochs=20, optimizer=rmsprop\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - loss: 0.0179 - val_loss: 0.0065\n",
            "Epoch 2/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0022 - val_loss: 0.0060\n",
            "Epoch 3/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0020 - val_loss: 0.0057\n",
            "Epoch 4/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0020 - val_loss: 0.0089\n",
            "Epoch 5/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0043 - val_loss: 0.0064\n",
            "Epoch 6/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0024 - val_loss: 0.0054\n",
            "Epoch 7/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0016 - val_loss: 0.0053\n",
            "Epoch 8/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0012 - val_loss: 0.0053\n",
            "Epoch 9/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0021 - val_loss: 0.0054\n",
            "Epoch 10/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0030 - val_loss: 0.0053\n",
            "Epoch 11/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0011 - val_loss: 0.0057\n",
            "Epoch 12/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0020 - val_loss: 0.0053\n",
            "Epoch 13/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0011 - val_loss: 0.0062\n",
            "Epoch 14/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0027 - val_loss: 0.0055\n",
            "Epoch 15/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0017 - val_loss: 0.0053\n",
            "Epoch 16/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0019 - val_loss: 0.0057\n",
            "Epoch 17/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0013 - val_loss: 0.0060\n",
            "Epoch 18/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0021 - val_loss: 0.0059\n",
            "Epoch 19/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0017 - val_loss: 0.0053\n",
            "Epoch 20/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0012 - val_loss: 0.0054\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step\n",
            "MSE: 0.6033955233179206\n",
            "Training model with units=100, dropout=0.2, batch_size=64, epochs=40, optimizer=adam\n",
            "Epoch 1/40\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 37ms/step - loss: 0.0269 - val_loss: 0.0073\n",
            "Epoch 2/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0036 - val_loss: 0.0067\n",
            "Epoch 3/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0019 - val_loss: 0.0056\n",
            "Epoch 4/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0013 - val_loss: 0.0054\n",
            "Epoch 5/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0018 - val_loss: 0.0053\n",
            "Epoch 6/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0013 - val_loss: 0.0053\n",
            "Epoch 7/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0013 - val_loss: 0.0054\n",
            "Epoch 8/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0014 - val_loss: 0.0055\n",
            "Epoch 9/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0012 - val_loss: 0.0053\n",
            "Epoch 10/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0014 - val_loss: 0.0054\n",
            "Epoch 11/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0012 - val_loss: 0.0054\n",
            "Epoch 12/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0014 - val_loss: 0.0054\n",
            "Epoch 13/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0011 - val_loss: 0.0055\n",
            "Epoch 14/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0016 - val_loss: 0.0053\n",
            "Epoch 15/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0014 - val_loss: 0.0053\n",
            "Epoch 16/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 7.0780e-04 - val_loss: 0.0055\n",
            "Epoch 17/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0016 - val_loss: 0.0053\n",
            "Epoch 18/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0019 - val_loss: 0.0054\n",
            "Epoch 19/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 8.2256e-04 - val_loss: 0.0054\n",
            "Epoch 20/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0012 - val_loss: 0.0054\n",
            "Epoch 21/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0012 - val_loss: 0.0053\n",
            "Epoch 22/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 6.9059e-04 - val_loss: 0.0053\n",
            "Epoch 23/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0012 - val_loss: 0.0054\n",
            "Epoch 24/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8.3476e-04 - val_loss: 0.0053\n",
            "Epoch 25/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0012 - val_loss: 0.0054\n",
            "Epoch 26/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0012 - val_loss: 0.0054\n",
            "Epoch 27/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 5.4349e-04 - val_loss: 0.0054\n",
            "Epoch 28/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 8.6100e-04 - val_loss: 0.0055\n",
            "Epoch 29/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0010 - val_loss: 0.0054\n",
            "Epoch 30/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 7.0869e-04 - val_loss: 0.0054\n",
            "Epoch 31/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 5.4495e-04 - val_loss: 0.0054\n",
            "Epoch 32/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 6.6062e-04 - val_loss: 0.0054\n",
            "Epoch 33/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0012 - val_loss: 0.0054\n",
            "Epoch 34/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 7.0857e-04 - val_loss: 0.0054\n",
            "Epoch 35/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 8.6770e-04 - val_loss: 0.0055\n",
            "Epoch 36/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0021 - val_loss: 0.0054\n",
            "Epoch 37/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 9.4359e-04 - val_loss: 0.0054\n",
            "Epoch 38/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 9.0778e-04 - val_loss: 0.0054\n",
            "Epoch 39/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 6.8394e-04 - val_loss: 0.0054\n",
            "Epoch 40/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0012 - val_loss: 0.0054\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
            "MSE: 0.6028017216263205\n",
            "Training model with units=100, dropout=0.2, batch_size=64, epochs=40, optimizer=rmsprop\n",
            "Epoch 1/40\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 35ms/step - loss: 0.0137 - val_loss: 0.0067\n",
            "Epoch 2/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0030 - val_loss: 0.0065\n",
            "Epoch 3/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0030 - val_loss: 0.0054\n",
            "Epoch 4/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0019 - val_loss: 0.0055\n",
            "Epoch 5/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0014 - val_loss: 0.0057\n",
            "Epoch 6/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0015 - val_loss: 0.0068\n",
            "Epoch 7/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0029 - val_loss: 0.0057\n",
            "Epoch 8/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0025 - val_loss: 0.0055\n",
            "Epoch 9/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0017 - val_loss: 0.0055\n",
            "Epoch 10/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0012 - val_loss: 0.0064\n",
            "Epoch 11/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0013 - val_loss: 0.0054\n",
            "Epoch 12/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0012 - val_loss: 0.0053\n",
            "Epoch 13/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0016 - val_loss: 0.0056\n",
            "Epoch 14/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0019 - val_loss: 0.0053\n",
            "Epoch 15/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0013 - val_loss: 0.0063\n",
            "Epoch 16/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0023 - val_loss: 0.0053\n",
            "Epoch 17/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0020 - val_loss: 0.0053\n",
            "Epoch 18/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0015 - val_loss: 0.0053\n",
            "Epoch 19/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 8.8488e-04 - val_loss: 0.0072\n",
            "Epoch 20/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0013 - val_loss: 0.0063\n",
            "Epoch 21/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0018 - val_loss: 0.0055\n",
            "Epoch 22/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0021 - val_loss: 0.0053\n",
            "Epoch 23/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0016 - val_loss: 0.0053\n",
            "Epoch 24/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0010 - val_loss: 0.0055\n",
            "Epoch 25/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0012 - val_loss: 0.0053\n",
            "Epoch 26/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0012 - val_loss: 0.0053\n",
            "Epoch 27/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 9.4241e-04 - val_loss: 0.0057\n",
            "Epoch 28/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0014 - val_loss: 0.0055\n",
            "Epoch 29/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0014 - val_loss: 0.0054\n",
            "Epoch 30/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0013 - val_loss: 0.0071\n",
            "Epoch 31/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0030 - val_loss: 0.0059\n",
            "Epoch 32/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0024 - val_loss: 0.0057\n",
            "Epoch 33/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0011 - val_loss: 0.0053\n",
            "Epoch 34/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 7.3222e-04 - val_loss: 0.0054\n",
            "Epoch 35/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0019 - val_loss: 0.0054\n",
            "Epoch 36/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0022 - val_loss: 0.0055\n",
            "Epoch 37/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0011 - val_loss: 0.0054\n",
            "Epoch 38/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0012 - val_loss: 0.0055\n",
            "Epoch 39/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0011 - val_loss: 0.0055\n",
            "Epoch 40/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0014 - val_loss: 0.0058\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
            "MSE: 0.6518199304060767\n",
            "Training model with units=100, dropout=0.3, batch_size=32, epochs=20, optimizer=adam\n",
            "Epoch 1/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - loss: 0.0152 - val_loss: 0.0057\n",
            "Epoch 2/20\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0016 - val_loss: 0.0054\n",
            "Epoch 3/20\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0023 - val_loss: 0.0053\n",
            "Epoch 4/20\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0011 - val_loss: 0.0053\n",
            "Epoch 5/20\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0012 - val_loss: 0.0054\n",
            "Epoch 6/20\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0018 - val_loss: 0.0054\n",
            "Epoch 7/20\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0013 - val_loss: 0.0053\n",
            "Epoch 8/20\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0017 - val_loss: 0.0054\n",
            "Epoch 9/20\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 9.6150e-04 - val_loss: 0.0054\n",
            "Epoch 10/20\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0022 - val_loss: 0.0054\n",
            "Epoch 11/20\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0014 - val_loss: 0.0054\n",
            "Epoch 12/20\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 8.5788e-04 - val_loss: 0.0056\n",
            "Epoch 13/20\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0017 - val_loss: 0.0054\n",
            "Epoch 14/20\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0017 - val_loss: 0.0054\n",
            "Epoch 15/20\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0012 - val_loss: 0.0054\n",
            "Epoch 16/20\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0013 - val_loss: 0.0054\n",
            "Epoch 17/20\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0014 - val_loss: 0.0054\n",
            "Epoch 18/20\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0017 - val_loss: 0.0054\n",
            "Epoch 19/20\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 8.7016e-04 - val_loss: 0.0054\n",
            "Epoch 20/20\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0016 - val_loss: 0.0054\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "MSE: 0.6031809145260453\n",
            "Training model with units=100, dropout=0.3, batch_size=32, epochs=20, optimizer=rmsprop\n",
            "Epoch 1/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 0.0121 - val_loss: 0.0059\n",
            "Epoch 2/20\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0029 - val_loss: 0.0078\n",
            "Epoch 3/20\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0029 - val_loss: 0.0053\n",
            "Epoch 4/20\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0023 - val_loss: 0.0064\n",
            "Epoch 5/20\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0022 - val_loss: 0.0055\n",
            "Epoch 6/20\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0014 - val_loss: 0.0053\n",
            "Epoch 7/20\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0015 - val_loss: 0.0053\n",
            "Epoch 8/20\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0021 - val_loss: 0.0053\n",
            "Epoch 9/20\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0014 - val_loss: 0.0056\n",
            "Epoch 10/20\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0015 - val_loss: 0.0054\n",
            "Epoch 11/20\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0013 - val_loss: 0.0058\n",
            "Epoch 12/20\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0031 - val_loss: 0.0053\n",
            "Epoch 13/20\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0012 - val_loss: 0.0053\n",
            "Epoch 14/20\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0012 - val_loss: 0.0056\n",
            "Epoch 15/20\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0011 - val_loss: 0.0059\n",
            "Epoch 16/20\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0011 - val_loss: 0.0055\n",
            "Epoch 17/20\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0011 - val_loss: 0.0055\n",
            "Epoch 18/20\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0015 - val_loss: 0.0055\n",
            "Epoch 19/20\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0014 - val_loss: 0.0058\n",
            "Epoch 20/20\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0013 - val_loss: 0.0053\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
            "MSE: 0.5945998868385353\n",
            "Training model with units=100, dropout=0.3, batch_size=32, epochs=40, optimizer=adam\n",
            "Epoch 1/40\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 0.0195 - val_loss: 0.0062\n",
            "Epoch 2/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0016 - val_loss: 0.0054\n",
            "Epoch 3/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0010 - val_loss: 0.0054\n",
            "Epoch 4/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0013 - val_loss: 0.0053\n",
            "Epoch 5/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0019 - val_loss: 0.0053\n",
            "Epoch 6/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0010 - val_loss: 0.0057\n",
            "Epoch 7/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0011 - val_loss: 0.0055\n",
            "Epoch 8/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0014 - val_loss: 0.0053\n",
            "Epoch 9/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0015 - val_loss: 0.0056\n",
            "Epoch 10/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0021 - val_loss: 0.0053\n",
            "Epoch 11/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0012 - val_loss: 0.0053\n",
            "Epoch 12/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 6.4411e-04 - val_loss: 0.0054\n",
            "Epoch 13/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0012 - val_loss: 0.0054\n",
            "Epoch 14/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0012 - val_loss: 0.0054\n",
            "Epoch 15/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0010 - val_loss: 0.0054\n",
            "Epoch 16/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0017 - val_loss: 0.0054\n",
            "Epoch 17/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0013 - val_loss: 0.0054\n",
            "Epoch 18/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0010 - val_loss: 0.0056\n",
            "Epoch 19/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0018 - val_loss: 0.0055\n",
            "Epoch 20/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0022 - val_loss: 0.0055\n",
            "Epoch 21/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0014 - val_loss: 0.0054\n",
            "Epoch 22/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0013 - val_loss: 0.0055\n",
            "Epoch 23/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0016 - val_loss: 0.0054\n",
            "Epoch 24/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 9.5658e-04 - val_loss: 0.0054\n",
            "Epoch 25/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 6.8651e-04 - val_loss: 0.0054\n",
            "Epoch 26/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0017 - val_loss: 0.0055\n",
            "Epoch 27/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 9.3410e-04 - val_loss: 0.0054\n",
            "Epoch 28/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0016 - val_loss: 0.0054\n",
            "Epoch 29/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 9.4717e-04 - val_loss: 0.0054\n",
            "Epoch 30/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 9.3496e-04 - val_loss: 0.0054\n",
            "Epoch 31/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0014 - val_loss: 0.0054\n",
            "Epoch 32/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 6.6271e-04 - val_loss: 0.0054\n",
            "Epoch 33/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 7.3198e-04 - val_loss: 0.0055\n",
            "Epoch 34/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 8.5912e-04 - val_loss: 0.0054\n",
            "Epoch 35/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 8.6881e-04 - val_loss: 0.0053\n",
            "Epoch 36/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 8.0393e-04 - val_loss: 0.0055\n",
            "Epoch 37/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0013 - val_loss: 0.0053\n",
            "Epoch 38/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 8.4095e-04 - val_loss: 0.0054\n",
            "Epoch 39/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0015 - val_loss: 0.0054\n",
            "Epoch 40/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0016 - val_loss: 0.0054\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "MSE: 0.6013616458475329\n",
            "Training model with units=100, dropout=0.3, batch_size=32, epochs=40, optimizer=rmsprop\n",
            "Epoch 1/40\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 0.0122 - val_loss: 0.0055\n",
            "Epoch 2/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0017 - val_loss: 0.0060\n",
            "Epoch 3/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0024 - val_loss: 0.0058\n",
            "Epoch 4/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0017 - val_loss: 0.0053\n",
            "Epoch 5/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0014 - val_loss: 0.0060\n",
            "Epoch 6/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0014 - val_loss: 0.0053\n",
            "Epoch 7/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0015 - val_loss: 0.0053\n",
            "Epoch 8/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0021 - val_loss: 0.0053\n",
            "Epoch 9/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0022 - val_loss: 0.0055\n",
            "Epoch 10/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0013 - val_loss: 0.0053\n",
            "Epoch 11/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0019 - val_loss: 0.0061\n",
            "Epoch 12/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0012 - val_loss: 0.0053\n",
            "Epoch 13/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0016 - val_loss: 0.0062\n",
            "Epoch 14/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0014 - val_loss: 0.0056\n",
            "Epoch 15/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0013 - val_loss: 0.0055\n",
            "Epoch 16/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0010 - val_loss: 0.0054\n",
            "Epoch 17/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0020 - val_loss: 0.0053\n",
            "Epoch 18/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0010 - val_loss: 0.0054\n",
            "Epoch 19/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0020 - val_loss: 0.0054\n",
            "Epoch 20/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0011 - val_loss: 0.0053\n",
            "Epoch 21/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 9.6310e-04 - val_loss: 0.0055\n",
            "Epoch 22/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0021 - val_loss: 0.0054\n",
            "Epoch 23/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0010 - val_loss: 0.0065\n",
            "Epoch 24/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0027 - val_loss: 0.0054\n",
            "Epoch 25/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0015 - val_loss: 0.0057\n",
            "Epoch 26/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0020 - val_loss: 0.0056\n",
            "Epoch 27/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0011 - val_loss: 0.0060\n",
            "Epoch 28/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0024 - val_loss: 0.0054\n",
            "Epoch 29/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 7.5899e-04 - val_loss: 0.0054\n",
            "Epoch 30/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0013 - val_loss: 0.0055\n",
            "Epoch 31/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0023 - val_loss: 0.0057\n",
            "Epoch 32/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0017 - val_loss: 0.0054\n",
            "Epoch 33/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0019 - val_loss: 0.0054\n",
            "Epoch 34/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0015 - val_loss: 0.0056\n",
            "Epoch 35/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 8.7697e-04 - val_loss: 0.0055\n",
            "Epoch 36/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0014 - val_loss: 0.0054\n",
            "Epoch 37/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0013 - val_loss: 0.0055\n",
            "Epoch 38/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0017 - val_loss: 0.0064\n",
            "Epoch 39/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0014 - val_loss: 0.0056\n",
            "Epoch 40/40\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0015 - val_loss: 0.0054\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "MSE: 0.6045722984721045\n",
            "Training model with units=100, dropout=0.3, batch_size=64, epochs=20, optimizer=adam\n",
            "Epoch 1/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - loss: 0.0291 - val_loss: 0.0076\n",
            "Epoch 2/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0035 - val_loss: 0.0058\n",
            "Epoch 3/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0019 - val_loss: 0.0056\n",
            "Epoch 4/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0015 - val_loss: 0.0054\n",
            "Epoch 5/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0022 - val_loss: 0.0053\n",
            "Epoch 6/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0011 - val_loss: 0.0053\n",
            "Epoch 7/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0016 - val_loss: 0.0053\n",
            "Epoch 8/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0017 - val_loss: 0.0053\n",
            "Epoch 9/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0015 - val_loss: 0.0054\n",
            "Epoch 10/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0012 - val_loss: 0.0054\n",
            "Epoch 11/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 7.6266e-04 - val_loss: 0.0053\n",
            "Epoch 12/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0015 - val_loss: 0.0054\n",
            "Epoch 13/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0014 - val_loss: 0.0054\n",
            "Epoch 14/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0016 - val_loss: 0.0053\n",
            "Epoch 15/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 9.6219e-04 - val_loss: 0.0053\n",
            "Epoch 16/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0013 - val_loss: 0.0053\n",
            "Epoch 17/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0015 - val_loss: 0.0054\n",
            "Epoch 18/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0013 - val_loss: 0.0053\n",
            "Epoch 19/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0011 - val_loss: 0.0054\n",
            "Epoch 20/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0015 - val_loss: 0.0054\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "MSE: 0.6013690380058017\n",
            "Training model with units=100, dropout=0.3, batch_size=64, epochs=20, optimizer=rmsprop\n",
            "Epoch 1/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 106ms/step - loss: 0.0190 - val_loss: 0.0056\n",
            "Epoch 2/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0038 - val_loss: 0.0058\n",
            "Epoch 3/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0028 - val_loss: 0.0055\n",
            "Epoch 4/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0019 - val_loss: 0.0053\n",
            "Epoch 5/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0031 - val_loss: 0.0054\n",
            "Epoch 6/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0013 - val_loss: 0.0053\n",
            "Epoch 7/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0017 - val_loss: 0.0097\n",
            "Epoch 8/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0040 - val_loss: 0.0054\n",
            "Epoch 9/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0017 - val_loss: 0.0055\n",
            "Epoch 10/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0016 - val_loss: 0.0056\n",
            "Epoch 11/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0020 - val_loss: 0.0057\n",
            "Epoch 12/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0015 - val_loss: 0.0057\n",
            "Epoch 13/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0013 - val_loss: 0.0058\n",
            "Epoch 14/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0019 - val_loss: 0.0057\n",
            "Epoch 15/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0016 - val_loss: 0.0053\n",
            "Epoch 16/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0021 - val_loss: 0.0063\n",
            "Epoch 17/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0017 - val_loss: 0.0056\n",
            "Epoch 18/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0017 - val_loss: 0.0062\n",
            "Epoch 19/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0014 - val_loss: 0.0058\n",
            "Epoch 20/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0014 - val_loss: 0.0054\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "MSE: 0.6076091486757342\n",
            "Training model with units=100, dropout=0.3, batch_size=64, epochs=40, optimizer=adam\n",
            "Epoch 1/40\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 52ms/step - loss: 0.0265 - val_loss: 0.0070\n",
            "Epoch 2/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0033 - val_loss: 0.0064\n",
            "Epoch 3/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0022 - val_loss: 0.0054\n",
            "Epoch 4/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0012 - val_loss: 0.0054\n",
            "Epoch 5/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0018 - val_loss: 0.0053\n",
            "Epoch 6/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0011 - val_loss: 0.0053\n",
            "Epoch 7/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0012 - val_loss: 0.0053\n",
            "Epoch 8/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0012 - val_loss: 0.0053\n",
            "Epoch 9/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0011 - val_loss: 0.0053\n",
            "Epoch 10/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0013 - val_loss: 0.0053\n",
            "Epoch 11/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0013 - val_loss: 0.0053\n",
            "Epoch 12/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0015 - val_loss: 0.0056\n",
            "Epoch 13/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0018 - val_loss: 0.0054\n",
            "Epoch 14/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0012 - val_loss: 0.0053\n",
            "Epoch 15/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 8.0919e-04 - val_loss: 0.0054\n",
            "Epoch 16/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0019 - val_loss: 0.0053\n",
            "Epoch 17/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0015 - val_loss: 0.0054\n",
            "Epoch 18/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0012 - val_loss: 0.0055\n",
            "Epoch 19/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 8.7402e-04 - val_loss: 0.0054\n",
            "Epoch 20/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0015 - val_loss: 0.0054\n",
            "Epoch 21/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0010 - val_loss: 0.0053\n",
            "Epoch 22/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0010 - val_loss: 0.0054\n",
            "Epoch 23/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0017 - val_loss: 0.0055\n",
            "Epoch 24/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0013 - val_loss: 0.0053\n",
            "Epoch 25/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0016 - val_loss: 0.0054\n",
            "Epoch 26/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0012 - val_loss: 0.0054\n",
            "Epoch 27/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 6.3041e-04 - val_loss: 0.0054\n",
            "Epoch 28/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0014 - val_loss: 0.0054\n",
            "Epoch 29/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0011 - val_loss: 0.0055\n",
            "Epoch 30/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 9.9687e-04 - val_loss: 0.0055\n",
            "Epoch 31/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0016 - val_loss: 0.0054\n",
            "Epoch 32/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0012 - val_loss: 0.0054\n",
            "Epoch 33/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0015 - val_loss: 0.0054\n",
            "Epoch 34/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8.9979e-04 - val_loss: 0.0054\n",
            "Epoch 35/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0016 - val_loss: 0.0054\n",
            "Epoch 36/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0011 - val_loss: 0.0054\n",
            "Epoch 37/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 8.7092e-04 - val_loss: 0.0054\n",
            "Epoch 38/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 7.7249e-04 - val_loss: 0.0054\n",
            "Epoch 39/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 9.8809e-04 - val_loss: 0.0055\n",
            "Epoch 40/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0016 - val_loss: 0.0054\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "MSE: 0.6018174764624424\n",
            "Training model with units=100, dropout=0.3, batch_size=64, epochs=40, optimizer=rmsprop\n",
            "Epoch 1/40\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 37ms/step - loss: 0.0169 - val_loss: 0.0059\n",
            "Epoch 2/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0037 - val_loss: 0.0055\n",
            "Epoch 3/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0030 - val_loss: 0.0066\n",
            "Epoch 4/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0029 - val_loss: 0.0055\n",
            "Epoch 5/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0028 - val_loss: 0.0074\n",
            "Epoch 6/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0022 - val_loss: 0.0054\n",
            "Epoch 7/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0021 - val_loss: 0.0056\n",
            "Epoch 8/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0012 - val_loss: 0.0064\n",
            "Epoch 9/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0024 - val_loss: 0.0053\n",
            "Epoch 10/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0017 - val_loss: 0.0054\n",
            "Epoch 11/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0030 - val_loss: 0.0053\n",
            "Epoch 12/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0022 - val_loss: 0.0058\n",
            "Epoch 13/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0019 - val_loss: 0.0053\n",
            "Epoch 14/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0024 - val_loss: 0.0054\n",
            "Epoch 15/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0017 - val_loss: 0.0055\n",
            "Epoch 16/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0011 - val_loss: 0.0055\n",
            "Epoch 17/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0015 - val_loss: 0.0061\n",
            "Epoch 18/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0014 - val_loss: 0.0057\n",
            "Epoch 19/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0018 - val_loss: 0.0061\n",
            "Epoch 20/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0020 - val_loss: 0.0054\n",
            "Epoch 21/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0016 - val_loss: 0.0056\n",
            "Epoch 22/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0011 - val_loss: 0.0057\n",
            "Epoch 23/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0016 - val_loss: 0.0053\n",
            "Epoch 24/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0017 - val_loss: 0.0059\n",
            "Epoch 25/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0018 - val_loss: 0.0055\n",
            "Epoch 26/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0015 - val_loss: 0.0053\n",
            "Epoch 27/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0012 - val_loss: 0.0053\n",
            "Epoch 28/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0020 - val_loss: 0.0053\n",
            "Epoch 29/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0016 - val_loss: 0.0055\n",
            "Epoch 30/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0013 - val_loss: 0.0053\n",
            "Epoch 31/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 9.3649e-04 - val_loss: 0.0055\n",
            "Epoch 32/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0012 - val_loss: 0.0059\n",
            "Epoch 33/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0024 - val_loss: 0.0053\n",
            "Epoch 34/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 9.7691e-04 - val_loss: 0.0057\n",
            "Epoch 35/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0018 - val_loss: 0.0054\n",
            "Epoch 36/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0016 - val_loss: 0.0054\n",
            "Epoch 37/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0016 - val_loss: 0.0053\n",
            "Epoch 38/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0017 - val_loss: 0.0054\n",
            "Epoch 39/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 9.1259e-04 - val_loss: 0.0054\n",
            "Epoch 40/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0013 - val_loss: 0.0053\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
            "MSE: 0.5974398665782877\n",
            "Best Hyperparameters: Units=50, Dropout=0.3, Batch Size=64, Epochs=20, Optimizer=rmsprop\n",
            "Best MSE: 0.5902\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Layer\n",
        "import tensorflow as tf\n",
        "\n",
        "# Custom Self-Attention Layer\n",
        "class SelfAttention(Layer):\n",
        "    def __init__(self):\n",
        "        super(SelfAttention, self).__init__()\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        self.W = self.add_weight(shape=(input_shape[-1], input_shape[-1]), initializer=\"random_normal\", trainable=True)\n",
        "        self.b = self.add_weight(shape=(input_shape[-1],), initializer=\"random_normal\", trainable=True)\n",
        "        self.u = self.add_weight(shape=(input_shape[-1],), initializer=\"random_normal\", trainable=True)\n",
        "\n",
        "    def call(self, x):\n",
        "        u_it = tf.tanh(tf.tensordot(x, self.W, axes=[2, 0]) + self.b)\n",
        "        a_it = tf.nn.softmax(tf.tensordot(u_it, self.u, axes=[2, 0]), axis=1)\n",
        "        return tf.reduce_sum(x * tf.expand_dims(a_it, -1), axis=1)\n",
        "\n",
        "# Modify the model to include self-attention\n",
        "def create_lstm_with_attention(units=50, dropout_rate=0.3, optimizer='rmsprop'):\n",
        "    model = Sequential()\n",
        "    model.add(LSTM(units=units, return_sequences=True, input_shape=(sequence_length, 1)))\n",
        "    model.add(SelfAttention())  # Add Self-Attention layer\n",
        "    model.add(Dropout(dropout_rate))\n",
        "    model.add(Dense(1))\n",
        "    model.compile(optimizer=optimizer, loss='mean_squared_error')\n",
        "    return model\n",
        "\n",
        "# Train the model with self-attention\n",
        "attention_model = create_lstm_with_attention(units=50, dropout_rate=0.3, optimizer='rmsprop')\n",
        "attention_model.fit(X_train, y_train, epochs=20, batch_size=64, validation_data=(X_test, y_test))\n",
        "\n",
        "# Evaluate the model\n",
        "y_pred = attention_model.predict(X_test)\n",
        "y_pred_rescaled = scaler.inverse_transform(y_pred)\n",
        "y_test_rescaled = scaler.inverse_transform(y_test.reshape(-1, 1))\n",
        "\n",
        "# Calculate and print MSE with attention model\n",
        "mse_attention = mean_squared_error(y_test_rescaled, y_pred_rescaled)\n",
        "print(f\"Mean Squared Error with Self-Attention: {mse_attention:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O8_pI72ilMgZ",
        "outputId": "9ceae527-c680-4d7f-caa0-ff4221c56016"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - loss: 0.0297 - val_loss: 0.0071\n",
            "Epoch 2/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0040 - val_loss: 0.0065\n",
            "Epoch 3/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0032 - val_loss: 0.0067\n",
            "Epoch 4/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0044 - val_loss: 0.0064\n",
            "Epoch 5/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0028 - val_loss: 0.0064\n",
            "Epoch 6/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0034 - val_loss: 0.0062\n",
            "Epoch 7/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0032 - val_loss: 0.0062\n",
            "Epoch 8/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0039 - val_loss: 0.0061\n",
            "Epoch 9/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0031 - val_loss: 0.0061\n",
            "Epoch 10/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0029 - val_loss: 0.0061\n",
            "Epoch 11/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0035 - val_loss: 0.0062\n",
            "Epoch 12/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0028 - val_loss: 0.0062\n",
            "Epoch 13/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0024 - val_loss: 0.0062\n",
            "Epoch 14/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0026 - val_loss: 0.0068\n",
            "Epoch 15/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0032 - val_loss: 0.0067\n",
            "Epoch 16/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0021 - val_loss: 0.0061\n",
            "Epoch 17/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0025 - val_loss: 0.0066\n",
            "Epoch 18/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0022 - val_loss: 0.0062\n",
            "Epoch 19/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0021 - val_loss: 0.0062\n",
            "Epoch 20/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0023 - val_loss: 0.0060\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            "Mean Squared Error with Self-Attention: 0.6764\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score\n",
        "\n",
        "# Define a threshold for anomaly detection (you can tune this)\n",
        "threshold = 0.5\n",
        "\n",
        "# Convert the predicted values and true values to binary based on the threshold\n",
        "y_pred_binary = (np.abs(y_pred_rescaled - y_test_rescaled) > threshold).astype(int)\n",
        "y_true_binary = (np.abs(y_test_rescaled - np.mean(y_test_rescaled)) > threshold).astype(int)\n",
        "\n",
        "# Calculate precision, recall, and F1 score\n",
        "precision = precision_score(y_true_binary, y_pred_binary)\n",
        "recall = recall_score(y_true_binary, y_pred_binary)\n",
        "f1 = f1_score(y_true_binary, y_pred_binary)\n",
        "roc_auc = roc_auc_score(y_true_binary, y_pred_binary)\n",
        "\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1 Score: {f1:.4f}\")\n",
        "print(f\"ROC-AUC: {roc_auc:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XhiDQdc-mcwz",
        "outputId": "1af1de60-69c1-4ebc-d1cd-244cf66b109a"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision: 0.8167\n",
            "Recall: 0.4455\n",
            "F1 Score: 0.5765\n",
            "ROC-AUC: 0.6540\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot True vs Predicted Values with Anomalies Highlighted\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(y_test_rescaled, label=\"True Values\", color='blue')\n",
        "plt.plot(y_pred_rescaled, label=\"Predicted Values\", color='green')\n",
        "\n",
        "# Highlight anomalies (where predicted values differ from true values beyond the threshold)\n",
        "anomalies = np.where(np.abs(y_pred_rescaled - y_test_rescaled) > threshold)[0]  # Extract indices of anomalies\n",
        "plt.scatter(anomalies, y_test_rescaled[anomalies], color='red', label=\"Detected Anomalies\", marker='o')\n",
        "\n",
        "plt.title(\"True vs Predicted Values with Anomalies Highlighted\")\n",
        "plt.xlabel(\"Time Step\")\n",
        "plt.ylabel(\"Value\")\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "id": "kOGfjqXioHk4",
        "outputId": "2936ac68-a81b-4751-978f-a553f119b35c"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x600 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA+cAAAIjCAYAAABh8GqqAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAADGkUlEQVR4nOzdd3hT5f/G8Xda2tJdCgUKLS1T9sYBskGmMgUZMsQtCgjuwVAZKoqiX3CBqMgQAf2JioCAIIgggsres2wolJbO8/vjkDTpLlDapPfrunIlOTnn5EmbjjufZ1gMwzAQERERERERkXzjlt8NEBERERERESnsFM5FRERERERE8pnCuYiIiIiIiEg+UzgXERERERERyWcK5yIiIiIiIiL5TOFcREREREREJJ8pnIuIiIiIiIjkM4VzERERERERkXymcC4iIiIiIiKSzxTORUTkhvn888+xWCwcPHjQtq1Fixa0aNEi39qUVkZtvBlWrVqFxWJh1apVN/V581JuXpN13wULFuR9w5ycxWJhzJgxtvv59Z7NrbTtzu2xQ4cOzXa/G/07pkWLFtSsWfOajr1RxowZg8Viydc2iEjBoHAuIi7BYrHk6OJKwSgjkZGRDq+3ZMmSNG3alEWLFuV303IlNjaWMWPG5Nv3q3bt2pQrVw7DMDLdp0mTJpQqVYqkpKSb2LKC7+uvv2bKlCl5+hz/+9//sFgs3HbbbXn6PIWZNTCeOXMmw8cjIyPp3LnzTW5V/jl+/Dhjxoxhy5Yt+d0UEXFhRfK7ASIiN8KXX37pcP+LL75g2bJl6bZXq1btZjYrX9StW5eRI0cC5j+UH330Ed27d2fatGk8+uijN709v/zyS66PiY2NZezYsQD5UnXv168fzz//PGvWrKFZs2bpHj948CDr169n6NChFClSeP+UNmvWjLi4ODw9PW3bvv76a/777z+GDx+eZ887e/ZsIiMj+fPPP9m7dy+VKlXKs+cqCO6//37uu+8+vLy88rspWYqLi8uXn4dr+R2TW8ePH2fs2LFERkZSt27dPH8+ESmcCu9/FCLiUvr37+9w/48//mDZsmXptqcVGxuLj49PXjbtpitbtqzD6x4wYACVKlXi3XffzTScJyUlkZKS4hCybpS8OGde69u3Ly+88AJff/11huF8zpw5GIZBv3798qF1BYebmxtFixa9qc954MAB1q1bx8KFC3nkkUeYPXs2o0ePvqltuNnc3d1xd3fP72Zk62a/F6yc8XeMiEhG1K1dRAoN69jCv/76i2bNmuHj48OLL74IZD5WMjIykkGDBjlsu3DhAsOHDyc8PBwvLy8qVarEpEmTSElJyfL5O3fuTIUKFTJ87I477qBhw4a2+8uWLePOO+8kKCgIPz8/brnlFltbc6t06dJUq1aNAwcOAGbV12Kx8PbbbzNlyhQqVqyIl5cX27dvB2Dnzp307NmT4OBgihYtSsOGDfn+++/TnXfbtm20atUKb29vwsLCeP311zP8GmQ0HvTKlSuMGTOGKlWqULRoUUJDQ+nevTv79u3j4MGDhISEADB27FhbF33778+NbmNa4eHhNGvWjAULFpCYmJju8a+//pqKFSty2223cejQIR5//HFuueUWvL29KV68OPfee2+Oxgdn9P6CjL9m8fHxjB49mkqVKuHl5UV4eDjPPvss8fHxDvtdy3une/fu1K9f32Hb3XffjcVicfi6btiwAYvFwk8//QSkH3PeokULlixZwqFDh2zft8jISIfzpqSk8MYbbxAWFkbRokVp3bo1e/fuzbJ99mbPnk2xYsXo1KkTPXv2ZPbs2en2sX+Pf/zxx7b3eKNGjdi4cWO6/X/99VeaNm2Kr68vQUFBdOnShR07djjsY+3mvXv3bvr3709gYCAhISG88sorGIbBkSNH6NKlCwEBAZQuXZrJkyc7HJ+QkMCrr75KgwYNCAwMxNfXl6ZNm7Jy5cpsX3NmY85/+uknW7v9/f3p1KkT27Ztc9jnxIkTDB48mLCwMLy8vAgNDaVLly55Mn49o9+jq1atomHDhhQtWpSKFSvy0UcfZTnGevHixdSsWRMvLy9q1KjBzz//nO3zZvTzcujQIe655x58fX0pWbIkI0aMYOnSpZkOb9q+fTstW7bEx8eHsmXL8uabbzq8hkaNGgEwePBg23v7888/t+2zYcMG2rdvT2BgID4+PjRv3pzff/893fOsXbuWRo0aOXw9RESsVDkXkULl7NmzdOjQgfvuu4/+/ftTqlSpXB0fGxtL8+bNOXbsGI888gjlypVj3bp1vPDCC0RFRWU51rZ3794MGDCAjRs32v7RA/OfyD/++IO33noLMANl586dqV27NuPGjcPLy4u9e/dm+I9eTiQmJnLkyBGKFy/usH3mzJlcuXKFhx9+GC8vL4KDg9m2bRtNmjShbNmyPP/88/j6+jJ//ny6du3Kt99+S7du3QDzH/6WLVuSlJRk2+/jjz/G29s72/YkJyfTuXNnVqxYwX333cewYcO4dOkSy5Yt47///qNNmzZMmzaNxx57jG7dutG9e3fAHAdu/frkdRvB7Nr+8MMPs3TpUoextf/++y///fcfr776KgAbN25k3bp13HfffYSFhXHw4EGmTZtGixYt2L59+w3pmZGSksI999zD2rVrefjhh6lWrRr//vsv7777Lrt372bx4sW2r821vHeaNm3Kd999x8WLFwkICMAwDH7//Xfc3NxYs2YN99xzDwBr1qzBzc2NJk2aZHiel156iejoaI4ePcq7774LgJ+fn8M+EydOxM3NjVGjRhEdHc2bb75Jv3792LBhQ46+FrNnz6Z79+54enrSp08fpk2blu5nyurrr7/m0qVLPPLII1gsFt588026d+/O/v378fDwAGD58uV06NCBChUqMGbMGOLi4pg6dSpNmjRh8+bN6T5c6N27N9WqVWPixIksWbKE119/neDgYD766CNatWrFpEmTmD17NqNGjaJRo0a2nhcXL17k008/pU+fPjz00ENcunSJzz77jHbt2vHnn3/muqv0l19+ycCBA2nXrh2TJk0iNjaWadOmceedd/L333/b2t2jRw+2bdvGk08+SWRkJKdOnWLZsmUcPnw43WvLyLlz5zLcnpMPuf7++2/at29PaGgoY8eOJTk5mXHjxtk+fEtr7dq1LFy4kMcffxx/f3/ef/99evToweHDh9P9/srK5cuXadWqFVFRUQwbNozSpUvz9ddfZ/pByPnz52nfvj3du3enV69eLFiwgOeee45atWrRoUMHqlWrxrhx43j11Vd5+OGHadq0KQCNGzcGzA93OnToQIMGDRg9ejRubm7MnDmTVq1asWbNGm699VbA/N1x1113ERISwpgxY0hKSmL06NG5/jskIi7MEBFxQU888YSR9ldc8+bNDcCYPn16uv0BY/To0em2R0REGAMHDrTdf+211wxfX19j9+7dDvs9//zzhru7u3H48OFM2xQdHW14eXkZI0eOdNj+5ptvGhaLxTh06JBhGIbx7rvvGoBx+vTp7F5mhu296667jNOnTxunT582tm7datx3330GYDz55JOGYRjGgQMHDMAICAgwTp065XB869atjVq1ahlXrlyxbUtJSTEaN25sVK5c2bZt+PDhBmBs2LDBtu3UqVNGYGCgARgHDhywbW/evLnRvHlz2/0ZM2YYgPHOO++ka39KSophGIZx+vTpTL8nedHGjJw7d87w8vIy+vTp47D9+eefNwBj165dhmEYRmxsbLpj169fbwDGF198Ydu2cuVKAzBWrlxp25b2/WWV9mv25ZdfGm5ubsaaNWsc9ps+fboBGL///rthGNf+3tm4caMBGD/++KNhGIbxzz//GIBx7733Grfddpttv3vuuceoV69elq+pU6dORkRERLrnsO5brVo1Iz4+3rb9vffeMwDj33//zbadmzZtMgBj2bJlhmGY3/ewsDBj2LBhDvtZ3+PFixc3zp07Z9v+3XffGYDxf//3f7ZtdevWNUqWLGmcPXvWtm3r1q2Gm5ubMWDAANu20aNHG4Dx8MMP27YlJSUZYWFhhsViMSZOnGjbfv78ecPb29vhe5uUlOTwuq37lSpVynjggQcctqd978+cOdPhPXvp0iUjKCjIeOihhxyOO3HihBEYGGjbfv78eQMw3nrrrXRfy+xYX29Wl06dOmXZ7rvvvtvw8fExjh07Ztu2Z88eo0iRIul+PwOGp6ensXfvXtu2rVu3GoAxderUTL8WhpH+52Xy5MkGYCxevNi2LS4uzqhatWq696v174L9z2p8fLxRunRpo0ePHrZt1p+RmTNnOrQ7JSXFqFy5stGuXTvb7y/DMH8vlC9f3mjbtq1tW9euXY2iRYvaftcbhmFs377dcHd3T/f1EJHCSd3aRaRQ8fLyYvDgwdd8/DfffEPTpk0pVqwYZ86csV3atGlDcnIyv/32W6bHBgQE0KFDB+bPn+8wC/i8efO4/fbbKVeuHABBQUEAfPfddzmqTqX1yy+/EBISQkhICHXq1OGbb77h/vvvZ9KkSQ779ejRw6GCde7cOX799Vd69erFpUuXbK/t7NmztGvXjj179nDs2DEAfvzxR26//XZbRQggJCQkR2Owv/32W0qUKMGTTz6Z7rHslhO6WW0EKFasGB07duT777/n8uXLABiGwdy5c2nYsCFVqlQBcKjEJyYmcvbsWSpVqkRQUBCbN2/O0XNl55tvvqFatWpUrVrV4X3XqlUrAFtF8FrfO/Xq1cPPz8/2/l2zZg1hYWEMGDCAzZs3Exsbi2EYrF271lY1vFaDBw92GCNsPd/+/fuzPXb27NmUKlWKli1bAub7pXfv3sydO5fk5OR0+/fu3ZtixYpl+lxRUVFs2bKFQYMGERwcbNuvdu3atG3blh9//DHdOR988EHbbXd3dxo2bIhhGAwZMsS2PSgoiFtuucXhNbm7u9ted0pKCufOnSMpKYmGDRvm+n2ybNkyLly4QJ8+fRzeD+7u7tx2222294O3tzeenp6sWrWK8+fP5+o5rL799luWLVuW7pJdtTc5OZnly5fTtWtXypQpY9teqVIlOnTokOExbdq0oWLFirb7tWvXJiAgIEfvDXs///wzZcuWtfX4AHM8/EMPPZTh/n5+fg7zdHh6enLrrbfm6Hm3bNnCnj176Nu3L2fPnrV9Ly5fvkzr1q357bffSElJITk5maVLl9K1a1fb73owJylt165drl6fiLgudWsXkUKlbNmy1zV50J49e/jnn38y7ZZ56tSpLI/v3bs3ixcvZv369TRu3Jh9+/bx119/OXSH7927N59++ikPPvggzz//PK1bt6Z79+707NkTN7fsP1O97bbbeP3117FYLPj4+FCtWjVbaLNXvnx5h/t79+7FMAxeeeUVXnnllUxfX9myZTl06FCGy1jdcsst2bZv37593HLLLdc0q/PNaqNVv379WLRoEd999x19+/Zl3bp1HDx4kGHDhtn2iYuLY8KECcycOZNjx445fPASHR2di1eXuT179rBjx45s33fX+t5xd3fnjjvuYM2aNYAZzps2bcqdd95JcnIyf/zxB6VKleLcuXPXHc7tgwlgC8/Zhcfk5GTmzp1Ly5YtbfMngPl+nzx5MitWrOCuu+7K1XMdOnQIyPg9Ua1aNZYuXcrly5fx9fXN9JyBgYEULVqUEiVKpNt+9uxZh22zZs1i8uTJ7Ny502Eug7Q/i9nZs2cPgO3DmbQCAgIA88PISZMmMXLkSEqVKsXtt99O586dGTBgAKVLl87RczVr1izda4PsJ387deoUcXFxGc6kn9ns+mm/tmB+z3L7wcKhQ4eoWLFiug/7MnvesLCwdPsWK1aMf/75J9vnsn4vBg4cmOk+0dHRxMfHExcXR+XKldM9fsstt2T4QZCIFD4K5yJSqOR0vLFV2mpcSkoKbdu25dlnn81wf2s1NTN33303Pj4+zJ8/n8aNGzN//nzc3Ny49957Hdr422+/sXLlSpYsWcLPP//MvHnzaNWqFb/88ku2szaXKFGCNm3aZPva0n4trJXWUaNGZVrJye8lq252Gzt37kxgYCBff/01ffv25euvv8bd3Z377rvPts+TTz7JzJkzGT58OHfccQeBgYFYLBbuu+++bKvXmfUUSE5Odvg+p6SkUKtWLd55550M9w8PDweu771z55138sYbb3DlyhXWrFnDSy+9RFBQEDVr1mTNmjW2Sun1hvPM2mBksaY8mON6o6KimDt3LnPnzk33+OzZs9OF82t9rqxkdM6cPM9XX33FoEGD6Nq1K8888wwlS5bE3d2dCRMmsG/fvly1wfq++vLLLzMM2fYffA0fPpy7776bxYsXs3TpUl555RUmTJjAr7/+Sr169XL1vHktL75fef281u/FW2+9lem8AX5+fukmbhQRyYjCuYgIZpXkwoULDtsSEhKIiopy2FaxYkViYmJyFH4z4uvrS+fOnfnmm2945513mDdvHk2bNnXo9gnmElWtW7emdevWvPPOO4wfP56XXnqJlStXXvNzZ8c6k7yHh0e2zxEREWGrGNnbtWtXts9TsWJFNmzYQGJiom1SrrQyC603q41WXl5e9OzZky+++IKTJ0/yzTff0KpVK4dAtGDBAgYOHOgwO/eVK1fSvZ8yktH7DszKn/3M/hUrVmTr1q20bt06267/1/readq0KQkJCcyZM4djx47ZQnizZs1s4bxKlSrZdmfOrn3Xavbs2ZQsWZIPP/ww3WMLFy5k0aJFTJ8+PVcfwEVERAAZvyd27txJiRIlHKrm12PBggVUqFCBhQsXOnyNrmUZOGvX75IlS+bo90HFihUZOXIkI0eOZM+ePdStW5fJkyfz1Vdf5fq5c6pkyZIULVo0w5n4czM7/7WIiIhg+/btGIbh8LW+nufN7H1t/V4EBARk+b0ICQnB29v7un8niYhr05hzERHMf7DSjhf/+OOP01XOe/Xqxfr161m6dGm6c1y4cIGkpKRsn6t3794cP36cTz/9lK1bt9K7d2+HxzOaHdlakcnL6kvJkiVp0aIFH330UboPJQBOnz5tu92xY0f++OMP/vzzT4fHM1rWKq0ePXpw5swZPvjgg3SPWStV1hnO0wbXm9VGe/369SMxMZFHHnmE06dPpxuz7u7unq7CNnXq1AzHQKdVsWJF/vjjDxISEmzbfvjhB44cOeKwX69evTh27BiffPJJunPExcXZxsRfz3vntttuw8PDg0mTJhEcHEyNGjUAM7T/8ccfrF69OkdVc19f3xvWnd8qLi6OhQsX0rlzZ3r27JnuMnToUC5dupThcnpZCQ0NpW7dusyaNcvhvfbff//xyy+/0LFjxxv2GqzVWfv3yoYNG1i/fn2uz9WuXTsCAgIYP358hkv9WX8OYmNjuXLlisNjFStWxN/fP88rue7u7rRp04bFixdz/Phx2/a9e/faluLLK+3atePYsWMO74crV65k+POTU9YPadL+TmrQoAEVK1bk7bffJiYmJt1x1u+Fu7s77dq1Y/HixRw+fNj2+I4dOzL8eyIihZMq5yIimJM8Pfroo/To0YO2bduydetWli5dmm6s5TPPPMP3339P586dGTRoEA0aNODy5cv8+++/LFiwgIMHD2Y4PtNex44d8ff3Z9SoUbi7u9OjRw+Hx8eNG8dvv/1Gp06diIiI4NSpU/zvf/8jLCyMO++884a/dnsffvghd955J7Vq1eKhhx6iQoUKnDx5kvXr13P06FG2bt0KwLPPPsuXX35J+/btGTZsmG2ZsoiIiGzHaQ4YMIAvvviCp59+mj///JOmTZty+fJlli9fzuOPP06XLl3w9vamevXqzJs3jypVqhAcHEzNmjWpWbPmTWmjvebNmxMWFsZ3332Ht7e3bWk3q86dO/Pll18SGBhI9erVWb9+PcuXL8/R0k8PPvggCxYsoH379vTq1Yt9+/bx1VdfOUyKBXD//fczf/58Hn30UVauXEmTJk1ITk5m586dzJ8/n6VLl9KwYcPreu/4+PjQoEED/vjjD9sa52BWzi9fvszly5dzFM4bNGjAvHnzePrpp2nUqBF+fn7cfffd2R6Xle+//55Lly45TPBl7/bbbyckJITZs2en+7ArO2+99RYdOnTgjjvuYMiQIbal1AIDA9Ot2X09OnfuzMKFC+nWrRudOnXiwIEDTJ8+nerVq2cY6rISEBDAtGnTuP/++6lfvz733XcfISEhHD58mCVLltCkSRM++OADdu/eTevWrenVqxfVq1enSJEiLFq0iJMnTzoMzcgrY8aM4ZdffqFJkyY89thjJCcn88EHH1CzZk22bNmSZ8/7yCOP8MEHH9CnTx+GDRtGaGgos2fPto2Tv5beHRUrViQoKIjp06fj7++Pr68vt912G+XLl+fTTz+lQ4cO1KhRg8GDB1O2bFmOHTvGypUrCQgI4P/+7/8AGDt2LD///DNNmzbl8ccfJykpialTp1KjRo1c/U4SERd28yeIFxHJe5ktpVajRo0M909OTjaee+45o0SJEoaPj4/Rrl07Y+/evRkudXXp0iXjhRdeMCpVqmR4enoaJUqUMBo3bmy8/fbbRkJCQo7a169fPwMw2rRpk+6xFStWGF26dDHKlCljeHp6GmXKlDH69OmTbvm2jERERKRb3igt6zJTmS2vtG/fPmPAgAFG6dKlDQ8PD6Ns2bJG586djQULFjjs988//xjNmzc3ihYtapQtW9Z47bXXjM8++yzbZY4Mw1xm6KWXXjLKly9veHh4GKVLlzZ69uxp7Nu3z7bPunXrjAYNGhienp7plmi60W3MzjPPPGMARq9evdI9dv78eWPw4MFGiRIlDD8/P6Ndu3bGzp070713Mlp2zDDMZZ/Kli1reHl5GU2aNDE2bdqU4dcsISHBmDRpklGjRg3Dy8vLKFasmNGgQQNj7NixRnR0tGEY1/fesX+dkyZNctheqVIlA3D4/mT2mmJiYoy+ffsaQUFBBmBbVs267zfffONwDuv7Me0SVfbuvvtuo2jRosbly5cz3WfQoEGGh4eHcebMmSzf42nfS4ZhGMuXLzeaNGlieHt7GwEBAcbdd99tbN++3WEf69JiaZepGzhwoOHr65vuedL+vklJSTHGjx9vREREGF5eXka9evWMH374wRg4cGC6pefStjGj5cMMw/yatmvXzggMDDSKFi1qVKxY0Rg0aJCxadMmwzAM48yZM8YTTzxhVK1a1fD19TUCAwON2267zZg/f35mX8ZsX69VRr9rMvrarlixwqhXr57h6elpVKxY0fj000+NkSNHGkWLFk137BNPPJHh89j/HOVkKTXDMIz9+/cbnTp1Mry9vY2QkBBj5MiRxrfffmsAxh9//OFwbEZ/FzL6vnz33XdG9erVbUvB2b9n//77b6N79+5G8eLFDS8vLyMiIsLo1auXsWLFCodzrF692vZ7rUKFCsb06dNtX2sREYth5PEsGyIiIiIiV3Xt2pVt27ZlOP46L02ZMoURI0Zw9OhRypYte1OfW0QkJzTmXERERETyRFxcnMP9PXv28OOPP9KiRYub+rxXrlzho48+onLlygrmIlJgacy5iIiIiOSJChUqMGjQICpUqMChQ4eYNm0anp6emS5HeaN0796dcuXKUbduXaKjo/nqq6/YuXNnrieEFBG5mRTORURERCRPtG/fnjlz5nDixAm8vLy44447GD9+PJUrV87T523Xrh2ffvops2fPJjk5merVqzN37txcTxgoInIzacy5iIiIiIiISD7TmHMRERERERGRfKZwLiIiIiIiIpLPCtWY85SUFI4fP46/vz8WiyW/myMiIiIiIiIuzjAMLl26RJkyZXBzy7w+XqjC+fHjxwkPD8/vZoiIiIiIiEghc+TIEcLCwjJ9vFCFc39/f8D8ogQEBORza0RERERERMTVXbx4kfDwcFsezUyhCufWruwBAQEK5yIiIiIiInLTZDe0WhPCiYiIiIiIiOQzhXMRERERERGRfKZwLiIiIiIiIpLPCtWYcxERERERyXuGYZCUlERycnJ+N0Ukz7m7u1OkSJHrXq5b4VxERERERG6YhIQEoqKiiI2Nze+miNw0Pj4+hIaG4unpec3nUDgXEREREZEbIiUlhQMHDuDu7k6ZMmXw9PS87mqiSEFmGAYJCQmcPn2aAwcOULlyZdzcrm30uMK5iIiIiIjcEAkJCaSkpBAeHo6Pj09+N0fkpvD29sbDw4NDhw6RkJBA0aJFr+k8mhBORERERERuqGutHIo4qxvxntdPjYiIiIiIiEg+UzgXERERERERyWcK5yIiIiIiIi4kMjKSKVOm5HczJJcUzkVEREREpFCzWCxZXsaMGXNT2lGrVi0effTRDB/78ssv8fLy4syZMzelLXLzKZyLiIiIiEihFhUVZbtMmTKFgIAAh22jRo2y7WsYBklJSXnSjiFDhjB37lzi4uLSPTZz5kzuueceSpQokSfPLflP4VxERFxTcjKsWgVz5pjXycn53SIRkULJMODy5fy5GEbO2li6dGnbJTAwEIvFYru/c+dO/P39+emnn2jQoAFeXl6sXbuWQYMG0bVrV4fzDB8+nBYtWtjup6SkMGHCBMqXL4+3tzd16tRhwYIFmbajf//+xMXF8e233zpsP3DgAKtWrWLIkCHs27ePLl26UKpUKfz8/GjUqBHLly/P9JwHDx7EYrGwZcsW27YLFy5gsVhYtWqVbdt///1Hhw4d8PPzo1SpUtx///0OVfoFCxZQq1YtvL29KV68OG3atOHy5ctZf2ElVxTORUTE9SxcCJGR0LIl9O1rXkdGmttFROSmio0FP7/8ucTG3rjX8fzzzzNx4kR27NhB7dq1c3TMhAkT+OKLL5g+fTrbtm1jxIgR9O/fn9WrV2e4f4kSJejSpQszZsxw2P75558TFhbGXXfdRUxMDB07dmTFihX8/ffftG/fnrvvvpvDhw9f82u7cOECrVq1ol69emzatImff/6ZkydP0qtXL8DsWdCnTx8eeOABduzYwapVq+jevTtGTj/9kBwpkt8NEBERuaEWLoSePdOXS44dM7cvWADdu+dP20RExGmNGzeOtm3b5nj/+Ph4xo8fz/Lly7njjjsAqFChAmvXruWjjz6iefPmGR43ZMgQOnTowIEDByhfvjyGYTBr1iwGDhyIm5sbderUoU6dOrb9X3vtNRYtWsT333/P0KFDr+m1ffDBB9SrV4/x48fbts2YMYPw8HB2795NTEwMSUlJdO/enYiICMAcHy83lsK5iIi4juRkGDbMFsx3cguBRBPKCXObxQLDh0OXLuDunr9tFREpJHx8ICYm/577RmnYsGGu9t+7dy+xsbHpAn1CQgL16tXL9Li2bdsSFhbGzJkzGTduHCtWrODw4cMMHjwYgJiYGMaMGcOSJUuIiooiKSmJuLi466qcb926lZUrV+Ln55fusX379nHXXXfRunVratWqRbt27bjrrrvo2bMnxYoVu+bnlPQUzkVExHWsWQNHjwJwjmLUYSuV2Ms2apqPGwYcOWLuZzcmUERE8o7FAr6++d2K6+eb5kW4ubml69admJhoux1z9ROJJUuWULZsWYf9vLy8Mn0eNzc3Bg0axKxZsxgzZgwzZ86kZcuWVKhQAYBRo0axbNky3n77bSpVqoS3tzc9e/YkISEh0/MBDm21b6e1rXfffTeTJk1Kd3xoaCju7u4sW7aMdevW8csvvzB16lReeuklNmzYQPny5TN9LZI7GnMuIiKuIyrKdvMUJUnAiyOEZ7mfiIjItQgJCSEqzd8T+0nXqlevjpeXF4cPH6ZSpUoOl/DwDP422Rk8eDBHjhxh4cKFLFq0iCFDhtge+/333xk0aBDdunWjVq1alC5dmoMHD2bZTsChrfbtBKhfvz7btm0jMjIyXVutH0pYLBaaNGnC2LFj+fvvv/H09GTRokVZvg7JHYVzERFxHaGhtptJVzuHJWXUScxuPxERkWvRqlUrNm3axBdffMGePXsYPXo0//33n+1xf39/Ro0axYgRI5g1axb79u1j8+bNTJ06lVmzZmV57vLly9OqVSsefvhhvLy86G43V0rlypVZuHAhW7ZsYevWrfTt25eUlJRMz+Xt7c3tt99um8xu9erVvPzyyw77PPHEE5w7d44+ffqwceNG9u3bx9KlSxk8eDDJycls2LCB8ePHs2nTJg4fPszChQs5ffo01apVu8avnmRE4VxERFxH06YQFgYWC8mYY8qt14DZtzI83NxPRETkOrRr145XXnmFZ599lkaNGnHp0iUGDBjgsM9rr73GK6+8woQJE6hWrRrt27dnyZIlOeoKPmTIEM6fP0/fvn0pWrSobfs777xDsWLFaNy4MXfffTft2rWjfv36WZ5rxowZJCUl0aBBA4YPH87rr7/u8HiZMmX4/fffSU5O5q677qJWrVoMHz6coKAg3NzcCAgI4LfffqNjx45UqVKFl19+mcmTJ9OhQ4dcfMUkOxajEM1/f/HiRQIDA4mOjiYgICC/myMiInnh6mztm416NOAv3EkiCQ8zmINmaxcRyUNXrlyxzTJuHyhFXF1W7/2c5lCnqZwnJyfzyiuvUL58eby9valYsSKvvfaa1tYTERFH3bvDggUklzS7ridbu7WHhSmYi4iISIHlNLO1T5o0iWnTpjFr1ixq1KjBpk2bGDx4MIGBgTz11FP53TwRESlIuncnqWQXuNp7PWXFStyaN9XyaSIiIlJgOU04X7duHV26dKFTp04AREZGMmfOHP788898bpmIiBRE9mPNk5u2wE25XERERAowp+nW3rhxY1asWMHu3bsB2Lp1K2vXrs1yEoL4+HguXrzocBERkcIhOTnj2yIiIiIFkdNUzp9//nkuXrxI1apVcXd3Jzk5mTfeeIN+/fplesyECRMYO3bsTWyliIgUFPaBPCkp/9ohIiIikhNOUzmfP38+s2fP5uuvv2bz5s3MmjWLt99+O8s1Al944QWio6NtlyNHjtzEFouISH5S5VxEREScidNUzp955hmef/557rvvPgBq1arFoUOHmDBhAgMHDszwGC8vL7y8vG5mM0VEpICwr5YrnIuIiEhB5zSV89jYWNzcHJvr7u5OSkpKPrVIREQKMlXORURExJk4TeX87rvv5o033qBcuXLUqFGDv//+m3feeYcHHnggv5smIiIFkMK5iIiIOBOnqZxPnTqVnj178vjjj1OtWjVGjRrFI488wmuvvZbfTRMRkQJI4VxERAqqQYMG0bVrV9v9Fi1aMHz48JvejlWrVmGxWLhw4UKePo/FYmHx4sV5+hyuwGnCub+/P1OmTOHQoUPExcWxb98+Xn/9dTw9PfO7aSIiUgDZjznXbO0iIpKdQYMGYbFYsFgseHp6UqlSJcaNG0fSTfgjsnDhwhwXHW9WoE5ISKBEiRJMnDgxw8dfe+01SpUqRWJiYp62ozBxmnAuIiKSG6qci4hIbrVv356oqCj27NnDyJEjGTNmDG+99VaG+yYkJNyw5w0ODsbf3/+Gne9G8PT0pH///sycOTPdY4Zh8PnnnzNgwAA8PDzyoXWuSeFcRERcksK5iEjBYBgGlxMu58vFMIxctdXLy4vSpUsTERHBY489Rps2bfj++++B1K7ob7zxBmXKlOGWW24B4MiRI/Tq1YugoCCCg4Pp0qULBw8etJ0zOTmZp59+mqCgIIoXL86zzz6brl1pu7XHx8fz3HPPER4ejpeXF5UqVeKzzz7j4MGDtGzZEoBixYphsVgYNGgQACkpKUyYMIHy5cvj7e1NnTp1WLBggcPz/Pjjj1SpUgVvb29atmzp0M6MDBkyhN27d7N27VqH7atXr2b//v0MGTKEjRs30rZtW0qUKEFgYCDNmzdn8+bNmZ4zo8r/li1bsFgsDu1Zu3YtTZs2xdvbm/DwcJ566ikuX75se/x///sflStXpmjRopQqVYqePXtm+VqcgdNMCCciIpIbCuciIgVDbGIsfhP88uW5Y16IwdfT95qP9/b25uzZs7b7K1asICAggGXLlgGQmJhIu3btuOOOO1izZg1FihTh9ddfp3379vzzzz94enoyefJkPv/8c2bMmEG1atWYPHkyixYtolWrVpk+74ABA1i/fj3vv/8+derU4cCBA5w5c4bw8HC+/fZbevTowa5duwgICMDb2xuACRMm8NVXXzF9+nQqV67Mb7/9Rv/+/QkJCaF58+YcOXKE7t2788QTT/Dwww+zadMmRo4cmeXrr1WrFo0aNWLGjBnceeedtu0zZ86kcePGVK1alV9//ZWBAwcydepUDMNg8uTJdOzYkT179lxzb4B9+/bRvn17Xn/9dWbMmMHp06cZOnQoQ4cOZebMmWzatImnnnqKL7/8ksaNG3Pu3DnWrFlzTc9VkCici4iIS1I4FxGRa2UYBitWrGDp0qU8+eSTtu2+vr58+umntnmvvvrqK1JSUvj000+xWCyAGVyDgoJYtWoVd911F1OmTOGFF16ge/fuAEyfPp2lS5dm+ty7d+9m/vz5LFu2jDZt2gBQoUIF2+PBwcEAlCxZkqCgIMCstI8fP57ly5dzxx132I5Zu3YtH330Ec2bN2fatGlUrFiRyZMnA3DLLbfw77//MmnSpCy/FkOGDGHUqFG8//77+Pn5cenSJRYsWMD7778PkO5Dho8//pigoCBWr15N586dszx3ZiZMmEC/fv1svQkqV67M+++/b3sdhw8fxtfXl86dO+Pv709ERAT16tW7pucqSBTORUTEJdnP36NwLiKSf3w8fIh5ISbfnjs3fvjhB/z8/EhMTCQlJYW+ffsyZswY2+O1atVymJB669at7N27N12F+MqVK+zbt4/o6GiioqK47bbbbI8VKVKEhg0bZtrlfsuWLbi7u9O8efMct3vv3r3ExsbStm1bh+0JCQm20Lpjxw6HdgC2IJ+VPn36MGLECObPn88DDzzAvHnzcHNzo3fv3gCcPHmSl19+mVWrVnHq1CmSk5OJjY3l8OHDOW5/Wlu3buWff/5h9uzZtm2GYZCSksKBAwdo27YtERERVKhQgfbt29O+fXu6deuGj0/uvt8FjcK5iIi4JFXORUQKBovFcl1dy2+mli1bMm3aNDw9PSlTpgxFijjGJV9fx9cRExNDgwYNHEKkVUhIyDW1wdpNPTdiYswPP5YsWULZsmUdHvPy8rqmdlgFBATQs2dPZs6cyQMPPMDMmTPp1asXfn7mUIWBAwdy9uxZ3nvvPSIiIvDy8uKOO+7IdMI8Nzdz2jP7DyfSzvgeExPDI488wlNPPZXu+HLlyuHp6cnmzZtZtWoVv/zyC6+++ipjxoxh48aNtt4EzkjhXEREXJJ9INdSaiIikhO+vr5UqlQpx/vXr1+fefPmUbJkSQICAjLcJzQ0lA0bNtCsWTMAkpKS+Ouvv6hfv36G+9eqVYuUlBRWr15t69Zuz1q5T7b7Q1e9enW8vLw4fPhwphX3atWq2Sa3s/rjjz+yf5GYXdtbtGjBDz/8wLp16xxmsP/999/53//+R8eOHQFzgrwzZ85kei7rhxZRUVEUK1YMMHsL2Ktfvz7bt2/P8ntRpEgR2rRpQ5s2bRg9ejRBQUH8+uuvtuEDzkiztYuIiEtS5VxERPJav379KFGiBF26dGHNmjUcOHCAVatW8dRTT3H06FEAhg0bxsSJE1m8eDE7d+7k8ccfz3KN8sjISAYOHMgDDzzA4sWLbeecP38+ABEREVgsFn744QdOnz5NTEwM/v7+jBo1ihEjRjBr1iz27dvH5s2bmTp1KrNmzQLg0UcfZc+ePTzzzDPs2rWLr7/+ms8//zxHr7NZs2ZUqlSJAQMGULVqVRo3bmx7rHLlynz55Zfs2LGDDRs20K9fvyyr/5UqVSI8PJwxY8awZ88elixZYhsHb/Xcc8+xbt06hg4dypYtW9izZw/fffcdQ4cOBczhB++//z5btmzh0KFDfPHFF6SkpNhm0HdWCuciIuKSNOZcRETymo+PD7/99hvlypWje/fuVKtWjSFDhnDlyhVbJX3kyJHcf//9DBw4kDvuuAN/f3+6deuW5XmnTZtGz549efzxx6latSoPPfSQbRmxsmXLMnbsWJ5//nlKlSplC6yvvfYar7zyChMmTKBatWq0b9+eJUuWUL58ecDsDv7tt9+yePFi6tSpw/Tp0xk/fnyOXqfFYuGBBx7g/PnzPPDAAw6PffbZZ5w/f5769etz//3389RTT1GyZMlMz+Xh4cGcOXPYuXMntWvXZtKkSbz++usO+9SuXZvVq1eze/dumjZtSr169Xj11VcpU6YMAEFBQSxcuJBWrVpRrVo1pk+fzpw5c6hRo0aOXk9BZTFyu/ifE7t48SKBgYFER0dn2u1ERERcw5tvwnPPmbdXr4arvQlFRCQPXblyhQMHDlC+fHmKFi2a380RuWmyeu/nNIeqci4iIi5J3dpFRETEmSici4iIS1I4FxEREWeicC4iIi7Jfsy5ZmsXERGRgk7hXEREXJIq5yIiIuJMFM5FRMQlKZyLiIiIM1E4FxERl6RwLiIiIs5E4VxERFySwrmIiIg4E4VzERFxSfaTwCmci4iISEGncC4iIi5JlXMRERFxJgrnIiLikuwDuZZSExERcRQZGcmUKVPyuxl5qkWLFgwfPtx2v6C/ZoVzERFxSaqci4g4ueRkWLUK5swxr/P4l/mgQYOwWCxYLBY8PDwoVaoUbdu2ZcaMGaSkpOTqXGPGjKFu3bo3vI35ES6PHj2Kp6cnNWvWvKnPmxc2btzIww8/nN/NyJTCuYiIuCSNORcRcWILF0JkJLRsCX37mteRkeb2PNS+fXuioqI4ePAgP/30Ey1btmTYsGF07tyZpELaDevzzz+nV69eXLx4kQ0bNuR3c65LSEgIPj4++d2MTCmci4iIS1LlXETESS1cCD17wtGjjtuPHTO352FA9/LyonTp0pQtW5b69evz4osv8t133/HTTz/x+eef2/a7cOECDz74ICEhIQQEBNCqVSu2bt0KmGF27NixbN261VaJtx6b1XFW//d//0ejRo0oWrQoJUqUoFu3boDZRfvQoUOMGDHCdl6rtWvX0rRpU7y9vQkPD+epp57i8uXLtsdPnTrF3Xffjbe3N+XLl2f27Nk5+noYhsHMmTO5//776du3L5999pnD4wcPHsRisbBw4UJatmyJj48PderUYf369Q77ffvtt9SoUQMvLy8iIyOZPHmyw+ORkZG8/vrrDBgwAD8/PyIiIvj+++85ffo0Xbp0wc/Pj9q1a7Np0ybbMWfPnqVPnz6ULVsWHx8fatWqxZw5c7J8PWl7HmT3/di6dSstW7bE39+fgIAAGjRo4NCGG03hXEREXJLCuYiIE0pOhmHDwDDSP2bdNnz4Tf3F3qpVK+rUqcNCuw8F7r33Xk6dOsVPP/3EX3/9Rf369WndujXnzp2jd+/ejBw5kho1ahAVFUVUVBS9e/fO9jiAJUuW0K1bNzp27Mjff//NihUruPXWWwFYuHAhYWFhjBs3znZegH379tG+fXt69OjBP//8w7x581i7di1Dhw61tXfQoEEcOXKElStXsmDBAv73v/9x6tSpbF/7ypUriY2NpU2bNvTv35+5c+c6hH6rl156iVGjRrFlyxaqVKlCnz59bD0N/vrrL3r16sV9993Hv//+y5gxY3jllVccPuwAePfdd2nSpAl///03nTp14v7772fAgAH079+fzZs3U7FiRQYMGIBx9X1w5coVGjRowJIlS/jvv/94+OGHuf/++/nzzz9z+q3N9vvRr18/wsLC2LhxI3/99RfPP/88Hh4eOT5/rhmFSHR0tAEY0dHR+d0UERHJY336GIb5n5xhvP9+frdGRKRwiIuLM7Zv327ExcVd2wlWrkz95Z3VZeXKG9lswzAMY+DAgUaXLl0yfKx3795GtWrVDMMwjDVr1hgBAQHGlStXHPapWLGi8dFHHxmGYRijR4826tSp4/B4To674447jH79+mXaxoiICOPdd9912DZkyBDj4YcfTvdcbm5uRlxcnLFr1y4DMP7880/b4zt27DCAdOdKq2/fvsbw4cNt9+vUqWPMnDnTdv/AgQMGYHz66ae2bdu2bTMAY8eOHbZztG3b1uG8zzzzjFG9enWH19W/f3/b/aioKAMwXnnlFdu29evXG4ARFRWVaXs7depkjBw50na/efPmxrBhwxyex/qac/L98Pf3Nz7//PNMn89eVu/9nOZQVc5FRMQlabZ2EREndLUafMP2u0EMw7B1I9+6dSsxMTEUL14cPz8/2+XAgQPs27cv03Pk5LgtW7bQunXrXLVt69atfP755w7nbNeuHSkpKRw4cIAdO3ZQpEgRGjRoYDumatWqBAUFZXneCxcusHDhQvr372/b1r9//3Rd2wFq165tux0aGgpgq8zv2LGDJk2aOOzfpEkT9uzZQ7LdH2v7c5QqVQqAWrVqpdtmPW9ycjKvvfYatWrVIjg4GD8/P5YuXcrhw4ezfF1WOfl+PP300zz44IO0adOGiRMnZvn9vRGK5OnZRURE8okmhBMRcUJXg90N2+8G2bFjB+XLlwcgJiaG0NBQVq1alW6/rAJvTo7z9vbOddtiYmJ45JFHeOqpp9I9Vq5cOXbv3p3rcwJ8/fXXXLlyhdtuu822zTAMUlJS2L17N1WqVLFtt+/qbf0QI7cz3Gd0jqzO+9Zbb/Hee+8xZcoUatWqha+vL8OHDychISFHz5eT78eYMWPo27cvS5Ys4aeffmL06NHMnTvXNg/AjaZwLiIiLkljzkVEnFDTphAWZk7+ltG4c4vFfLxp05vWpF9//ZV///2XESNGAFC/fn1OnDhBkSJFiIyMzPAYT09Ph6pwTo+rXbs2K1asYPDgwbk67/bt26lUqVKGx1StWpWkpCT++usvGjVqBMCuXbu4cOFCJq/Y9NlnnzFy5EgGDRrksP3xxx9nxowZTJw4McvjrapVq8bvv//usO3333+nSpUquLu75+gcGfn999/p0qWLrbJv/dCgevXqOTo+J98PgCpVqlClShVGjBhBnz59mDlzZp6Fc3VrFxERl6RwLiLihNzd4b33zNt2s5E73J8yxdwvD8THx3PixAmOHTvG5s2bGT9+PF26dKFz584MGDAAgDZt2nDHHXfQtWtXfvnlFw4ePMi6det46aWXbDN5R0ZGcuDAAbZs2cKZM2eIj4/P0XGjR49mzpw5jB49mh07dvDvv/8yadIkW/siIyP57bffOHbsGGfOnAHgueeeY926dQwdOpQtW7awZ88evvvuO9uEcLfccgvt27fnkUceYcOGDfz11188+OCDWVbpt2zZwubNm3nwwQepWbOmw6VPnz7MmjUrx0vLjRw5khUrVvDaa6+xe/duZs2axQcffMCoUaNy/w2yU7lyZZYtW8a6devYsWMHjzzyCCdPnszx8dl9P+Li4hg6dCirVq3i0KFD/P7772zcuJFq1apdV7uzonAuIiIuSeFcRMRJde8OCxZA2bKO28PCzO3du+fZU//888+EhoYSGRlJ+/btWblyJe+//z7fffedrcprsVj48ccfadasGYMHD6ZKlSrcd999HDp0yDYuukePHrRv356WLVsSEhLCnDlzcnRcixYt+Oabb/j++++pW7curVq1cph9fNy4cRw8eJCKFSsSEhICmNX21atXs3v3bpo2bUq9evV49dVXKVOmjO24mTNnUqZMGZo3b0737t15+OGHKVmyZKZfh88++4zq1atTtWrVdI9169aNU6dO8eOPP+boa1q/fn3mz5/P3LlzqVmzJq+++irjxo1LV5HPrZdffpn69evTrl07WrRoQenSpenatWuOj8/u++Hu7s7Zs2cZMGAAVapUoVevXnTo0IGxY8deV7uzbJNhZNRfxDVdvHiRwMBAoqOjCQgIyO/miIhIHrrrLli2zLw9ejSMGZOvzRERKRSuXLnCgQMHKF++PEWLFr2+kyUnw5o15uRvoaFmV/Y8qpiLXK+s3vs5zaEacy4iIi5JlXMRESfn7g4tWuR3K0RuGnVrFxERl6Sl1ERERMSZKJyLiIhLUuVcREREnInCuYiIuCSFcxEREXEmCuciIuKS7LuyK5yLiNxchWjOaRHgxrznFc5FRMQlqXIuInLzeXh4ABAbG5vPLRG5uazveevPwLXQbO0iIuKSFM5FRG4+d3d3goKCOHXqFAA+Pj5YLJZ8bpVI3jEMg9jYWE6dOkVQUBDu17Hcn8K5iIi4JM3WLiKSP0qXLg1gC+gihUFQUJDtvX+tFM5FRMQlacy5iEj+sFgshIaGUrJkSRITE/O7OSJ5zsPD47oq5lYK5yIi4pLUrV1EJH+5u7vfkMAiUlhoQjgREXFJCuciIiLiTBTORUTEJSmci4iIiDNROBcREZekcC4iIiLOROFcRERckiaEExEREWeicC4iIi5JS6mJiIiIM1E4FxERl6Ru7SIiIuJMFM5FRMQlKZyLiIiIM1E4FxERl6Qx5yIiIuJMFM5FRMQlqXIuIiIizkThXEREXJLCuYiIiDgThXMREXFJmq1dREREnInCuYiIuBzDgJSU1PuqnIuIiEhBp3AuIiIuJ20YVzgXERGRgk7hXEREXI7CuYiIiDgbhXMREXE5CuciIiLibBTORUTE5Sici4iIiLNROBcREZeTdnZ2hXMREREp6BTORUTE5aQN41pKTURERAo6hXMREXE56tYuIiIizkbhXEREXI7CuYiIiDgbhXMREXE5GnMuIiIizkbhXEREXI4q5yIiIuJsFM5FRMTlKJyLiIiIs1E4FxERl6PZ2kVERMTZKJyLiIjLUeVcREREnI3CuYiIuBxNCCciIiLORuFcRERcjirnIiIi4mwUzkVExOUonIuIiIizcapwfuzYMfr370/x4sXx9vamVq1abNq0Kb+bJSIiBYw1jHt5Od4XERERKaiK5HcDcur8+fM0adKEli1b8tNPPxESEsKePXsoVqxYfjdNREQKGOuYc09PiI9XOBcREZGCz2nC+aRJkwgPD2fmzJm2beXLl8/HFomISEFlDeOenua1YUBKCrg5VX8xERERKUyc5t+U77//noYNG3LvvfdSsmRJ6tWrxyeffJLlMfHx8Vy8eNHhIiIiri9tOLffJiIiIlIQOU04379/P9OmTaNy5cosXbqUxx57jKeeeopZs2ZlesyECRMIDAy0XcLDw29ii0VEJL8onIuIiIizsRiGYeR3I3LC09OThg0bsm7dOtu2p556io0bN7J+/foMj4mPjyc+Pt52/+LFi4SHhxMdHU1AQECet1lERPLH0qXQvj1UqQK7d5vbYmLA1zd/2yUiIiKFz8WLFwkMDMw2hzpN5Tw0NJTq1as7bKtWrRqHDx/O9BgvLy8CAgIcLiIi4vrsJ4SzUuVcRERECjKnCedNmjRh165dDtt2795NREREPrVIREQKqrRLqdlvExERESmInCacjxgxgj/++IPx48ezd+9evv76az7++GOeeOKJ/G6aiIgUMBmNObdW00VEREQKIqcJ540aNWLRokXMmTOHmjVr8tprrzFlyhT69euX300TEZECxhrOixQBi8Vxm4iIiEhB5DTrnAN07tyZzp0753czRESkgLNWyd3dzUtSksK5iIiIFGxOUzkXERHJKWsQt4Zz+20iIiIiBZHCuYiIuBz7bu0K5yIiIuIMFM5FRMTl2FfOixRx3CYiIiJSECmci4iIy1G3dhEREXE2CuciIuJy0k4IZ79NREREpCBSOBcREZejyrmIiIg4G4VzERFxOZoQTkRERJyNwrmIiLgcVc5FRETE2Sici4iIy7Efc67Z2kVERMQZKJyLiIjLUeVcREREnI3CuYiIuJyMxpxrtnYREREpyBTORUTE5ahyLiIiIs5G4VxERFxORuucK5yLiIhIQaZwLiIiLkeVcxEREXE2CuciIuJyFM5FRETE2Sici4iIy7GfEE5LqYmIiIgzUDgXERGXo8q5iIiIOBuFcxERcTkZTQinpdRERESkIFM4FxERl6PKuYiIiDgbhXMREXE59mPOFc5FRETEGSici4iIy1HlXERERJyNwrmIiLgc+zHnmq1dREREnIHCuYiIuBxVzkVERMTZKJyLiIjLyWjMuWZrFxERkYJM4VxERFyOKuciIiLibBTORUTE5Sici4iIiLNROBcREZdjPyGcwrmIiIg4A4VzERFxOaqci4iIiLNROBcREZdjPyGcllITERERZ6BwLiIiLkeVcxEREXE2CuciIuJyMhpzrqXUREREpCBTOBcREZejyrmIiIg4G4VzERFxOfZjzhXORURExBkonIuIiMtR5VxEREScjcK5iIi4HIVzERERcTYK5yIi4nLsJ4TTUmoiIiLiDBTORUTE5WRUOdds7SIiIlKQKZyLiIjL0YRwIiIi4mwUzkVExOVozLmIiIg4G4VzERFxOfZjzhXORURExBkonIuIiMtR5VxEREScjcK5iIi4HPsx55qtXURERJyBwrmIiLgcVc5FRETE2Sici4iIy9FSaiIiIuJsFM5FRMTlaEI4ERERcTYK5yIi4nLUrV1EREScjcK5iIi4HPsJ4RTORURExBkonIuIiMtR5VxEREScjcK5iIi4HPsx51pKTURERJyBwrmIiLgczdYuIiIizkbhXEREXI7GnIuIiIizUTgXERGXYhgacy4iIiLOR+FcRERcSkpK6m2FcxEREXEWCuciIuJS7EO4wrmIiIg4C4VzERFxKfYhvEgRzdYuIiIizkHhXEREXIoq5yIiIuKMFM5FRMSlZBbOtZSaiIiIFGQK5yIi4lLsQ7gq5yIiIuIsFM5FRMSlqFu7iIiIOCOFcxERcSnWEO7mBhaLwrmIiIg4B4VzERFxKdYQbg3lCuciIiLiDBTORUTEpVjHnFtDuZZSExEREWegcC4iIi4ls8q5ZmsXERGRgkzhXEREXIo1nFsr5urWLiIiIs5A4VxERFyKxpyLiIiIM1I4FxERl6JwLiIiIs5I4VxERFxK2gnhFM5FRETEGSici4iIS1HlXERERJyR04bziRMnYrFYGD58eH43RURECpC0E8JpKTURERFxBk4Zzjdu3MhHH31E7dq187spIiJSwGgpNREREXFGThfOY2Ji6NevH5988gnFihXL7+aIiEgBozHnIiIi4oycLpw/8cQTdOrUiTZt2mS7b3x8PBcvXnS4iIiIa9OYcxEREXFGRfK7Abkxd+5cNm/ezMaNG3O0/4QJExg7dmwet0pERAqStGPOreHcMMyLxZI/7RIRERHJitNUzo8cOcKwYcOYPXs2RYsWzdExL7zwAtHR0bbLkSNH8riVIiKS3zKrnNs/JiIiIlLQOE3l/K+//uLUqVPUr1/fti05OZnffvuNDz74gPj4eNzt/wMDvLy88PLyutlNFRGRfJQ2nBcp4vhYEaf5yyciIiKFidP8i9K6dWv+/fdfh22DBw+matWqPPfcc+mCuYiIFE6ZTQhnfUyf2YqIiEhB5DTh3N/fn5o1azps8/X1pXjx4um2i4hI4ZXZmHP7x0REREQKGqcZcy4iIpITGnMuIiIizshpKucZWbVqVX43QUREChiFcxEREXFGqpyLiIhLSTvm3M3uL53CuYiIiBRUCuciIuJS0lbO7W8rnIuIiEhBpXAuIiIuJe2EcPa3Fc5FRESkoFI4FxERl5JV5dza5V1ERESkoFE4FxERl6Ju7SIiIuKMFM5FRMSlpJ0Qzv62wrmIiIgUVArnIiLiUjIac65wLiIiIgWdwrmIiLgUdWsXERERZ6RwLiIiLkXhXERERJyRwrmIiLiUjMacW7u4a7Z2ERERKagUzkVExKWoci4iIiLOSOFcRERciiaEExEREWekcC4iIi5FlXMRERFxRgrnIiLiUrTOuYiIiDgjhXMREXEpqpyLiIiIM1I4FxERl5LRmHPrbYVzERERKagUzkVExKVkVTnXUmoiIiJSUCmci4iIS1G3dhEREXFGCuciIuJSNCGciIiIOKNrCudJSUksX76cjz76iEuXLgFw/PhxYmJibmjjREREckuVcxEREXFGRbLfxdGhQ4do3749hw8fJj4+nrZt2+Lv78+kSZOIj49n+vTpedFOERGRHMloQjiFcxERESnocl05HzZsGA0bNuT8+fN4e3vbtnfr1o0VK1bc0MaJiIjklirnIiIi4oxyXTlfs2YN69atw9PT02F7ZGQkx44du2ENExERuRYZjTm3VtE1W7uIiIgUVLmunKekpJCcQenh6NGj+Pv735BGiYiIXCtVzkVERMQZ5Tqc33XXXUyZMsV232KxEBMTw+jRo+nYseONbJuIiEiuacy5iIiIOKNcd2ufPHky7dq1o3r16ly5coW+ffuyZ88eSpQowZw5c/KijSIiIjmmyrmIiIg4o1yH87CwMLZu3crcuXP5559/iImJYciQIfTr189hgjgREZH8oHAuIiIizijX4RygSJEi9O/f/0a3RURE5LplNCGcwrmIiIgUdLkO51988UWWjw8YMOCaGyMiInK9Mhpzbr2tcC4iIiIFVa7D+bBhwxzuJyYmEhsbi6enJz4+PgrnIiKSr7Lq1q6l1ERERKSgyvVs7efPn3e4xMTEsGvXLu68805NCCciIvlOY85FRETEGeU6nGekcuXKTJw4MV1VXURE5GbTmHMRERFxRjcknIM5Sdzx48dv1OlERESuiSrnIiIi4oxyPeb8+++/d7hvGAZRUVF88MEHNGnS5IY1TERE5FpkNCGcwrmIiIgUdLkO5127dnW4b7FYCAkJoVWrVkyePPlGtUtEROSaqHIuIiIizijX4TwlJSUv2iEiInJDZBTOtZSaiIiIFHQ3bMy5iIhIQZDVhHBaSk1EREQKqhxVzp9++ukcn/Cdd9655saIiIhcL405FxEREWeUo3D+999/5+hkFovluhojIiJyvTTmXERERJxRjsL5ypUr87odIiIiN4TCuYiIiDgjjTkXERGXktWYc4VzERERKahyPVs7wKZNm5g/fz6HDx8mISHB4bGFCxfekIaJiIhcC1XORURExBnlunI+d+5cGjduzI4dO1i0aBGJiYls27aNX3/9lcDAwLxoo4iISI5lNCGc9bZmaxcREZGCKtfhfPz48bz77rv83//9H56enrz33nvs3LmTXr16Ua5cubxoo4iISI6pci4iIiLOKNfhfN++fXTq1AkAT09PLl++jMViYcSIEXz88cc3vIEiIiK5oXAuIiIizijX4bxYsWJcunQJgLJly/Lff/8BcOHCBWJjY29s60RERHJJE8KJiIiIM8pxOLeG8GbNmrFs2TIA7r33XoYNG8ZDDz1Enz59aN26dd60UkREJIcyGnOucC4iIiIFXY5na69duzaNGjWia9eu3HvvvQC89NJLeHh4sG7dOnr06MHLL7+cZw0VERHJCXVrFxEREWeU43C+evVqZs6cyYQJE3jjjTfo0aMHDz74IM8//3xetk9ERCRXMgrn1iq6wrmIiIgUVDnu1t60aVNmzJhBVFQUU6dO5eDBgzRv3pwqVaowadIkTpw4kZftFBERyZGsxpxrKTUREREpqHI9IZyvry+DBw9m9erV7N69m3vvvZcPP/yQcuXKcc899+RFG0VERHJMY85FRETEGeU6nNurVKkSL774Ii+//DL+/v4sWbLkRrVLRETkmmjMuYiIiDijHI85T+u3335jxowZfPvtt7i5udGrVy+GDBlyI9smIiKSKykpYBjmbYVzERERcSa5CufHjx/n888/5/PPP2fv3r00btyY999/n169euHr65tXbRQREckR+/CtcC4iIiLOJMfhvEOHDixfvpwSJUowYMAAHnjgAW655Za8bJuIiORWcjKsWQNRURAaCk2bOqZUF6dwLiIiIs4qx+Hcw8ODBQsW0LlzZ9wL0T96IiJOY+FCGDYMjh5N3RYWBu+9B92751+7biL78G0/IZz1tmZrFxERkYIqx+H8+++/z8t2iIjI9Vi4EHr2TB1wbXXsmLl9wYJCEdBVORcRERFndV2ztYuISAGQnGxWzNMGc0jdNnx4oUimCuciIiLirBTORUSc3Zo1tq7sl/DjVjbwBi+mPm4YcOSIuZ+Ls++2rnAuIiIizkThXETE2UVF2W5upBEbuZVZDMxyP1dlDd8WC7jZ/YVTOBcREZGCTuFcRMTZhYbabsbh7XCd2X6uyhq+085bqnAuIiIiBZ3CuYiIs2va1JyV3WKxhfIrFE193GKB8HBzPxencC4iIiLOSuFcRMTZububy6UBV9KGc4vFvJ4ypVCsd24dc572pWopNRERESnoFM5FRFxB9+6wYAFxQWbXdVs4DwsrNMuogSrnIiIi4rxyvM65iIgUcN27E3e4K4yAJDxIWr6KIi3uLBQVcytr+C6S5q+bwrmIiIgUdKqci4i4kCsJqb/Wr9zWvFAFc1DlXERERJyXwrmIiAuJi0u9feVK/rUjvyici4iIiLNSOBcRcSH2gdw+qBcWmU0Ip3AuIiIiBZ3CuYiIC1Hl3LxOO+Zcs7WLiIhIQec04XzChAk0atQIf39/SpYsSdeuXdm1a1d+N0tEpEBRODevVTkXERERZ+M04Xz16tU88cQT/PHHHyxbtozExETuuusuLl++nN9NExEpMAp7t3aFcxEREXFWTrOU2s8//+xw//PPP6dkyZL89ddfNGvWLJ9aJSJSsBT2yrnGnIuIiIizcppwnlZ0dDQAwcHBme4THx9PfHy87f7FixfzvF0iIvnJPpAXxnCuyrmIiIg4K6fp1m4vJSWF4cOH06RJE2rWrJnpfhMmTCAwMNB2CQ8Pv4mtFBG5+ewr54W5W3vaCeEUzkVERKSgc8pw/sQTT/Dff/8xd+7cLPd74YUXiI6Otl2OHDlyk1ooIpI/Cnu39uwq5ykpYBg3t00iIiIiOeF03dqHDh3KDz/8wG+//UZYWFiW+3p5eeHl5XWTWiYikv/Urd28ThvO7SvpycnpK+siIiIi+c1pKueGYTB06FAWLVrEr7/+Svny5fO7SSIiBU5h79ae3YRwoK7tIiIiUjA5Te3giSee4Ouvv+a7777D39+fEydOABAYGIi3t3c+t05EpGBQ5dy8zmzMuf0+IiIiIgWJ01TOp02bRnR0NC1atCA0NNR2mTdvXn43TUSkwNCYc/NalXMRERFxNk5TOTc0g4+ISLYKe7d2hXMRERFxVk5TORcRkewV9m7tGnMuIiIizkrhXETERRiGwnlmY87d7P7aWQO8iIiISEGicC4i4iLShnF1a09lsaRuU+VcRERECiKFcxERF5E2nBfmynnacG6/TeFcRERECiKFcxERF5G2Uq5w7kjhXERERAoyhXMRERehbu2ZTwhnv03hXERERAoihXMRERehynnmE8KBwrmIiIgUbArnIiIuQuFc3dpFRETEeSmci4i4CHVrzzqcW6vpWkpNRERECiKFcxERF6HKucaci4iIiPNSOBcRcRFaSk1jzkVERMR5KZyLiLgIa+U8IMDxfmGiMeciIiLirBTORURchDWMBwWZ14W5cq5wLiIiIs5G4VxExEVYw3hwsOP9wkRjzkVERMRZKZyLiLgIa+W8WLHU+4aRf+3JDzmpnGu2dhERESmIFM5FRFxE2m7thgGJifnWnHyR1YRw1m2qnIuIiEhBpHAuIuIi0nZrt99WWGjMuYiIiDgrhXMRERdhrZwHBqbfVlgonIuIiIizUjgXEXER1iq5tzcULeq4rbDQhHAiIiLirBTORURchLVKXpjDeVZjzhXORUREpCBTOBcRcRHWcF60qBnQ7bcVFurWLiIiIs5K4VxExEWoW3vW4dxaTddSaiIiIlIQKZyLiLgIdWvXmHMRERFxXgrnIiIuwhrE1a1dY85FRETE+Sici4i4CFXONeZcREREnFcGtQUREXFGCucK5yIiIk4nORnWrIGoKAgNhaZNM/5DXggonIuIuIiMurUrnKdSOBcRESlgFi6EYcPg6NHUbWFh8N570L17/rUrn6hbu4iIi8iocl7YxpznZEI4zdYuIiJSACxcCD17OgZzgGPHzO0LF+ZPu/KRwrmIiIuwr5wX9m7tGU0IZ92myrmISC4lJ8OqVTBnjnmtX6RyvZKTzYq5YQCQhDuG9bGr2xg+vNC91xTORURchH3lXN3a0z+mbu0iItdg4UKIjISWLaFvX/M6MrJQVjXlBlqzxlYxv4g/ddlCbf5hP+XNxw0DjhyBqVMz/sPtoh8YKZyLiLgIdWtXOBcRuaHU7VjySlSU7ea7jGAbNfmPWtzJWrZTLXW/ESPSfxjkwh8YKZyLiLiA5GRITDRvF+Zu7TkZc65wLiKSA2m6HTsoxN2OCzxnqSiHhgJwlmAmMxKAkpwkijI04zf+on7qvvYfBrn4B0YK5yIiLsA+hKtbe8ZjzhXORURywa7bcQoWnmcCX3B/6uPWbsdr1uRTAyUdZ6ooN20KYWG8xbNcIoC6/M02atCIPzlLCVqykjXcae5r/TBo2DCHD4zOUYxJPEsKFpf5wEjhXETEBdh3X7evnKtbeyqFcxGRXLDrdvwbzZjE8zzKdBLTrsRst5/ko6wqyj16wLhxBaua7u7OiTHTeZ8nAXiNVyjBWZbThmas5hIBtGMpy2hj7m8Y5mu7+vou40NnfuB5JjGKt1P3cfIPjBTORURcgLVC7uFhhtDC2q09q3BuraZrKTURkRy42u0YYO3VCmYcPmylTqb7ST5JMwThAJF8Q09i8E2tKI8enbtqel51j7c774Qf6xCHD7d7/kUnlgAQwCV+pj0dWUIcPtzN//ELbR1OkUgR7uUb1tOYYpxjCJ85PocTf2CkcC4i4gLsJ4Ozv1Y4T6XKuYhILlztdozFwhqa2jav5w7zhsUC4eHmfpK/0gxB6MiP9OIbwjnCc0zkKGUd989ofLZ9GB83Lmfd43Mb4O263R/u+xzTF4YA8PpzMVjefde2mzdXWEQ37uE74inKPXzPUu6yvb5BfM5PdMSbWJbQiRpsd3weJ/7ASOFcRMQF2K9xbn9d2Lq1a0I4EZEbxN0d3nuPJMOddTS2bV7PHWYwB5gyJeNfuHJz2VWKV9KSnVdnO79AMd7kOcpzgL7MZhdVzJ0Mw7w89BCsWAELFjiG8dGjs59wLbfj29N0u3+dl0nAi5b8SuvXW0LZsrYPgwA8SeQb7qULi4mnKF34jp9L9GeE3yd8TT+KkMi39OAO/kh9Dhf4wEjhXETEBaStnBf2bu2aEE5E5Abo3p1/3lpKDP62TetobIaoBQuge/d8bFwBlrainJCQtzOo21WKP+IRAB5hOovpQnNWkYQHc+jLrfzJclqnHnfuHLRpA/femz6MA4cJT62620+4tmBB7mZMT9Ptfg+VmMEDgBnSARg5EqzVc7uAPp9edGUR8RSl07kveD9mCAAzeYAO/Jz6HC7ygZHCuYiIC1C3dpO6tYuI3FhrPVsB0KRmNG6WFA4RSdS6Awrmmcmoouzjk77C/M032Qf2nIb8q0MQTlCaRXQD4HH+Rxe+ZxUt+Yv6NGEtFwmkAz8xk0EZNv08QSykG4/zIZXZTQSHqcJudnKLuYN1wrXHH7cF7YNEsJYmJOCR+Yzpdt3uV9KC5qwmmSJ0ZAmNWZ963hIlzOBfNrUbvieJzAsbRbfbjpGSYgbwdwdvpX/YKsfGu8gHRhnUFkRExNmoW7tJ4VxE5MZau9a87tgnkJj5sHUrrP/Tne5h+duuAsnadTvt2vBp//AcPQq9ejluCwuD995LDZcLF5rVZvvqtLu747nsj3nvPWb22EQSHtzOemrzr223+vzNctrwADOYQ18eYCb7qcA4XuUkpVhENxbQk9U0JzlNPIzDh1d4jW+wa+/p0wCcIoT6bOY8wfhzkbv4hY7Gj3Q48hOha9ZAixbm/lFRJOHOGMYwnhcxcKMa25l6daZ2m6go6NMHunQxA31UFISG4tm0KfNS3Jk40XzJgwfXgeSDDvvQtKlTV8ytFM5FRFyAurWbcjLmXLO1i4jkjGGkrkp1551mcXPrVli3zukLlDdemq7b9mLxZjdVOEVJqrKTcI5gSbuTtUv4ggXm/ZyEfLtjUrp255OS7eAUPMJH6dpQlHi+oj8V2M8bvMzrvMI8erOXShh2namrsZ22LKMNyynOWe5kLQu4l7+oTwM2O5zzBSZwnmAspHCJAL6lJ9/SE4CIe2OodyfUqwc1jFq8w2rW0QSAB/mEKQzHl1jHRlq757u7pwb7qzzc4ZVX7DZksI8rUDgXEXEB1hCubu3mdUZjzq3bVDkXEcmZ/fvhxAlzmc5GjeDgQZg+Hdavv0FPkJycd9XPvDx3Ruy6bhvAWzzDctqwk6ocoZzDrsU5Q122UI+/6cds6rLVDOIWixnwIV0wT8aNA5RnB9XwJIG2LMPNeszw4Swr2oUDp3wJCjLoNecBON8O9uyBMWNs53PD4HVeoQL7eYSP2HN1grjb+IOeLKAH31Kegw7P24/ZfMX9vMh4llo6mF3PT5/mTxoxA3P891ruxINEltCJH+nIRm7l0Bk/Di2GxYsBagIQQDQf8zC9me/4tbNYzJK4E0/kdqMonIuIuABr5Vzd2s1rdWsXEbl+1i7tjRqZH/o2vjpp+19/QXw8eHldx8kz6radtmt3QTx3ZuxmTF9Ba57jTYeHgzlLCKfZR0XOUoIVtGEFbfiQJ1hBa3PWccNwaPNF/HmeifxOE3ZxC/EUtT3Wi3l8wQC8jAQ4coTpE84BIQwYYMGnfbPUJ65ZM93X4gFmUp3tbKEuHfmRchzJ9GWNZTRzuY9faMcqozktPnyclBEjGXrsAwAG8rk5bhxoxCbGWMZxoUx1tszayt//uPP332Zvi3IeUbz/VxPKWw6an15YuchEbjeKJoQTEXEB6tZuUjgXEblx7Lu0A1SsaBZO4+Ph77+v48RpltWyyWy274Jy7qzYzZj+NqMAuJf5rOFOTlOCs5RgJ9W4hD+baMAnPEgzVhOHD535gR1UdTjdGYrTil+ZxuP8Qx3iKUpR4qjNVjxIYD696ciPXMSf44Tyf+uKA/DII2na1b272eVh+XIIDrZtvp0NPMpHWQZzgAoc4GE+BuCFKgswet7LzHsWsZFb8eciE3k+deerQTvo/XG0aO3OiBHwxRdmOP+/TaGU//Zth8neAJeZyO1GUTgXEXEBaSeEK+zd2hXORUSun7Vybg3nFgvccYd5O9uu7WlnGrf+8s1ibHams33n1I0+d2avISNXZ0z/l1ospT1uJDOJ57iT3ynBWdtuRYmnAZt5kM/4kY7cygbOUZz2/MwxygBwjDI04zf+oiElOM039GQfFYjBj63U5Uc64sclfqU1LVjFRJ4nOcWNO++E6tUzaJu7O7RuDZ98Yn4TLelGvKcXFgZjx8LXX/Pygnp4exv8sbs4X34JLyxoAMCYwCmU5qTjMVkFbesHBStXwtdfm9cHNPO/PXVrFxFxAVlVzq1D0gqDnEwIp3AuIpK906dh1y7zdpMmqdsbN4b/+z8znI8YkcnBWXUrDw522P4yr7GYriymK5XYl7qslv1s3zllN+47Bl9mMph7+J4IDpuP5+bcue0a7+4O773HOz2iATIcv52WL7EsoRNN+J3d3EJ7fubzks/R8+x0DiaXI4wjLKMtVdnlcFwbVrCKFnTgJ/6mPn9TH4BHH836JdG9uxme076u8HCYPBlCQjIcox8KDNsEEyfCoEHml7FaNXhy80vwR7Pcjet30YncbhSFcxERF5BZOAez+6H9fVeW1YRwCuciIjlnrZrXqOHQG9pWOV+3LpMDM1tOzNqt3DrhGXCcUCbxHEl4MJBZ/EYz3EkxH7Qbw51jdscM4TPm05u3eIY/udWxwpvdubN7DZlUh4/f3p3ZRVIgCUYyOfWBtEug2SnBWZbSjjtYz3/UouGpHwGoxB6W05YIDmV4XAM28zt30o6fOUAFiheHHj2yflmA2e40S5XlJFQ/+6w5GeCFC+b9998Hj6IK2jeaurWLiLiAzLq12z9WGOSkW7uWUhMRycLVrtxrP90JwJ1NUhwebtjQ/H167JhZhE53rF238hQsxHL1D5I16M6ebdv9Ix4hCQ8A1tGEd7ErxduN4c6xq8csoAfz6Q3AEcrRhe+Is5tMLctzX0fX+KlTITHJjTubGNy2clJq1+3YWMeu3N98Y1bhr4rkED+XGkSATyJgzuG25tPdRISleY40f9wqh19h3ac7GDQIPvooFx/EW6vXffqY1zmYiK1YMXjpJfP2vfdCmzY5fC7JFYVzEREXkLZyXqQIuLk5PlYYZBXOtZSaiEg2Fi6EyEho2ZI1P14EoOmCYQ6TqPn6Qp06Zkhd//Zax7HYaZYTG8AXFOcsv3N1mnfDMPvLh4SQgCcfYc5edg/fAfAyr7Odamb36mPHsh/nnVbTppwOrc3j/A+AwcwgmLP8yW0MZBYpuJlduLNassvuNQDM4T5KE8VCuqW+BmvXeDsxMWZlGWDkKItj+PX0dLzfs2e6sdd1jv3I6t89eO01WL0aSg/plH58dtqQf+AApYd0YubMHFbNr9PIkebL/vLLvH+uwkrhXETEBaStnFsshXPGdo05FxG5RnaznF/Gh81XxzHfee7/HGc5X7iQxrs+B2Dd+5ugZUsz0C9c6NBdfD69mE1/ruDNE3xIsn3s6NePBfTkJKUpwzG+4V468CPxFGUQn5N0+hz07+947pxwd2do+SWcpiS1+IfpPMoiuuFBAt/Qi1cZZ1uya/9+eOst6NYNfv/d7hx2r2EPlXiQTzlJaR7hI84SnOF+ADNmmF2+K1eGu+/OWVvTVq/r1oWXX7YbRpB2n7Qh/yYvPWaxmJMDXtcSepIlhXMREReQtnJuf7swhXONORcRuQZpunJv4DaSKUIYRyhnHfM8fLg51rpnT+64vAyA9VwdgG4di71nDwCnKcFQPrCdfit1+ZQHU5+vSxemVnkfgEeZjieJfMJDBHGejdzKJJ5L3TcXS6AtWADz14Xh7pbC5yWfw5NEmrHG9txv8BIP/9ydBg3MZeGefRYWL4aOHeG//66e5GqX90SK0J+viMUXgDOE8Kz92uV2XeOTkszMD+YkeVquW66VwrmIiAvIKJxbK+eFpVu7YUDK1aGRqpyLiORQcrI5WNquK/ePdASgKWuwQGpX7scfB8PgDsx11P6mnjmW2zDMy9SpEBzMk0zlDCHU4h/eZiQAL/EG5ykG4eFs8m7KH7uL4+Fh8NC3HeCrrygbksj7PAXAWEazldpmY3K4BNrp02bzAF540Y36x3+wdQEfsPIBXnze/APxySewebM59KtVK3MM/cWL0KGD+TmAdUm013iVP7mNIM4z9+r49RkMYQ1N03WNnzPHXBGseHEYOPA6vhdS6Gm2dhERF5C2W7v97cJSOU+xm7NI4VxEJAPJyY6zdJ85Y5Z6rwbzBDwYyWQ+4EkA2rHU8fjTpwGI5CClieIEocynFwP4wgzxZ86wiK7M4z7cSWImg6nDVmYymG3UZAxjeG9KGB9MM38h9+ploXT3xrAqAU6fpj9fsZDuLKYbPfiW32lCKU7laAm0p582m1erFrzyCumW7HqtGcQnmsvDdeliXkJC4Nw5c6m4nTvNCvqaNe7899iXvPGSGb6n8yi9mc8KWvMJD/Mo0/j7rd14Xv2j8tVXMGSI+RxDh4KPz3V/l6QQUzgXEXEBWVXOC0s4t5+FXbO1i4hTSRuaM1raKif7ZHXePXvMsrH9+tZ2jlKWXsxn/dXJ217ide4n45m/LEBHfmQGQxjELL6iP2/yLBEc4jGmAfAsb9KAzQC8xzDasIIP3YbSvbgbc+ea53nyyasnvDp+24I5g/sW6rKPSrRjKatoQRDRDvtl5EdzBTKmTjWHZqfl5gZvv51+e3Aw/PQT3H47/POPudLY/v0tSAHu91lA79j5AEzkeRa7dWd7Sg0m76/B84a57veLL5rn6dULXngh0+aJ5IjCuYiIC7AG8IzGnBeWbu32FfGMxpxrtnYRKZAWLjTHe9uH5rAweO+91LW0c7IP5CqMWxnAUtoxgC84TUmCOM+X3E9nlqTuZLFAiRK2yjnAu4wgiAt8wFCW05b6/E1F9nKS0lRjuzn5GkBwMK3nv0jXqQaLv3OjY0eIjze7k99669WT2Y3fLslpltGWO1nLVupyN//HUtrhQ1yWS6Bdvmxely+f5cvNUGQkLFkCzZrBihWp2z7Y3A22roSoKIJDQ3nncDD3D4Rx42DbttRV4UaNgkmTUldJEblWCuciIi7AGsALc7d2+9Ctbu0i4hSsM6SnXVPbOgnaggXm/Yz2OXrUXD9r+HCzj3aaLupZMYCt1GEu9zGfXhygAgB1+Ztv6UEFDqTubLGY1x9+aPYdP3YMDIMALjGZUQzlA17mdb6mH/uohIUUZvAARYk3jzt3DtzdmfyOhZ9+NlcDA7Nqbj21dZy39dyV2MdS2tGc1aylKb2Yz6Kwp/DIZAm05GQz8MO1dytv0ADmz4d77jHvf/klBBRz7Brfz4CZs+DXX81gbrGYE8E99dS1PafkXmJyIscuHeNw9GEORx/m0IVDdK7SmTql6+R3024IhXMRERegbu0K5yLiZNLMkH4RfwK4ZD5mGGbyGzbMdj+RIiylHbfzByU4m3qeKVNSpwpPYx8VWE4b9lOBaAK5QBDRBLKXSuylsm0/Hy4zmJm8xTN4k+aPRliYef7u3c1fpD17mm272u7yHGQ2/Xmad3iXETTjN25ng+M5oqKo0MJcJ3v8eLMI36uX3ePu7mYvALtz1+EffqAzd/ELS+jM4Aq1+dLNHQvpWQM/mOuwX6tOnWDTJvNb07Bh+sctFpg2DerVM+c5mT3bseOC3Bjn486z7/w+9p3b53C9//x+jl06RoqR4rB/UNEghXMRESk4MpoQrjB3a1c4F5ECb80aW5V7CR3pzBIe4mM+4pHUGdKvPm4A9/Ml87gPPy4xgnd5mndSx2JfdY5i/EorltGWZbS1VcQz4sUVOrGE3syjE0vwJTb9Tu++a5a4rb9Au3c3q/lpu9gDDdjMV9yf8ZNd7Y7+0kvm7+BWrRz/XmV27jv5nQUlHqPL+ZnM/q0cz/4LtWunP719OE933lyqVy/rx6tUge3bwcMDypS5vucqjAzD4HTsaY5EH7FVv49cNG8fuHCAfef2cf7K+SzP4enuSbnAcpQLLEdEYARVile5Sa3PewrnIiIuQJVzx4neMhr3p3AuUkhdy0RqN4Pd5GaTry439gkPU54DvMBEh10n8RzzuA+AGPx5jVeZypOM4m0as44VtGYZbdlEQ1JIfW0eJHAH66nPZoK4QCDRBHGBEpyhGb+lVurTsljMirl9MLfq3t3sRr9mjdkNfcQIs0t92m739ue52h3dx8ecRC1T9ue++v3q2LQpVeu68d9/cOpUxodZw7mPj11X+TwUEZH3z+GsLidctoVtWwC/mHr7yMUjXEnK/h+T0n6lqVisIhWDK1KxWEUqFKtAxWIVKV+sPCV9S+Jmcc0B/grnIiIuQOE8NXS7u2f8z5nCuUghlNOJ1PJSZh8OXK0m76UiK2ll2/1FJlCZPfTkWwB+pAMvMh6A//EYpTnBK7zGNmryMm+ke7pqbOcufqEty2jOavy4nLv2Wn+BTpmS+YcY9suUeXun6+qe4/Nkd+6rrF3VYzMo7ttv1zJmeS8uMc5W4d5/fj/7zu/jUPQhWxX8XNy5HJ0n1C+UcoHlCA8Mp1zA1Sp4UIQtiPt6Xsf4BCemcC4i4gLUrd0xnGdES6mJFDI5mWwtrwN6Vh8OdOkCYWHMOGoukt2On7mFXbzPMAbwBREcJrBUUfqemoNhuPEwH/EY0wG4h++ZR2/G8yJnKU5LVnIXv9CG5YRx7PrabD/GPCcy6+qe2/NkwRq6L2fyOYPC+Y1jGAanLp+yBW+H63P7iIrJfDk7K39Pf1u383KB5QgPCE+9HRhOWf+yeBXxugmvxvkonIuIOLnExNRgqsp55uFcS6mJFCJpJltzYJ1szTrLeV51cc/BhwNJ77zP571uA+BBPqUbi9hLJX6kE/fwHYHufkQb/jRhLVNJnRLcnRT6Moe+zLm+NoaHw+TJEBJyfd3+M+iOfiOHD2RXObeGdoXz7BmGwcnLJzl04RCHog+lXl+9vf/8fi4nZt3bIsArwFbhrlCsAuWDyjuE8cCigTfp1bgehXMRESdnH74Lczi3VsSzq5wrnIsUAnaTrQFsph5f05dXGWeOszYMOHLE3C9NF+obwu7DAQPYTwUiOEQRkh0+HPjp/QNE4U4Jt7Pck/I97qQwhz408fiT/xKrcuI4lC0LC8ZG4zmmZI6WSctSWBg89BBUrnzjx99n0B39Rslp5fx6Zmp3JTEJMbZK995ze22V74MXDnI4+jDxyfFZHm/BQnhguG2ctzWEW28HewdjuRmD+wshhXMRESdn323dy66XWGHt1l4kk79sCucihYjdZGsJeHAv37CfingRzxu8nOF+N9TVDwfOE8RjTGMe99GWX/iRjqkB/cgRPn3rPFCCgcOK4XnPLxAVRUBoKD+Uq0zjphAdDYsWQelGnWDQQfO8331ndhdPO8Y7I3kZxm8ijTl3ZJ3xPO1SY9bbJy+fzPJ4N4sbZfzLEBEYQURQhHl99XaFYhWICIxQt/N8onAuIuLkrOG7aFHHidAKW+U8p2POFc5FCoGrk60BfMYQ9lMRgE95kFcZhxcJ6fa7FoYBu3dD8eLm2t02UVGsoBUDmcUxwgBYxl08xyQmM8rchdIs+SMYgCEPuUG1FrbDIzDPGxdnd15rZbpFCzNkpx3jfaO6qBdAhXHMeXJKMkcuHnGoftsH8ZiEmCyPD/YOdpjt3DrTeURgBGEBYXi4e9ykVyK5oXAuIuLkMpoMzv6+wrnjdoVzkUKgaVMICyP26Dle4xUALKRwilIspDt9LPMclvjKrStXYO5ceP99+Ptvc1vt2tCypXn5bdGdvEMfACqzm0F8zkuM5x1G0oC/6MscZjGQ5BQ3GjeGatXSP4evbxbdtPN4jHdBY/06uEo4TzFSOH35NMcvHef4peMcu3TMdtsayA9eOEhiSmKm57BgISwgzCF8224HVySoaNDNe0Fywyici4g4uYyWUbO/X9i6tWu2dhHB3R3ee48PemwgijJEcoB+zOYNXuZ/PE4f5uV+iS/g9GmYOhWmTzdvA3h4mBNz/vOPeXnvPYBwAB5lOm8zEl9iicWHN3iZIXxGVXbxWZFHIAkefPA6XmMejfEuaJyhW7thGFyMv8jZuLOcjT3L2biznIw56RC8rZeomCiSUrL/Y+Tp7kn5oPIZBvDyxcpTtEjRbM8hzkXhXETEyVkr42nDeWGrnGtCOBGxF926OxP9OkMMjGEMbVnGJJ5jLU355+1fqN29Ta7Ot3w59OsHp06Z98PD4YknzHCdnAyrVsHKlebFzQ3e7LqOzhMfN3c2YCyj2Ux9fqIjrVhBdFIQ/v5w77039nW7ouy6tVu358WEcNYqd1RMlBmsL0U5hGzr9YmYEzkK3FYWLJTyK0UZ/zLmxc+8LhtQ1hbCy/qXxd3NNXtDSMacLpx/+OGHvPXWW5w4cYI6deowdepUbr311vxu1g2TmJxIt3ndbDMiVgquRMXgipQPKq+JGUQkQ/Zjzu0VtnCe3YRwWkpNxDWsWwc7dpgVa+slKAiaNzdvW739NpyP8aRaNYP+Uwfjfqo93T46zzerSzJtTxum5fD5kpNh3Dh47TVzjHmNGjB6NHTr5vj7plcv85KqMTRMXf/bnRS+pi+NivzN3qTyAPTpA35+1/kFKQTyonKenJLM6djTtrDtEL5jUkP4ycsncxW6vYt4U9ynOMW9i1PKrxRl/cumBnC7S2m/0hRxc7ooJnnMqd4R8+bN4+mnn2b69OncdtttTJkyhXbt2rFr1y5KliyZ3827IQ5eOMiSPUvSbbeOK6kUXMn2aVq1EtWoU7oOEYERWs5ApBDLrlt7YQvnqpyLuK5t28yh1Skp6R+LjITnn4dBg8xZzt9919z++usW3Fu3AODxUPimJXz5JUycCIHZLMccFQV9+5pVcYCHHzZ7w6f9fZupNGPDg0JDWRxcjtubQEyMOZG6ZC83E8IlpyRz6vKpdJVu+yr38UvHORlzkmQjZ38QLFgo6VuSMv5lCPUPpYzf1Wv/MoT6hdrCdgmfEnh75PTNIZKeU4Xzd955h4ceeojBgwcDMH36dJYsWcKMGTN4/vnn87l1N0awdzAfd/7YYVbGvef2EpMQw5GLRzhy8QgrD650OCbAK4DapWpTu2RtKhevTKXgSlQKrqRqu0ghkV23do05d9yucC7ivCZONIN5pUpQoYI51jsxEXbtgoMH4dFH4fXXzZXDLl+Ghg3NCrdV8+bm5Gs7dpgBfejQzJ9r40bo3Nnsxu7nBx99ZAb1XEszNrwGsH49nDhhtk+yZ5sQLtbg1OXT7Dyzk91nd3P04lGiLkXxk/dxeDiKqZ7Hmfj6SVKMDD69yYC1a7k1YFuvbSH86rZSfqVU5ZabwmneZQkJCfz111+88MILtm1ubm60adOG9evXZ3hMfHw88fHxtvsXL17M83Zer+I+xXmogePHqNa1DPee22tbPmHPuT1sO7WN7ae3czH+ImsPr2Xt4bUOx1mwUC6wHBWDK1KpWCVbaLd2lffxcJIpLUUkS+rWbtKYcxHXtn8/zJlj3p47Fxo0SH0sNhY++QTefNNcXcy6wtj48Y5LTFos8Pjj8OST8L//mWPGM+p8uHw5dO1qBvxateCbb+CWW27ca6lZ07xIxhKTE9l3fh87z+xk55mdrDi5C4bsZH2pnZR6+0L6A7zNyyUAw1zH21bptg/c1hB+NXiX9C2p0C0FitO8G8+cOUNycjKlSpVy2F6qVCl27tyZ4TETJkxg7NixN6N5ecpiMbvSlPQtSePwxg6PJSYnsvPMTv45+Q//nfrPVmnfe24vlxIucSj6EIeiD/HrgV/TnbeMfxkzrBdLDezW8B7gFXCzXp6IXKfMKueFtVt7ZmPOFc5F0vvrL/j3Xxg4MOOQeiMtWAA7d8Idd8Dtt+d+8q433zR/ftu1cwzmYHZnHjbMrJzPnAkffgi33gptMpjz7f77ze7vO3bA6tXpJzz/5htz4rfERGjdGhYtAn//3LVVcuZc3DlbAN91Zhc7z5q395/fn36cdzgkYxafIoIiuKX4LUQERhDqH8p3X5Vhy5pQXniyDEMHhip0i9Ny6XftCy+8wNNPP227f/HiRcLDw/OxRTeeh7sHtUrVolapWg7b7avt1ot9cD8Xd8420+Rvh35Ld96wgDBqhNSgekh1aoTUoFJwJSKDIgkLCNOskSIFTHaVc3Vrd9yupdRETPHx0LGj2W27RAmzC3de2bTJnCzNMMz77u5Qvz40a2aO465SJevjjx0zQzfASy9lvp+XlxnQH300830CA6F/f7Ob+qOPQu/e0Lix+YHBnDlmZd0woGdP+Oor85xy7ZJSkjh44WBqAD+zk51nzdunY09nepyvhy9VS1TllhK34B9flY9er0qpIrdwYFPldOO6140HdkP1ICijD1LEiTlNOC9RogTu7u6cPHnSYfvJkycpXbp0hsd4eXnhVUh/o2ZVbQfzk8p951LD+t7zqSH+1OVTHL14lKMXj7J031KH44q4FSE8IJwKxSpQtURVh0tZ/7KamE4kH2Q2IVxh69aeXTjXbO0ijubNS10W7Msv8y6cGwY89ZR5XbWqORHa0aPmmO6NG80J1h5+GF59FTL5l47JkyEhwZwMrmnT62/Tk0/Cp5+aY9XHjTO3WSypHx48+ih88EGul0EvtAzD4NilY+w5u4c95/aw++xu9pzbw56ze9h3fh8JyQmZHhseEG6G8OK32P6nvKXELQ7/V27fDh9th8Rg8PZIf46CsM65yI3gNOHc09OTBg0asGLFCrp27QpASkoKK1asYGhWs3lIhoK9gwkuG0yjso3SPXY+7jw7zuxg26ltbDttjms/cOEAhy4cIjElkQMXDnDgwgFWHFjhcJyfp5/DL9YqxatQsVhFKhSrQDHvYjfrpYkUOurWbspp5TwlxfwHXJ8lSmFmGPD++6n3v//enOE8u9nLrS5fNoNQTn6OZs82J0Dz9TXHcpctC4cPw9q18PXXsGQJTJsGs2bByJHwzDOO3cjPnDGr3AAvvpjz15iVGjXMbu3Ll5tLs61bZ45pB3jlFRg7Vr8j0rL2ytxz1i58Xw3ie8/tJTYxk3XOgKJFitr+R0z7v6KvZ/bjG/JiKTWRgshpwjnA008/zcCBA2nYsCG33norU6ZM4fLly7bZ2+XGKOZdjMbhjdNV3JNTkjl+6TgHLxxkz7k9trFBu87sss0o/1fUX/wV9Ve6cwYVDaJCsQqUDypPhWIVbJeKxSoSERShcUEi1yG7bu0JCWZwdfUKkLW7enZjzsEM6K7+9ZDCZds2s3t2q1bw3nvZB8s//jDHm3t5QZkycOAALFwIOfmX6uefzSr77bfDjBlZd0m/dAmefda8/fLLZjAHKFfOnPm8b19z3Pdzz8GGDeZa4h9+mDppW8mS5uuJjTW7wbdrl7OvR05UrmxeHnvMvH/iBJw7B9Wr37jncDaGYXDq8in2n9/P/vP704Xwi/GZT67sbnGnQrEKVC5emcrBlalSvAqVgytTuXhlygWWw83ids3tsobuK1cy/numcC6uwqkSUe/evTl9+jSvvvoqJ06coG7duvz888/pJomTvOHu5k54YDjhgeE0jXDsU5aQnMD+8/ttk3rsPLOTvef2sv/8fqJiorhw5QKbozazOWpzuvMWcStCZFAklYIrUTk4dSm4ysGViQyKxMM9g/5LImKTXbd2MMeWuvo/LTmtnFv3VTgXV3HunLmU9r59ZkgvXx5GjMj6GGvVvG9fc1myl14yx1fnJJxPnGj+DP3+O9SpYy5dNnx4xj9T48eba4VXrJh5m5o3NyvrixaZlfFdu8xzvvWWOVHdvHnmfi++mLfV7NKlM+9W70ouxV8ye0GeP8D+8/ttPSL3n9/PwQsHs6yAW1cCsg/e1tt5+T+b/eSBsbHpJ+hTOBdXYTEM6+ga13fx4kUCAwOJjo4mIECzkd8ssYmxHLxw0PYprPWy7/w+9p/fz5WkzPvculvcCQsIs13K+pdNvR1g3g71C1WAl0Ltscdg+nQYMwZGj07dnpQEHld/NM6eheDgfGneTTNvHtx3nznz8sqV6R+/dAmsv/pjY9N/mCHijJKSoEMHs3u2v7/5Pnd3h19/NSdby8jx4xARYR67eTMUK2YGeovF7G4eFpb58+3ebS4p5uZmnn/VKnP77bebY7hr1Ejdd88ec7mwhASz2/zdd2f/epKTYfFic2b2P/9M3V61qvnBg9u1F18LjcTkRA5HH7YF7gPnU8P3gQsHOBN7JsvjLVgIDwynfFD51Ar41Wp4xeCKFC1SNMvj84JhpH7vT5yAtHW54sXND6m2bSvcPR+k4MppDnWqyrk4Jx8PH6qHVKd6SPrflilGCscvHbdNRrfn7B72nr96fW4vcUlxtuXgMmPBQhn/MkQGRVK+WHkiA69eB0VSPqg8YQFhCu/i0jKrnBcpYl6SkgrHjO25qZxrxnZxFaNGmcHc19esZE+aZI7x7tXLDN5lyqQ/Zvp082egaVOoV8/cdued5hjwOXPMMd+Z+eQT87pjRzNwf/aZOU78jz/MIF69uvlhQYcO8O67ZjBv1y7nk825u0OPHtC9O6xZY1bPf/sN3n5bwdzKMAxOXj7pWPk+f4D9F8wgfuTiEVKMlCzPUdy7OOWLlbcNN7RdFytPucByeLp73qRXkzMWi1kVj4015ztIy1o5z+3yfCIFjcK55Cs3i5utEt4isoXDY4ZhcPzScQ5HH7bNHn/s0jHH64vHSExJ5NilYxy7dIzfj/ye7jms1fe04d36hyjUP/S6xkGJ5LfMJoQDs2t7TEzhmBTOGrhz2q1dpKBYuNAci33bbbk7buZMczw2mLOt16plTpz2zz/m2uX33mv2IvG0y1nx8amTqz35ZOr2/v3NcP7VV5mH8/h4+Pxz8/bDD5uB6cEHoX1781zff2/Oqr19uzm7OpgfEE6Zkvvu6BaLWZnPrPrv6qxdz62Vb/vu5wfOHyAuKetPXIsWKUr5oPKZBvAAL+frQerra4bwtJPCpaSk/o1Tt3ZxdgrnUmBZLBbKBpSlbEDZTPdJMVI4ffm0rfvWwQsHOXD+AAejr15fOEh8cryt+r760Op05/By9yIyKNJhojrrpXxQefy9tGCmFGyZTQgHZmAvLOHcGrgzmxDOfrvCuRQUP/1kVor9/eHIkZzPlr5uXepa3mPGQLdu5m1fXzPsN2xo7jNihFnBtgb0+fPN5dPCwuDq4jeAGeSffNIM9v/8A7Vrp3/O774zZ04vW9asjFuFhZnjxc+fh2XLzNf0889m9+PnnjO7pIuj5JRk25A/+y7n1iB+Nu5slsfbdz0vX6w8FYLM0G3936WUXymXKzxYg3fayrl9zzCFc3F2Cufi1NwsbpTyK0Upv1IZLguXYqRwMuakQ3C33t5/fj+How8TnxzPrrO72HV2V4bPEeITkmFwr1CsAmX9y+LuplmlJH9l1q0dUgO7urU7dolVOJeCIDnZDK9gjhX/9FOzi3h2Nm+GTp3MLuM9ephLf9mrVMmsgN99N/zvf+YSZc2aQevWZoUdzLkqPOxGfAUHm+dcvNjsFp9ROP/4Y/P6gQcy/hCsWDGzO32vXmY1Myoq4271hdW5uHP8vPdnluxZws97f+Zc3Lks9w/2DnaseFuDeLEKBbLreV7LbDk1+/uaS0ScncK5uDQ3ixuh/qGE+oemWxoOICkliSPRRxwnq7uw3+GT69Oxpzkde5oNxzakO97DzSPDqnvFYhWpFFwpR2t3ilyv7Lq12+/jyrIL5xaLGdBTUhTO5cawvpc8rnFak9mzze7nVu+9B8OGZd77A2DLFmjTBi5cgMaNzW7mGY3F7twZPvjArKqfOWNWs3/6yXzMywseeij9Mf37p4bzCRMcz7t3L6xYYf4cDRmS/Wtzc0tdNq0wSTFSiLoUlW4ytp1ndrLx+EaHseCu2PU8L1nDedrKuTWcFy2qeQnE+SmcS6FWxK2I+UexWHla0zrd49FXom1/YNNeDl44SGJKom39z4yE+oVSuXhlKhWrZF5fXSauUnAl/Dz98vrlSSGRXbd2UDi3cndXOJcb47//4J57wM/PnIgt7dJO2blyJbXiPXasGaSPHIFvvzXXK8/IP/+Ywfz8eXN29J9+Mp8/M088YVbI//3XDNYrVpgzoD/+OISEpN+/UyezW/2xY+ba4y1bpj726afm9V0dEvEMPsM/J09z6vIpTl++eh2bem3dFpMQw8Q2ExlQZ0DuvjgF2KX4SxyOPmzOdXPxmO067XC6zNQsWZNOlTvRqXIn7gi/gyJu+lc8pzLr1m69r8ngxBXoN4ITSkw01/qsVAkeeSS/W+PaAosGUrd0XeqWrpvuseSUZI5dOpbhEnH7zu3jbNxZomKiiIqJ4rdDv6U7vrRfadu67tblSSKDIokMiiTEJwRLXi7mKi4lJ5XzwtCt3TohXFZVR3d383eowrlcjz//NMdcn7vaK3n8eLPSnBsffpi6bNkzz5gfGo0dC++8Y3YLT/sn4L//zG7pZ8/CrbeaY7pzsiqsm5u5FnmdOvD00xnvYxgGlxIucTr2NM37neb7Fafo8+5R7tx5FO9SRzgSfZS1V47Dc6dZ6n2eMu/k/HU+/H8PU6dUHeqUrpPzg/JR9JVoDl44yKHoQxy8cNB2sd7Pris6mBPRlgss59AVvXxQeRqHNyYiKOImvArXlF23do03F1egcF7QJCeba4dERUFoqLnOSZoy0KRJ5pIiYI4Ru/fefGin4O5m/vEtF1gu3UzzAOfjzqcuEXduj8P1mdgznIg5wYmYE6w5vCbdsd5FvIkIiqCMfxlC/UIp7VeaUL9QygaUJSIwgsigSJec7EWuTVaVc3Vrd2R9TEup5T/DyP0M3hnZvRsqVMj6Q5kbaeVKs2IeEwMVK8K+fWagfuABqFzZcd+4OHPStiJFYPRoKFfO3H7hArzxhnl73Djzg7XHHoOJE83gv3692WXdats2aNXK7J7esCEsXZr9xHExCTGciDnByZiTDtVs61Ct05cdrxOSE8wDSwJ94CTw7Sng1NUTFks9t5vFjRI+JQjxCSHEN4SSviUJ8Ulz7RvCpN8n8eOeH+m9oDebHt6Urz3GklKSOBFzwqHaffzScdtqL9btMQkx2Z4rqGgQYQFhlPUva16u/m22dkcPCwhTRTwPZFY5VzgXV6LfHAXJwoXmYLOjR1O3hYWZg9C6dwfMP9DjxqU+PHgwVKuSTM3zWQd6ufmKeRejUdlGGU5Ud+HKhXRru+87t49D0Yc4dvEYcUlx7Dyzk51ndmZ6fi93LyKCImxh3Xqx3tcScYVHVhPCqVu7I2uAU+U8f1nDZqdOMGPGtZ/nvfdg+HBzje5ff732sd859X//Z34gHh9vVrEXLkqhe59oVvxxioGvnGbU6FNcSbpCu4rtCPYuzuDBMG+eeeycOfDss+Zl4kSza3qNGjDgao/vUqXMMd+ffWaGfWs4377d/FqdPg11G8Yz49tT7Ll8ghMnT9g+5D0Rc4ITl80gbr1/OTGDxaCz4ePhQ4hPCMU8Q7h8oiwHt4aTeDYMLobDpTI81Lck418qSbGixXI0GWr1kOrUnV6XXWd38cSPTzCr66xctyk71lVbjl86bvZWuxRlu33s0tUAfvEYJy+fzHbtb6sSPiUc/p7a/32NCIrQWPB8osq5FAYK5wXFwoXQs6dZSrB39Kg5Fevw4SR17srg55uRmGihUyfzn+0VK6Bbw8NsTOpKENHmMWFhHHjxE97f3Z6mTW25Pl9t2WKOV3v0UahZM79bk/+CigbRsExDGpZpmO6xhOQEjkQf4VD0IaIuRdn+2Thx+YRt+9GLR4lPjmf32d3sPrs7w+fwdPekXGA5IgLNCry1+l7arzSh/qnV+ACvAHWhd3Lq1m7KTeVc4Tz/JCaagfTUKXOd7iefhHr1cn+eP/6AUaPM22vXwssvmz3LspOSAsuXw/Hj0KCBQUSlWKITznEuLvPL+Svn+XfvOXYfOQePxODlH8MfPjEEvnMZGgGNYD3QY775HD4ePtRIGMzGZcMpUqQSDRua7R071gzfZ84AGLz6xiX2nD/O8UvHORFzguKdTsLBU3ybdJLWn54mOiGarTsvkNQ3GjffaLZ4RFN7Zs6/Rr4evpTyK+VQ1Q7xDcn02sfDMd2cO2d+AGJdS/3Fh6BELgJQCZ8SzOkxhxazWvDF1i9oFdmKgXUH5ujYpJQkTl0+ZQbtq38L092OieJkzEmSjZz9QLtb3An1D7VVu+0r39brMv5lNCdMAaXKuRQGCucFQXKyWTFPG8ztTZnCu1OKsJHmBPok8NFHnnj+8gMNV9Rib1J57udLvqMLVyjKpKMP8ebjzbmCuexJq1YQFJTJ82bThf56xcfDa6+Z/zAlJcHGjbAh/aTnYsfT3ZOKwRWpGFwx030SkxM5dulYhuPhDl44yJHoIyQkJ9iq81nxLuJNab/Sti761kBfLrAcEUERhAeEa9b5Ak7d2k3WruoK5wXbxInmUmBWb7wBCxbk7hynzyRzb994kjyuUKPhFbbtusKbM69QtuEVGt5+hZiEGMdwHXeeUzHn+GfPOfYcOUcc58D7HOw7B0UScv7Epc2reCA+MXWzpxFAwrmSFE0JoUK1i2w/s42Nlg/hyf9Ry7srPZo2IWRzFL9uPM5Rt+Pgfxy3wOP03nIZtqR5jqbm1a/Hrt4vbl5Za74ebh6U8itFab/S5sW3dOptu0spv1LXHTKDg80PFJ57zvx7XqxY9sek1TSiKWNbjOWVla/w+I+Pc1vYbZT2K+3Qvdx6ffTSUVt381OXT2GQxf9FdixYKOlb0lydxS/UNiSsjH8Zh+Ad4hOi5U+dmCrnUhgonBcEa9bYurIbQHcW0ph13M+XlOYkALuowiu8BsA7sY9Rdl17ePVpFlKSJvzOD9zN/XzJWu7kMOZkIx4kEBvryaxZZvZ3kEkX+vi3pxLdsislS17/y9qwwRyDt3176rY//zSr6HXrXv/5CzMPdw9bN7uMJKUkcfzScTO0XzjkUH23Vh1OxJzgYvxF4pLiOHDBXOolM8W9i1MusBzhgeGE+YeZY+0CyhIWEGYbd6cAnz8MQ93arayBO7sJ4ez3lbyTYqQQlxhHXFIccYlxxCbGsmVbHGM/i4PycfTqF8v8hXF8uzeOV7+PpViI475xSeb1+SvnORt7ljOxZzgbd5boK9EkpiTC1QLsNoD25u1h24HtmTTIKqO/b8keEFsc4oLx9wimUtlgalQI5sr5Yiz9LphLJ4NxTwzmwX7FuL+XP/5efvh5mpdAr0DiY7245RY4cQLq32+wZ8NKEhtOhio/8veVRfy9bJH5PBXsvj5XrwO9Am2hspRfKa6cKcni2aXgcghc+f/27ju+yWr/A/gnTTfdgw4KLUuWwI9x5YKioFwEFZCyRQVEBASkoFfEwVCvqDgYIgrIUFkiFRHXBS4gIktQtIIIlVlaaCndO/n+/jhN0rTpgtKMft6vV155Vp6c5MmT5Hu+55zHD1FhfvhwoS8iQ3wRXC8Y/u7+td7aydPzxgKfmXfMxO6zu7HzzE60XtK6ykG3VqNFiFeIMdgO81KXRjXOl3jf2Mfb8ZV3KTWO1k6OhN9ktiAx0Th5CLdhCwZiCwZiJuahL77FY1iJt/E08uGO3vgeY7AKmPQVkJyMTriIDzABY7Aa6zASANAQ5/EOpiMZwXgSS/H++6rZoPHajxaa0J9CM3x4cQJWDe+OdCc9Fix0wuTJsJhd3/KVFn//DTz1VPl/gl97TV0iRq8H6tcH3n8f2LRJ9b1btkzN083j7ORszIKjgoFhcwpzkJSVhEuZl3A+/bzxdi79nLpPO4fMgkxczb2Kq7lX8UvSL+Xuy9/dHw18Gpj9YTKbLm5Kz+aCNaugRNKPzdrVPTPnioggtygX13Kv4VreNaTlpSEzPxPZhdnIKcwx3rILzOcL9YUQCESk3PsCXUGZQNoQiOcU5iC3MLf8y0mNUXefAcBQNf1K+V8tlXJ2coa7szvyMt1RlOcOdxd3NI/yhLc2EFfOBeDM8QDosvyB3AAE1gtA/14BGHRfACICA+DrGoCkswH49ZAntm/XYOtWILMI+AXAGT8gPV39VN5yC7BhQ/nN7918VAuxUaOATz/RALgbD9xyN14bfxzLji5FSm4Kwr3Cjc2mDbcwr7AyFZsiQNvFql9+mzbArvWWL3tmT7ROWnwa/Sk6LeuES5mXAJh+Mxp4NzANrlY8b3h/gjyDmOkmIzZrp7qAwbktCAszTrbCCSzDOKzEYziArtiGftiGfgAAL2RiGZ6ABqJGhik2GmtwEi2wFBMxBYsxE/PgiVxkoR6e81iIv/5yxY4dQO/eKNOEfhvuxwLEYCd6mcqjV8H86e9O4+1f74E24TwAIAv1MMlzFT7OUcPDFxQAzz1X9uXs2QO88IKafvhhYMECIDBQNYfbuBH49FPgzTcrvjYr1Q5PF0808W+CJv5Nyt0mLS/NGLQnZCTgYsZFXMy8qO4zLuJC+gVkF2bjWp4KAOKuxFX4nF6uXhUG8IZ+8QEeAewLXwUlg+663qzd0UZrzyvKQ0pOClJyUlQrl8Jc5BXlIa8oDzmFOUjLS1PnXXHwbTZdfG8cgdvKXLWucCryRF6WB5z0Hmge5QEfD0/o8j1w9KAHUOiJB/p4ICTAA54unvBw9oCHiwc8nD3g7+GPQI9AaAsCcfq3IMyI8YU+3wML3/LAk+PdjBnT+HigY0cgIwPw7AL8/Iup8uof/1BNsx98sOznIyoA+GdHNSZKUpIaoG7ZMuDcObX+scdUn+vKfrMefhhYulT1LW/bFli3DvD2bo3F9y2u1nul0QCffKIqA55+2v4Dc4NQr1Acf/I4knOSEe4dXqZ/O1Fl2Kyd6gIG57age3c1KntCAnwkE+OwAuOwAifQEqsxGh/jUSQhDO9iGiJx3uIu5uF5vIbnUTKU8UI2RvW5gsVfRGDJkuLgvEQT+tUYhTFYDQDQQI/78A0m4AP8jrZ4HvOw8Otm+BuLsQ4P4RSaYzg24K+cFsb9z5mjBpu75RbTc+blAU88oaafeAL48EPTup491bXZT59WQfrYsZW/NatXAz/9pLL+Wq26eXmprH1oaOWPpxvn5+4HP3c/tAtpZ3G9iCAjP8MYrCdlJRmb0Ruu826YzinMQVZBFk6lnsKp1FMVPq+r1tU4aJ2lQD7UK9R4uR53ZwtRaR1hCLqdnCyPVF2XmrXbQ5/zIn0RLmddNnYtScxMNJ0zxcuSspKQnJ18XaNtW6LVaOHv4Q9/d394u3mjnks9eLp4mt0MyzxcPOCqdYUGGmg0mnLvXbWuxgC6dDDt6eKJjFQPXLnkAV2uJ/Jz3HElSau6V+mADZ+ZXwK03/fAtm1AkAewosRgZ5cvA+++C/z3sLrG95UrpnUjRgBTJphfiq1pUzXw6NChprFN7rxTDRTXq1fVLtsWGgo8/7wK5HfuVOdVr16VPw5Q265frwL7yZMBb++qPc6SDh2ub5A8W+fr7gtf90quAUdUDmbOqS5gcG4LtFpVLT94sPr3UJzVboU/8Qaew3/wAq6gPsKRaP644GA15Gvx9mb/OzQaICICT74ShsVfqMu/nD0LRBU3oY9HE0yBqs0fixV4Ea8iCipN8AC+RtN6l/Fo9vv4Cv3RCUdwFlEogBsicAFr8TBec5+L7/N64PHHgd07dXDap5q+v/ZtV/z1VxRCQ8uOmqvRqID92WdV0F5ZcL5jh7pUnCV//VX9AYTo5tBoNMY/XG3qtyl3OxFBZkGmMSApL4BPykpCam4qCnQFxox9ZXzcfIyjERtuZeaLr8Ub5BnkUH0TSw4GZyn4qIvN2ivqc14bl1LLzM9E/LV4xKfGm99fi8f59PNVvpwToJpsB3oEwtfd1xgAuzu7w93ZHX7ufvB3V0G3Ifi2dO/t6l2lVigpKUC/fio7tWYN0KDB9b3+48eB7h3VAGKlDRtmHpgDqgvUtm0qWzxrlroW+LJlKkhOSzNtp9Go65n37KkuNWbpJQ0ZArz9thp89MknVd339dBqiyu0qykqSnXrIqKax8w51QWO8w/V3kVHq2iz9CBtAJyhMw/MiwNvvPOOShGUCOiN6wFgwQK0bKNFr14q0P3g+fN4velxFMIZI7EWWfDGndiDDzEeWpj/WRyavQoNcQL9sRV/QWXLB2ALPsJYBCIVkXmj0Mb9b+zdq8WH9V/CxLR5+AOt8TpUx8HFDx+An98/y7zM0aNVFuPwYeCXX8rPDOTkAOPHq+n77gO6dFF/pnNzgbfeAjZvBo4dA9q3r/pbTNal0Wjg4+YDHzcf3BJ4S4Xb5hfll83AlwjeDffJ2cko1BciIz8DGfkZiL8WX6WyBHoEmgXs9T3NA/iSAb6/h79NXy++osHgADZrL62mMufJ2ck4efUk4lPj8fe1v43Bd3xqPJJzkit8rGGQK+OlDUuMyVCyVUiQZ1CtXeqwsFD9nBw4oOZvuw3YuhXo1Kn6+3r5ZRWYBwaqAN/LS91atFAjf5d2220qEP7vf1WrqKQk4Oef1bqOHVUWum1boFWrqg34NH169ctMRLavsgHhGJyTI2Bwbkuio4EBA1TT8y+/VJ21Kwi8yw3oIyJM6wFM7rQfO3Z0xYr1npiD+ZiHF3EQ/4Qv0vAJHjEPzDUa1Tk8NRVdcQAH0QUv4lXchT14AsuM2flInMfr/9yCKbsH4dm0mbgPazEOy1EIV/THlxj01kCg6+dlLrIeHKwWbdgALJuTgKXDfzBdxg0wDj4358vb8fffjRARoZoJ+viY9nHuHPDZZ+oP4ObNNfHGk61xc3ZDpF8kIv0qGM0OKhufnp+OK9lXjLfk7GTTfI75fEpOCgRiHODuRMqJSsui1WjNgvbKMvRerl612le+omucl1zO4Nx8XVWCcxFBQmYCTiSfwPHk4ziRYrpPyUmp8LFBnkFo6q8uidjUvyma+DcxzofUC7nhQa5EqtZMu6qeeQbYtUsF0RERwJ9/qq/lTz4BBg2q+n7++EN9PwOqWXhVK1BffFEF59u2qXkfH5WBnjChxq/wSUR2qrJm7RytnRwBg3Nbo9UCPXqoW/fulQbeZgG9peuVx8bigTeGohHicR6RmIZ3sQyqU/gHmIBGuGDat+Gf3tSpwOzZAIAmOGMcBb60J+OexAaEYB/uQDf8hEtoAC9k4j1MVruKiVFlK/XP6omWP2AD7sTard6Yv3UcvJCtUiwAcPUqjqID3i4ewnfpIz/Bx6eb2eNnz1Yjv8fG8rJsdZ1GozH2ia8sGw8AOr0Oqbmp5sF8TnK582l5adCJztgPuCrctG5lm9MXZ+b93P3g5eqFeq71UM+lHrxcvRDgEQB/D3/4uftdV3P7iq5xXnJ5XWrWXt3gXKfX4WzaWbPg+3jycZxIPoHMgsxy99XItxGaBTRTQXepQPxm9qtduVL1iX75ZWDixJrZ36JFavqTT1Sz8eHDge++U72t5swp2++6QwfLWapXXlEVB9HR1WvZ1L07cP/9wNdfq4HV5s/nuCJEZI7N2qkuYHBuyyoLvA0MAX1pxSOza6HDBHyA5zEPH0D9k3sEH2M4Nppvbwj8BwwAli8HEhLMs/YGGg0QFASn5CtYgcfRHsdwCapz4jzMRENcVBdsv3BBlb1k2WJj0WPOYNyCE/gLLbAeIzAOK4CrVwEAhXDGWHwEPbQYhg144PWHgM7mGfjWrVW/xQ0bgLlzBF/E7DG9P926qRHkSr5fQOXv4U30ww/A/v1q1N2K+sLaspwcYPt29efZXl8DoC7nE1wvGMH1gtEG5fePNyjQFSAlJ8UseDfLzueYz2cXZiNfl48LGRdwIeNCpfsvzdfNFwEeARZv/u7+Fpdn5AQAcLOrZu0HDqjP1N131+x+DQPClf6M6kWP9Lx0JOckIzcoBWh9CZ+cP4FVm1UQfvLqSeQVWX6DtBotmgU0Q6vgVmgd1FrdB7dGi8AWZS6BVZ6CAuDHH4FvvlEDlXXtCsycqRopVdfatcDjj6uv5unTgb59VT/n63XggCnAnzNHjWYOqHFKnn5aBe1z5qhbSQ0bqtfUqJFp2fHjpqz5rFnVL8vmzarf+/X2dScix8YB4agu0IhYir4cU0ZGBnx9fZGeng6fku2kHdXu3SoFAiAZQYjARRTADVE4g2NoDx8UZ4RefBG4554yGXcMHqymLTWrnzpVBfIAXsNMvIDX8E/sx4+4w7yZ/Lp1alhdQFUWREUBFy/ibUzHM3gbbRCHBYhBRxxFAK7hTfwbM/Am/JGKE2iFEE2yqjQ4c8YsoD5xAmjTRiCiwVF0QAf8qlZoteYpsRIZeaOICDUAX6km9zfDjh0qoC0oAD76SF2Sxx4NHapaK8ybZ/nyeaRkF2QjOSfZvGl9cTb+cvZlpOelI7swG1kFWcguyEZmQSau5V6rMDtbJYXu0IoHQgI9zEbN9nDxQPpVDxw77IFgf0/072u+HlCBq0500Ol1xmm96KHT68ymDesEAmeNM7ROWmg1WmidtGbbF+mLjPuzNJ1yVYcjvxRBNDp06qyDs6tpG+PjqzEtIsZRxIuKNNAVaeDiooGriwZOGidoNBpkF2RDJxW3Y3fTuqFFUAu0Dm6NVkGtjPfNA5vDVetarcORmqrGxPj1V1U5t2MHkJVlvo2/v/rqnTQJcHOr2n63bFFfyzod4OurrsE9cKD6ui7t2DF1ycrnn1fXyrbk0iWgc2dVbzlwoOol5VRqeIXly1WAXrJy5+pV4No11Qf8xx+BgAC1fMQIVWkaHc0uR0RU886cUYNCenqaB+h33qlyMJs2mf66EtmaqsahDM4d2fr1wEMPGWefwzwsxzhswwPoigOm7UoG0CXFxpZtVt+woQrKAwKMgb8A+B73ogsOwh9p5vvYtcuUOS9RWZCCQDRAAgpg+lfaGH/jEsKRD3eswmiMxhrL+yku28hBuViHkRiALdiCgVV9V0wVDJ+X7RNfLTpdhRn5AwdUU1DDD8j//R9w9GjN9hOtDYcOqQH5AHXZvD//tL/XYOsKdYXGa1On5qZavuWllll/Le9atUb+ruu8Xb1RkBaE/Ksh6NmuBe7tWByEB7dCY7/GN9QP/PffgVdfVef9eQsXGAgJAfr0UcHwBx+ovtkA0LixqvQyjO1Znu+/B/r3VxV9o0aprHaHDupr6LvvgHvvNW177pw6Zy9fVlnx99+3vM9nn1XNx9u0Ua17qnrprwsXVPY/IQG4/XbVqubMGeDWW1Vd7q+/crBOIqp5ly+burvodKbKxM6dgSNHVLeY++6zXvmIKsLg3II6F5yXCIYNBKUuuQaUDXxLKi8ANWTBK2r6XjrjXaqy4Cs8gLUYiZ/RGfFoZlx+D3ZgO/5lXk4LGfiTFz3RGsehhxZH0BEdi0eKrxJL5asOSxUXJTLyv/8O3HWXyi717Kn++OblqSzT7beX3d3Bg+o6vmPGlM1cWZOIanq8e7dp2eHD6oeQrE8veixbk4GJ09Jwe49cLHo/F7mFucgtMt3/fCwX89/NRVjDXEyeZr4eUE39nTROxiy4YdpJ42TMjhumDaPWl85gG9Y7Ozkb91N6Wl+kxRuva3H2b2d4emiRk6VFoL8zli/TwkWrnsfZyZSRr8q01kkLDTTQi+ClWYJPPhE4Owu+2CJo1UogEIgI6rnWQ6BHINyc3XDHHcC+fSqza6luTqdT/a737FHXzW7XTt0iIy0Hz9euqXEw3n/fvNFO48aqQq5zZxU4d+hgOreLitSlyl56SX21Auo8W7pUVYCVtn276m2Um6sGZ9uwQTXdnzZN1ZXecouqHHB1Vdn0O+5Q3ycA8MADqom6JdHRwBdfAO+9pzL41REXp34O0tJUU3hXV9WkvbxMPhHRjcrKMlUiZmebmrG3aqUSB7t3q/9eRLaoynGo1CHp6ekCQNLT061dlNpRVCQSESGi0YioOMv8ptGINGyotrsemzerfZTev2HZ5s3m2+/aZbkcgKTCT3bgbvkAT0gq/Mpus2uXxf08jI8FEGmFP+RRrJZx+FAmY5FMx1syDW/LVLwrU7BQJmGxbMUD5e+3qEhNr1un7i29J4ZtYmLKfz81Gjm95DsJDVWLunYVycoSeewxNT9sWNndJiWJ+Pio9c88c32H4mb59ltVLldXkbvuUtMxMdYuVd1VVCSyaJHI9u2mZR9+qI7LgAGWH/Pjj2p98+bVe67CQpFVq0TOnLnOwpag14uMGqXKERgocuKEiF/xaV7ytVyvV181nYIbNlS87Z13qm0/+6xsGbdtE2nTxvLp7e0t0q2byIQJIu+/L7J3r8jy5SJBQaZtBg0S2b1b5Nq1qpU7K0tk7lwRd3fTeTZ7tkhurkhqqsh774l06GDaf9++Ivn5psenpYmEhKh1b7yhjtm996p5rVbdd+hQ/vP/4x9qmy1bqlbe0vbsEXFzM3+ffvnl+vZFRFQZnc70XXPliml5o0Zq2aFD1isbUWWqGocyOHd01Q2gr2f/ERHm+27Y0PJ+K6ssqGoFwrp1xvUn0Vy0KKzy7pZjrPmCF18U2bSp7Gto0ED9azYE65a2AaQQWvkZHWU9hskreEFGYZWEaxMFEGnbVv3BFlF/WAERZ2eRhATzt8UQtBhuS5ZI1SoLROTyZRVU3Aw6nUj79qpM06eLfPWVmg4JUUEAieTkqOD33XdFtm69+c/33HPqGHh6qkodEZEFC9Sy4cMtP+bnn9X6iIjqPdecOWL8HOt0N1buhQtNAeOOHWrZxIlq2ciRVdtHdrY6Df/4w/wzv3y56dxZtKjy/fTsqbZdv9607NAhU+UTIOLvryrKHnlEnQOurhV/r7RqdWOVDPHxIn36mPYXEWEK2AERFxeR0aPV5620NWvUNvXqiYwYYfp8fPSRmg4OLv95w8PVNocPX3/ZP//c9JU+cOD174eIqCoM340lK44NlaRxcVYrFlGlGJxbUCeDc5HqBdDXo4qBpLEslioLKshEV5aB34vbZQGekjfwb3kZL8oLeEX+jTdkBubJTPxHXsArMhQb1C6hk/UYVvXKgXJuekA+w2BpilMWN2kaniOJiebFvuMOtW7WLNMyQ1YTEHn4YXXv5KSXrwJHme8wIsLsfYiLM/2ZnzbtBo9fOdauVfv38RFJSREpKFBZT0Dk++9vznMaXLigsvZvvSUyZoxI9+4iy5bd3OesqsuXRZ56SqRTJ1XZUvLjevz4zXveTz81/0hMnaqWv/66mh8zxvLj4uLU+qCgqj9XfLx5RvTzz6+/3Nu3m7K4775rWn7woFrm7q4ywBXR61XLAEN5QkJUZcRLL4k4Oallzz9ftfL06qW2//RTNb9ihWkfbm4izz5rqlQzKChQ7+O6daqC5P771VdoaKjIO++o9TdKr1fZ/LAw0+ts21ZVviQnl/84nU5l9Et+DrdsUVklw7K8vLKPKygwfQ2X/q6qrlWrRG6/XeSvv25sP0RElTH8D/njD9MyT0+17O+/rVcuosowOLegzgbnItULoG82S5UFgYGmb9zKKhCuIwOvB2QC3lfZaxRYbOJeBCfRofJ97sXt0gX7jYt8cU3uwA8yGivlVTwvGzBU0ld8VqbYGzYYAgu95P93txR+sl7aN80UQGTsWPXnfOw9Z1TmC1nyMzqWqai4vHKbTJhgCiYMq8rLfBUWinz3XcVNkwsLRc6dM/9I5OeLNG6s9v+f/5iWP/mkWvboo1U71NdjyhTLb72bW800sb5RhvfAcAsNNTWpKy9AvlGHDpmCZUOljKurOm6zZ6v5iRMtPzY+Xq338qr68z1QfHp4eKj7du2uL3v+yy+qOTigstAlM956vco4A5VXvBiy487O5hllw+2xx6regsTQ7Hv1atUU3LCPoUNFzp+v/musaWlpqmLs0KGqv6ajR01fh++8o5bp9aaMv6Xz5vx503t6oy0jiIhqS8OG6rvL0IRdrzd9jxtalBHZIgbnFtTp4NzWWKosuFkZ+OKbDhpjH3U35Mp23CO/oL28iWfkX/he3JEj3kiXbvhRJmKJLMV4+Q695WM8LPMwQyZjkdyNHcZdeiJLZmO2ZKJe2ecr2Ue+WEGBSHhAjsra4SFZjEkCiPhrrsmVlV+JFBVJQYMo+Re+V0EfLsk7iJE5mCUxeEcewRrx0aQbn2LgQJF+/dR0ly5l/2Dr9SqINmzfpInIuHGqkmDrVpGZM0V69FDNYQERX1+VEXzzTZEZM9SysDDVL9Zg3z5ToJedfcOfgjK++cZU4dC6tciQIap5ddeuavlDD9X8c1ZHXp5q8gyIzJ8vcvasep8PHFDLXFxqPsBLSDBlU/v1U6eFoQn244+bjtX06eU/HlDZ66rYutX0WvbtMwXXsbHVK/eZM2Ice6FHD8vZ2zffVOu7dSt/P6dOmT6j8+er/ezZoz4Xd98tMn589bpZ3HefKSttODeee+7mdQ+pLbGxIitXmr8OQwXb3r1lt9+/X61r1Kj2ykhEdKNatlTfXbt3q/nsbNN3eUaGdctGVBEG5xYwOHcwljLwhvaz5WTkC6GVBxFb1Xje4s0JRTIOH8olhJZdWdEge5s3y8t4SWUi8av44poAIu9jonrc3LkigKTBR9riWLnP37F5hvFHKSFBBcqAyIplOrPKjcULdaq8TmXfFkvFtrT8gw/MX4Jeb/rDv/6lP2q0JUZWlkhkpOVA85dfTGWsyQFfiorMB9iqzOefqzI0aFD2JffoodbVZDeDnBzToF2tW4sYvroM3SG0WlOw+cILlvdx9arpeFYWxObkiERFqW1nzFDLnn9ezf/f/1U9gE1JEWnRwhQEl9ds/dIlUyuQP/8su76wUFU8GQL8msjw9u9v/hmfP//G92mrundXr9HSIHmbNlVeMUJEZGs6dVLfXV9/reaTk03f59ZsFEpUGQbnFjA4d0Cls+35+ZYz8i++aPz2zoOr9MZ3AojUQ6bcj69kAZ6S39FG4tBa1mKEzMA86YNvpA1+l7uxQx7FapmJ/8h7eFJOoEX5EW55g+wVN8VPQn1xQb4p0MbPUgQn9biAAOO+LiJcxmOpDMc6mYD35Tm8JvMwQ77AANF9us5s12+9pR4W5JQiV6HSuntxuzijQAC1PiNDjUQ9bZoKslq3Vk2Bly8X+f139bYdPizy9tsqeAkMVH/sLfWlfXHwCQFEHsBW02sv1Sfe4rGp5Ffz6afVriIjRTIzy643DJzXvXvVgsQvv1T1HZYG0RJRP+gdOqhm0o8+qgLeyvZrCOwMgWtJhpHt69VTAfH1ysxUb+Xo0WowL0B9NE6fNt+ub1/zj98rr1jeX8msgqX3taRZs9R2DRuaWkykpJgqgEqP6n32rOqjPWeO6i8dF6cCcUNLh4YNRS5erPg5DZULM2eWXWcYlM7XVzXhrwkDB4qx0uqjj2pmn7Zq+HAxfgeUZhhIcMiQ2i8XEdH1MlQ6btqk5s+dU/NubtYtF1FlGJxbwOC8Dis1iFwhtPIbbpV8uFx/Cr30raJB9ko8/0h8YnzIfnSp/vOUajJfsDFWWiNOAJEn8Z4kIExCcUkAkeFYJ/rPa2jgPxGRzZvlBFoKoPruJyPQcsWEpVYNlgL4YkeOmDKohtrw0i5cMPU3/uKLSotpzLTfdZcp42yQmqoqKUq/ta1bq6AlN7fsPq9cMQ0AV3IgGgO93jS6/csvV1w+EdUa4OmnVT/1wYNFevdWWeLSI4MHBlrsJSFHjphvZykAEyn/0jOlnTpl6tdeegC4mTPV8g4d1OvU69WAaoZLAFq6+ftbfp9KM2RwS7dGOHDA1OJj7drK91NVq1er1h/VbaZvj555pvzWHBWtIyKyVYZxV1avVvMnTph+c4hsGYNzCxic12HXcxm3qt5iYirPDJe4/NvvaCNBuCL/xhtl9xUQUL3r0he/rv+hh8oGokja4HcBRNrimGSh3o1dy97SewhIR/wsgMgSTDSWrwhayY9ooqItS6+hnJYFhYUiHYvHvivvcmAGL7ygtmvevPwRsn/80RTEGwL+jh1NgWl6uqmpeEiICkTHjDENfgaIPPhg2Sy64XJgnTuXX771600Bdcm++iVdu6YGvSs5qF/pW9Om6mO1c2fFI4EPGmR6zHvvlb+dIeAvrz98XJypYqF377KvPTnZ1O97zRpTRhZQFQpjxqh7Q/90Dw/L/ZwtycszNRrp1Utl3aOiVJ93QF0ejK7Pu++q93Do0LLrDJddK69Sh4jIFkVHq++uJUvUvKGiukED65aLqDIMzi1gcF7HXccgchXeqnM5ulKZ+3Jvc+dW77r0JfY7DOuNm/shVU6jienxllKv1VXiud5BjArCkC0BSBF35BifKtQpSbrhRxmJT+QlzJU38G95Dc/JK3hB5mC2vOLzpqz6SCc7d6pLLxkuBebnV/lIqxkZIvXrq+0XLy67/sQJ04Bt/furpvqGpuEtW6r1t99uCqB//9302LQ0FeAagsKNG833bejnVtG1tAsLTX3yS2+n14t8/LGqEDC8VwMHirz2mnrejz9WLQKOH6963+4//jAF+RU10TZkuEtf6io/X33kDK/Z37/8y2EZBp4z3LRa1UKgZD92vV41MazuiLnljdDfrl3Zy5pR1X32mXofLfUrr6g/OhGRrXrkEfXdZRgvZO9eU6U9kS1jcG4Bg3Mq95rvn31m6h89d27l21R3ELTKMvcls+LVuS59iYz8RYSLFzJEA518jVIdktetK/vY6irxXIkIES9k1Egdh+G2YkXVirF0qdo+IEBdCuvnn9XblphoGlCuSxfTaPJ//mm69IohkPXzU7XtlhguTRYcrPpbi5iuFe7sXHHTcBGR999X2zZqpC5xtWKFuszZrbeaXmuLFur63zXh6adVc/S4uPK3MVQIHDtmWvbzzyr4NZSpX7+K+4dfuWLKnjdvrq5TXlOuXVMjty9erFoy7NunrldbnVHYqayfflLHKzKy7DpDJdKPP9Z6sYiIrtv48eq7a84cNf/dd2q+fXurFouoUlWNQzUiIqgjMjIy4Ovri/T0dPj4+Fi7OGQtOh2wdy+QmAiEhQHduwNabfW3qa7YWGDwYDVd8rTTaNT9558D0dHVe/7du4GePY2zf6A1suCFLjhkvt2uXUCPHjdW/lLPdQlhuIRweCIH9ZANT+RAA8E5ROJvNDHe8uAOZxRBCx2cUYQCuOJiu/txvjAM584BOTlAnz7AN9+Y3oqKFBUBHTsCv/9uWhYQANSrB1y4ADRrBvz0ExAcbFp//jzwr38Bf/0FeHsD27cDXbpY3n9BAdCpExAXBzw8Uo9PHv8BM96pjze/ao0B/QVbvqy4kLm5QFQUcOVK2XWensCsWcC0aYCra+WvtSpE1Hvi4lL+NlFRwLlzwMGDQIsWwOzZwOLFgF4PBAaq6eHDK3//d+0CfvkFGD9evd9k286fByIj1WcjLw9wclLLRQB3d/VZP3NGfT6IiOzB008D77wDPPss8MYbwBdfqL9O3boB+/ZZu3RE5atqHMrgnKg2xcYCU6cCFy+aljVsCCxYYArMq0OnU/+sExLMA34DjQaIiFD/wG+0cqEqzxUUBCQnV76v4soCESAjQwXMhsChKlJTgY8/BnbuBPbsATIz1fLgYGD/fqBp07KPSU4GliwBBgwAOnSoeP+HDgFduwr0eg22oh8m4ANcQgNsDhyH6GV9Kz1WS5YAkycDPj4q0O/UCejcWdWPhIRU/XXWlJYtgZMn1Udv40YgKUktHzYMWLQIqF+/9stEN19hIeDmpk7XpCTTZy852XTM8/NrrqKIiOhmmzULeOUVYNIk4L33gLVrgYcfBnr1UhXvRLaqqnFoNf4OE9ENi44Gzp5Vwem6der+zJnrC8wBFXAvXKimS6c9DfMLFtx4YF7V51qyRFUGlJeC1WhUZUT37sZZX9/qBeaAypTHxABffQVcvaoy5e+8A/zwg+XAHFCB+5w5lQfmAHDbxVjE6N8FAAzHBlxCAwTgKu6/+olq/RAbW+HjJ01SFQjXrgH/+x8wf74KhK0RmAOAh4e6X7hQBWnNmwPffw9s2MDA3JG5uJg+cwkJpuWG6fr1GZgTkX3x9FT3OTnm94blRPaOwTlRbdNqVQp1xAh1f6OBc3S0ahLfoIH58ogI86byNaGy5xoypPYqC4q5uABdu6qm4i1b1sAOdTpg6lS8ghfRBPHIgWq/PRwb4IZ8tU1MjNquAv7+1a90uFkMFbTu7sCrr6ouAb17W7dMVDsMp2rJxjqG6YiI2i8PEdGNMHSpys5W9wzOydHYyF9HIrohNZ2Rv5Hnqs3Kgpth717g4kV4Ihcr8Lhx8aP4WE2IqM7te/daqYDV9/LLqj7h+HHghRdUU2eqGwwBuKXMOYNzIrI3hiCcwTk5KmdrF4CIaoghI28LzxUdrTp31/SgerUhMdE42RO7sRqjkA5f3FZ6kL0S29m6u+5SN6p7DHVkJYNzQ+a8dP0ZEZGtM2TODUG5IUjnIKXkKBicE9HNUZuVBTUpLMxsdpQhY17JdkS2yJAdZ7N2InIEbNZOjo7N2omISurevVqD2hHZMkuZc8M0M+dEZG84IBw5OgbnREQl1eYI+EQ3GQeEIyJHwsw5OToG50REpdn7oHZExSoaEI6ZcyKyNxwQjhwd+5wTEVliz4PaERUzBOCZmUBGhmr8kZFhvo6IyF6UNyAcg3NyFAzOiYjKY6+D2hEV8/ICfH2B9HSVMTf0zPD1Bby9rVs2IqLqKpk5FzEF6RytnRwFg3MiIiIH1qCBKTgvuYyIyN4YgnARID+fzdrJ8bDPORERkQMrOSicIUDnYHBEZI9KBuHZ2QzOyfEwc05EROTALA0Kx8w5EdkjZ2fA1RUoKFCBOYNzcjQMzomIiBxYyWudi6hpZs6JyF7Vq6eCc2bOyRExOCciInJghkC85LXOGZwTkb3y9ASuXVPBOUdrJ0fD4JyIiMiBWcqcs1k7Edkrw6BwJTPnHK2dHAWDcyIiIgfGzDkRORJDIJ6aaqpwZOacHAWDcyIiIgdmyJJfuVJ2GRGRvTEE4ikppmUeHtYpC1FN46XUiIiIHFhQkBrd2MDNDQgMtF55iIhuhCFznpys7l1c1I3IETA4JyIicmAajXmmvEEDtYyIyB6VzpyzSTs5EgbnREREDq5kcM7+5kRkz0pnzhmckyNhcE5EROTgSgbkDM6JyJ4ZgnHDOBocqZ0cCYNzIiIiB9cgTG+a1p0HdDorloaI6PoZgnE2aydHxOCciIjIkcXGosHKV4yzERvfAqKigNhY65WJiOg6sVk7OTIG50RERI4qNhYYPBgR6XHGRQ2QACQkAIMHM0AnIrvDAeHIkTE4JyIickQ6HTB1KiCiAvJiEbgIiKiZmBg2cSciu2LInOfkqHsG5+RIGJwTERE5or17gYsXARQH5MWM0yLAhQtqOyIiO1E6GOeAcORInK1dACIiIroJEhONk+G4hKY4DSfoEYqkcrcjIrJ1pYNxZs7JkTA4JyIickRhYcZJZ+gQh1uhgUALfbnbERHZOgbn5MjYrJ2IiMgRde+uLmqu0QAA3JEPNxSY1ms0QMOGajsiIjtROhhncE6OhME5ERGRI9JqgYUL1XRxgG5kmF+wQG1HRGQnmDknR8bgnIiIyFFFRwOffw40aGC+PCJCLY+Otk65iIiuEzPn5MjsIjg/e/Ysxo4di8aNG8PDwwNNmzbF7NmzUVBQUPmDiYiI6rLoaODsWWDXLmDdOnV/5gwDcyKyS6Uz5xytnRyJXQwI9+eff0Kv1+PDDz9Es2bNEBcXh3HjxiE7OxtvvfWWtYtHRERk27RaoEcPa5eCiOiGMXNOjswugvM+ffqgT58+xvkmTZrg5MmTWLp0KYNzIiIiIqI6gn3OyZHZRXBuSXp6OgICAircJj8/H/n5+cb5jIyMm10sIiIiIiK6SRickyOziz7npZ0+fRqLFy/G+PHjK9xu3rx58PX1Nd4aNmxYSyUkIiIiIqKa5uICOJdILzI4J0di1eD8ueeeg0ajqfD2559/mj0mISEBffr0wZAhQzBu3LgK9z9z5kykp6cbbxcuXLiZL4eIiIiIiG6yktlzBufkSKzarP3pp5/G6NGjK9ymSZMmxulLly6hZ8+e6NatG5YtW1bp/t3c3ODm5najxSQiIiIiIhvh6Qmkp6tpjtZOjsSqwXlwcDCCg4OrtG1CQgJ69uyJTp06YdWqVXBysssW+UREREREdAOYOSdHZRcDwiUkJKBHjx6IjIzEW2+9heTkZOO60NBQK5aMiIiIiIhqE4NzclR2EZxv374dp0+fxunTpxEREWG2TkSsVCoiIiIiIqptJQNyBufkSOyibfjo0aMhIhZvRERERERUdzBzTo7KLoJzIiIiIiIiwBSQOzsDrq7WLQtRTWJwTkREREREdsOQOWfWnBwNg3MiIiIiIrIbhqCcwTk5GgbnRERERERkN+p56gEAnvpMYPduQKezboGIagiDcyIiIiIisg+xsai3+n0AgOeVs0DPnkBUFBAba9ViEdUEBudERERERGT7YmOBwYPhmZkEAPBEjlqekAAMHswAneweg3MiIiIiIrJtOh0wdSoggnrIBgDjPQyXV46JYRN3smsMzomIiIiIyLbt3QtcvAgA8EYmAMALWab1IsCFC2o7IjvlbO0CEBERERERVSgx0TjZH1uxAxvwBJZVuB2RvWFwTkREREREti0szDhZH8nYgBGVbkdkb9isnYiIiIiIbFv37kBEBKDRWF6v0QANG6rtiOwUg3MiIiIiIrJtWi2wcKGaLh2gG+YXLFDbEdkpBudERERERGT7oqOBzz8HGjQwXx4RoZZHR1unXEQ1hH3OiYiIiIjIPkRHAwMGqFHZExNVH/Pu3ZkxJ4fA4JyIiIiIiOyHVgv06GHtUhDVODZrJyIiIiIiIrIyBudEREREREREVsbgnIiIiIiIiMjKGJwTERERERERWRmDcyIiIiIiIiIrY3BOREREREREZGUMzomIiIiIiIisjME5ERERERERkZUxOCciIiIiIiKyMgbnRERERERERFbG4JyIiIiIiIjIyhicExEREREREVkZg3MiIiIiIiIiK3O2dgFqk4gAADIyMqxcEiIiIiIiIqoLDPGnIR4tT50KzjMzMwEADRs2tHJJiIiIiIiIqC7JzMyEr69vues1Uln47kD0ej0uXboEb29vaDQaaxenXBkZGWjYsCEuXLgAHx8faxeHqonHz77x+NkvHjv7xuNn33j87BuPn33j8bN9IoLMzEyEh4fDyan8nuV1KnPu5OSEiIgIaxejynx8fHiC2TEeP/vG42e/eOzsG4+ffePxs288fvaNx8+2VZQxN+CAcERERERERERWxuCciIiIiIiIyMoYnNsgNzc3zJ49G25ubtYuCl0HHj/7xuNnv3js7BuPn33j8bNvPH72jcfPcdSpAeGIiIiIiIiIbBEz50RERERERERWxuCciIiIiIiIyMoYnBMRERERERFZGYNzIiIiIiIiIitjcG5jlixZgqioKLi7u6NLly44dOiQtYtEFsybNw//+Mc/4O3tjfr16+PBBx/EyZMnzbbp0aMHNBqN2W3ChAlWKjGVNGfOnDLHpmXLlsb1eXl5mDRpEgIDA+Hl5YVBgwbh8uXLViwxlRQVFVXm+Gk0GkyaNAkAzz1b88MPP6Bfv34IDw+HRqPBli1bzNaLCGbNmoWwsDB4eHigV69eOHXqlNk2qampGDlyJHx8fODn54exY8ciKyurFl9F3VTRsSssLMSMGTPQtm1b1KtXD+Hh4Xj00Udx6dIls31YOl9ff/31Wn4ldVNl597o0aPLHJs+ffqYbcNzz3oqO36Wfgc1Gg3mz59v3Ibnn/1hcG5DNm7ciOnTp2P27Nk4evQo2rdvj3vvvRdXrlyxdtGolD179mDSpEk4cOAAtm/fjsLCQvTu3RvZ2dlm240bNw6JiYnG25tvvmmlElNpbdq0MTs2P/74o3HdtGnT8NVXX2HTpk3Ys2cPLl26hOjoaCuWlko6fPiw2bHbvn07AGDIkCHGbXju2Y7s7Gy0b98eS5Yssbj+zTffxKJFi/DBBx/g4MGDqFevHu69917k5eUZtxk5ciT++OMPbN++Hdu2bcMPP/yAJ554orZeQp1V0bHLycnB0aNH8dJLL+Ho0aOIjY3FyZMn0b9//zLbvvzyy2bn45QpU2qj+HVeZeceAPTp08fs2Kxfv95sPc8966ns+JU8bomJiVi5ciU0Gg0GDRpkth3PPzsjZDNuu+02mTRpknFep9NJeHi4zJs3z4qloqq4cuWKAJA9e/YYl911110ydepU6xWKyjV79mxp3769xXVpaWni4uIimzZtMi47ceKEAJD9+/fXUgmpOqZOnSpNmzYVvV4vIjz3bBkA+eKLL4zzer1eQkNDZf78+cZlaWlp4ubmJuvXrxcRkePHjwsAOXz4sHGbb7/9VjQajSQkJNRa2eu60sfOkkOHDgkAOXfunHFZZGSkvPvuuze3cFQpS8dv1KhRMmDAgHIfw3PPdlTl/BswYIDcfffdZst4/tkfZs5tREFBAY4cOYJevXoZlzk5OaFXr17Yv3+/FUtGVZGeng4ACAgIMFu+du1aBAUF4dZbb8XMmTORk5NjjeKRBadOnUJ4eDiaNGmCkSNH4vz58wCAI0eOoLCw0OxcbNmyJRo1asRz0QYVFBTg008/xWOPPQaNRmNcznPPPpw5cwZJSUlm55uvry+6dOliPN/2798PPz8/dO7c2bhNr1694OTkhIMHD9Z6mal86enp0Gg08PPzM1v++uuvIzAwEB06dMD8+fNRVFRknQJSGbt370b9+vXRokULTJw4EVevXjWu47lnPy5fvoyvv/4aY8eOLbOO5599cbZ2AUhJSUmBTqdDSEiI2fKQkBD8+eefVioVVYVer0dMTAxuv/123HrrrcblDz30ECIjIxEeHo7ffvsNM2bMwMmTJxEbG2vF0hIAdOnSBatXr0aLFi2QmJiIuXPnonv37oiLi0NSUhJcXV3L/LkMCQlBUlKSdQpM5dqyZQvS0tIwevRo4zKee/bDcE5Z+u0zrEtKSkL9+vXN1js7OyMgIIDnpA3Jy8vDjBkzMGLECPj4+BiXP/XUU+jYsSMCAgLw008/YebMmUhMTMQ777xjxdISoJq0R0dHo3HjxoiPj8fzzz+Pvn37Yv/+/dBqtTz37MiaNWvg7e1dpgsezz/7w+Cc6AZNmjQJcXFxZn2WAZj1yWrbti3CwsJwzz33ID4+Hk2bNq3tYlIJffv2NU63a9cOXbp0QWRkJD777DN4eHhYsWRUXR999BH69u2L8PBw4zKee0S1q7CwEEOHDoWIYOnSpWbrpk+fbpxu164dXF1dMX78eMybNw9ubm61XVQqYfjw4cbptm3bol27dmjatCl2796Ne+65x4olo+pauXIlRo4cCXd3d7PlPP/sD5u124igoCBotdoyI0JfvnwZoaGhVioVVWby5MnYtm0bdu3ahYiIiAq37dKlCwDg9OnTtVE0qgY/Pz/ccsstOH36NEJDQ1FQUIC0tDSzbXgu2p5z585hx44dePzxxyvcjuee7TKcUxX99oWGhpYZGLWoqAipqak8J22AITA/d+4ctm/fbpY1t6RLly4oKirC2bNna6eAVGVNmjRBUFCQ8buS55592Lt3L06ePFnpbyHA888eMDi3Ea6urujUqRN27txpXKbX67Fz50507drViiUjS0QEkydPxhdffIH//e9/aNy4caWP+fXXXwEAYWFhN7l0VF1ZWVmIj49HWFgYOnXqBBcXF7Nz8eTJkzh//jzPRRuzatUq1K9fH/fff3+F2/Hcs12NGzdGaGio2fmWkZGBgwcPGs+3rl27Ii0tDUeOHDFu87///Q96vd5Y8ULWYQjMT506hR07diAwMLDSx/z6669wcnIq01yarO/ixYu4evWq8buS5559+Oijj9CpUye0b9++0m15/tk+Nmu3IdOnT8eoUaPQuXNn3HbbbViwYAGys7MxZswYaxeNSpk0aRLWrVuHL7/8Et7e3sa+V76+vvDw8EB8fDzWrVuH++67D4GBgfjtt98wbdo03HnnnWjXrp2VS0/PPPMM+vXrh8jISFy6dAmzZ8+GVqvFiBEj4Ovri7Fjx2L69OkICAiAj48PpkyZgq5du+Kf//yntYtOxfR6PVatWoVRo0bB2dn0U8Zzz/ZkZWWZtVo4c+YMfv31VwQEBKBRo0aIiYnBq6++iubNm6Nx48Z46aWXEB4ejgcffBAA0KpVK/Tp0wfjxo3DBx98gMLCQkyePBnDhw83685ANa+iYxcWFobBgwfj6NGj2LZtG3Q6nfG3MCAgAK6urti/fz8OHjyInj17wtvbG/v378e0adPw8MMPw9/f31ovq86o6PgFBARg7ty5GDRoEEJDQxEfH49nn30WzZo1w7333guA5561VfbdCajKzE2bNuHtt98u83ief3bK2sPFk7nFixdLo0aNxNXVVW677TY5cOCAtYtEFgCweFu1apWIiJw/f17uvPNOCQgIEDc3N2nWrJn8+9//lvT0dOsWnEREZNiwYRIWFiaurq7SoEEDGTZsmJw+fdq4Pjc3V5588knx9/cXT09PGThwoCQmJlqxxFTa999/LwDk5MmTZst57tmeXbt2Wfy+HDVqlIioy6m99NJLEhISIm5ubnLPPfeUOa5Xr16VESNGiJeXl/j4+MiYMWMkMzPTCq+mbqno2J05c6bc38Jdu3aJiMiRI0ekS5cu4uvrK+7u7tKqVSt57bXXJC8vz7ovrI6o6Pjl5ORI7969JTg4WFxcXCQyMlLGjRsnSUlJZvvguWc9lX13ioh8+OGH4uHhIWlpaWUez/PPPmlERG56DQARERERERERlYt9zomIiIiIiIisjME5ERERERERkZUxOCciIiIiIiKyMgbnRERERERERFbG4JyIiIiIiIjIyhicExEREREREVkZg3MiIiIiIiIiK2NwTkRERERERGRlDM6JiIjs3OjRo/Hggw9auxhERER0AxicExER2TCNRlPhbc6cOVi4cCFWr15tlfItX74c7du3h5eXF/z8/NChQwfMmzfPuJ4VB0RERFXjbO0CEBERUfkSExON0xs3bsSsWbNw8uRJ4zIvLy94eXlZo2hYuXIlYmJisGjRItx1113Iz8/Hb7/9hri4OKuUh4iIyJ4xc05ERGTDQkNDjTdfX19oNBqzZV5eXmWy0z169MCUKVMQExMDf39/hISEYPny5cjOzsaYMWPg7e2NZs2a4dtvvzV7rri4OPTt2xdeXl4ICQnBI488gpSUlHLLtnXrVgwdOhRjx45Fs2bN0KZNG4wYMQL/+c9/AABz5szBmjVr8OWXXxoz/bt37wYAXLhwAUOHDoWfnx8CAgIwYMAAnD171rhvw2uaO3cugoOD4ePjgwkTJqCgoKDG3lsiIiJbwuCciIjIAa1ZswZBQUE4dOgQpkyZgokTJ2LIkCHo1q0bjh49it69e+ORRx5BTk4OACAtLQ133303OnTogJ9//hnfffcdLl++jKFDh5b7HKGhoThw4ADOnTtncf0zzzyDoUOHok+fPkhMTERiYiK6deuGwsJC3HvvvfD29sbevXuxb98+eHl5oU+fPmbB986dO3HixAns3r0b69evR2xsLObOnVuzbxQREZGNYHBORETkgNq3b48XX3wRzZs3x8yZM+Hu7o6goCCMGzcOzZs3x6xZs3D16lX89ttvAID33nsPHTp0wGuvvYaWLVuiQ4cOWLlyJXbt2oW//vrL4nPMnj0bfn5+iIqKQosWLTB69Gh89tln0Ov1AFSTew8PD7i5uRkz/a6urti4cSP0ej1WrFiBtm3bolWrVli1ahXOnz9vzKwDgKurK1auXIk2bdrg/vvvx8svv4xFixYZ909ERORIGJwTERE5oHbt2hmntVotAgMD0bZtW+OykJAQAMCVK1cAAMeOHcOuXbuMfdi9vLzQsmVLAEB8fLzF5wgLC8P+/fvx+++/Y+rUqSgqKsKoUaPQp0+fCgPoY8eO4fTp0/D29jY+V0BAAPLy8syeq3379vD09DTOd+3aFVlZWbhw4cJ1vCNERES2jQPCEREROSAXFxezeY1GY7ZMo9EAgDGIzsrKQr9+/fDGG2+U2VdYWFiFz3Xrrbfi1ltvxZNPPokJEyage/fu2LNnD3r27Glx+6ysLHTq1Alr164tsy44OLjiF0ZEROSgGJwTEREROnbsiM2bNyMqKgrOztf/96B169YAgOzsbACqabpOpyvzXBs3bkT9+vXh4+NT7r6OHTuG3NxceHh4AAAOHDgALy8vNGzY8LrLR0REZKvYrJ2IiIgwadIkpKamYsSIETh8+DDi4+Px/fffY8yYMWWCa4OJEyfilVdewb59+3Du3DkcOHAAjz76KIKDg9G1a1cAQFRUFH777TecPHkSKSkpKCwsxMiRIxEUFIQBAwZg7969OHPmDHbv3o2nnnoKFy9eNO6/oKAAY8eOxfHjx/HNN99g9uzZmDx5Mpyc+PeFiIgcD3/diIiICOHh4di3bx90Oh169+6Ntm3bIiYmBn5+fuUGw7169cKBAwcwZMgQ3HLLLRg0aBDc3d2xc+dOBAYGAgDGjRuHFi1aoHPnzggODsa+ffvg6emJH374AY0aNUJ0dDRatWqFsWPHIi8vzyyTfs8996B58+a48847MWzYMPTv3x9z5sypjbeDiIio1mlERKxdCCIiIqKSRo8ejbS0NGzZssXaRSEiIqoVzJwTERERERERWRmDcyIiIiIiIiIrY7N2IiIiIiIiIitj5pyIiIiIiIjIyhicExEREREREVkZg3MiIiIiIiIiK2NwTkRERERERGRlDM6JiIiIiIiIrIzBOREREREREZGVMTgnIiIiIiIisjIG50RERERERERW9v8jGGoBD/vHugAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}